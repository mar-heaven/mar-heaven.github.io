{"posts":[{"title":"2019和2020","text":"前言2019年总体来说还是有所收获的，除了技术上成长了许多，还开发了自己的博客；另外还参与了 Pycon China2019 成都 的志愿者活动，有机会和各位大佬近距离接触 ，阿里老哥、日本小姐姐以及 Flask 项目大神维护者的讲解让小生受益匪浅。 读书的话貌似杂志更多吧，受老爸影响没事的时候就会看看《特别关注》、还有初中以来一直看的《读者》、《意林》。小说的话也看了《嫌疑人x的献身》（开始以为是推理小说，最后还是爱情结尾……以前看《白夜行》感觉亮司也是个“好人”）、《巨人的陨落1》、《巨人的陨落2》目前看了一半吧。 工作方面之前一直在成都工作，最终也是内心斗争了好久还是决定来深圳了，2年前就一直想来了，毕业后又工作了几个月（从成都到北上广深的也许可以体会这需要多大的勇气~），来到深圳开始找新的工作吧，目前有一个offer不过岗位路线和自己的计划略微偏移，最终决定放弃这个offer。 旅行，去年把《港澳通行证》办了，打算的是今年来一趟香港之旅，不过成都距离还是太远了，现在来深圳方便多了，明年的话这个计划基本没问题。 对于2020年 学习，微服务无论是前景还是技术角度个人还是很看好的，然后之前抽空也大概看了看 docker，不过还没有项目部署经验，年前这段时间再巩固一下，年后打算把博客改成 docker 部署。由于用到了 elasticsearch 进行全文检索 和 supervisor 来进程管理，免不了再来一大波操作了~。 社交，感觉自己的运气还是蛮好的，来深圳之前帮助一个老哥解决了一些技术问题，来深圳以后老哥也帮了我不少。未来希望结交一些新朋友吧，不过这个随缘就好。 兴趣，周日的话想培养个兴趣，目前是想弹弹吉他，工作稳定后换个房子，养条狗，还是要有些仪式感的。 读书，《巨人的陨落》还有一本半没读完，《平凡的世界》，《基督山伯爵》（英文版）。 待补充…… 最后想给自己来一句 愿你在被打击时，记起你的珍贵，抵抗恶意；愿你在迷茫时，坚信你的珍贵。爱你所爱，行你所行，听从你心，无问西东。","link":"/2019/12/28/2019%E5%92%8C2020/"},{"title":"2021年总结","text":"本来是打算在年末的最后一天总结一下的，结果跨年玩到了3点多才回后瑞，那就元旦的上午抽点时间回顾2021年的经历，顺便规划一下2022年。 按理来说总结应该是简单的，不过多写点其实也挺好的，很久之后再看回过头再看自己写的东西其实挺有意思的。 2021年的春节是在朋友家过的，在过年的前一个月疫情突然又严重了，老妈说太原那边看样子回不去了，票可以退掉。想到从来没有一个人在外地过年，还是有点新鲜的，所以后来虽然确定可以回去了，也果断选择留在深圳过年。 那天上午在家玩了几局游戏，下午就出门了，目的地没有想好，先去宝安图书馆转了一下，本以为十分冷清的大厅竟坐满了人，大部分是准备考试的，考研、考证、可能考公也不一定。在书架上挑了本讲宇宙天体的书看了两个小时，不得不说有插画的书，特别是这种讲太空星体的更能让人耐心看下去。四点多到了深圳湾公园，海边也有不少人的，也不奇怪，毕竟图书馆都能有那么多人。有不少人在拍照,找了自认为风景还可以的角度拍了几张，选了一张贴上。七点回去吃年夜饭，朋友准备的还是很不错的，菜式比较丰富，名字叫不上来，十分好吃。期间聊了一下工作，还有以前的经历，每个人都有自己的过去，以前一直认为朋友身在一个互联网大厂，在深圳定居已经让不少人羡慕了，但北京的几年辛酸加上个人的性格，就不在 Tencent 想必也差不到哪去。朋友说很多年前他也曾沉迷游戏，为了充钱过年也没有回家，家里还一度以为他在好好读书。那天聊了很久，年夜饭就这么结束了。过年的两个星期把《无心法师》追完了。 三月和同事去玩了恐怖密室，《鬼打墙》。之前是没有玩过恐怖主题密室的，表面平静，实际感觉还是有点吓人的，有个女生主动 solo 最后一关，我们还是佩服她的勇气，后来又去了个恐怖主题的，但都没有第一家那种感觉了。 六月组织了梅林-塘朗山穿越，一行七人，都是入门级玩家，有四位竟然只带了一瓶水就来爬山了，只能说想法比较年经，不过能让他们体会到了躺平是多么美好的一件事，后来这种强度的运动他们再也不参加了。还有一位行进比较慢就到终点等我们了。同事体力相当好，我被丢到了后面，后来带着我的所有补给和唯一的通信工具上了山顶，以至于我后来没有体力走下去了，也联系不上同事，还遇到了分叉口，被迫下山了。下山后找了家小商店，八宝粥火腿什么的各种吃，顺便加了根老冰棍,然后给家里打电话说没钱结账了，家里多转了100块打车回家，用电脑上的微信联系到了同事。“你太能折腾了，自己都这样还叫同事，下次一个人就好了，自己丢了不要紧，别把其他人捎带了。”依稀记得后来老妈是说么说的。再后来就把阳台山，梧桐山也爬完了，之后考虑挑战更高难度的山。 七月份入门了围棋，围棋以前总觉得很高深，不好上手。其实围棋对新人来说还是很友好的，成为国手就是另一回事了。 十一月底换了工作，转了 go 的开发。比较感谢 leader 一年多的关照，还有公司的其他同事也比较好沟通，离职一个多月了有时做梦还能梦到公司的猫。 十二月初捡起了闲置几个月的吉他，自买回来就没弹过几次，不过整个十二月还是连续下来了。 读书清单如下： 《幻夜》30% 《程序员修炼之道》40% 《我曾走在崩溃的边缘》100% 《明朝那些事儿》100% 《活着》100% 《读者》、《特别关注》若干 2021年总体来说相对2020年还是丰富了很多，2020年的周末基本都是在家里宅的。Pycon China 的Meeting up 也结识了不少新朋友，听了他们不同人生经历感触还是挺深的。读书的话这么一看似乎是有点少了，大部分都是杂志，技术方面对 k8s 架构了解了一下，也不再只局限于架构。小说只完成了两本，其实小说应该至少15+的。 退掉好多微信群年度的某个周末，我做了一个重大决定：退掉大部分群，简化社交。截止到2021年末微信加了很多很多的群，大部分都是同事群。因为都是和工作无关，所以离职后也没有退，还有一些在其他场合加入的。也许是自己无法做到让内心足够的平静，查看多个群的内容每天占据了相当可观的时间，虽然确实有一些内容比较有用，但这样的状态也不是自己所理想的。有考虑过退掉这么多群带来的弊端，比如技术领域的滞后，以及社交能力的下滑。然而最后还是这么做了。一直以来理想的状态是每周可以静心读一到两本小说，或者半月通读一本技术书籍；每天弹半个小时到一个小时吉他，然后做一定量的运动。如果每隔几分钟就想看一下群消息，担心错过什么重要信息，那我可能一直达不到理想的状态了。基于以上考虑，目前还是选择放弃一部分社交，多出来的时间调节一下自己，哪怕只是在躺着什么也不做，什么也不想。 2022年读书前置清单： 《幻夜》（一周） 《重构》（一个月） 《放学后》（一周） 《大秦帝国》（三个月） 《why we sleep》（两个月）先规划半年的吧，读书量按周末时间来估的 技术 SRE - Google 运维解密 深入了解 Proxyless Service Mesh 相关技术 一周两道算法练习 读gin源码 深度学习mysql 开源 参与到kratos rqalpha 户外运动（玩） 排牙山 广州蹦极 七娘山 音乐 学习乐理 健身目前每天晚上是固定2组简单的运动：每组40次哑铃（单手1.75KG），80个仰卧起坐以及30个俯卧撑。二月结束的时候希望达到每组50次哑铃（单手2.5KG），100个仰卧起坐以及40个俯卧撑。目前先这么定，哑铃的目标感觉有点高了，先挂着吧。 尝试尝试做一些自己从来没做过的方向，年前听了100天计划，你可以完成什么？播客，觉得很有意思，几位主播都用100天尝试自己从未涉及的领域，100天后的效果还是挺好的。能把一件自己觉得有意思的事连续100天不间断做下来，第二个100天就容易很多了。从来没有期望自己做什么惊天动地的大事，只是不想每天过着重复的生活，很多冲动的决定，只是希望生活可以丰富一点。 end最近看到一句很不错的话: 一个人最好的状态莫过于,眼里写满了故事,脸上却不见风霜。","link":"/2022/01/01/2022/"},{"title":"2022已过三分之一","text":"前言起早了，闲来无事刷一下 blog，看了看年初写的总结，决定复盘一下，近乎鞭尸的行为，先附上2021年总结。其实每过一段时间看看之前写的博客还蛮有意思的。 运动从年后到五月，只爬了一次山，更多的是出去吃个烧烤什么的，爬山的次数无法和2021年同期相比。目前可以做到80个仰卧起坐，40次哑铃（单手5KG）,30个俯卧撑，断断续续，并非每天，偶尔朋友吃饭回来11点了，就没有做了，之后的话尽量保证10.30之前回家。 读书年初的时候在 twitter 上看到一位老哥的总结，感触挺多的。当时看的时候还是挺感慨的，现在看也有同感。2021看完整读过的书不到10本，当然是除去了读者和特别关注等杂志，杂志也不是每篇都看。对比了一下自己： 单身和朋友合租，但基本也无人打扰 有一定社交，2021年还是参与一些群聊的 偶尔玩玩游戏 节假日会出去转转吧，爬山什么的 那天看了看书架上吃灰已久的书，做出了一些调整，周末玩游戏少了，退出了 N 个群，少花点时间水群。这在2021年总结 中有提到。空出来的时间以期读更多的书。从一月到五月，也就是写这篇文章的时候，读书情况如下： 《幻夜》100% 《新参者》 100% 《东方快车谋杀案》100% 《大秦帝国一（上）》100% 《大秦帝国一（下）》100% 《大秦帝国二（上）》100% 《秘密》100% 《三体一》100% 《三体二》100% 《三体三》100% 《大秦帝国二（下）》40% 《刀锋》35% 技术《kubernetes权威指南》时不时翻一下。 音乐🎸偶尔在弹，乐理没有在看。。。 最后阶段性的复盘还是很有必要的，之后每周写一下周报吧。","link":"/2022/05/08/2022%E5%B7%B2%E8%BF%87%E4%B8%89%E5%88%86%E4%B9%8B%E4%B8%80/"},{"title":"Borg状态共享","text":"前言有一个类 Singleton ，我们需要它所有的子类，以及子类的子类所有实例共享同一状态。 class Singleton(object): state = 1 def __init__(self, state): self.state = state class SingletonA(Singleton): pass class SingletonB(Singleton): pass a = SingletonA(1) b = SingletonB(2) a = SingletonA(1) b = SingletonB(2) print(&quot;a.state:&quot;, a.state) print(&quot;b.state:&quot;,b.state) a.state = 666 print(&quot;new a.state:&quot;,a.state) print(&quot;new b.state:&quot;,b.state) 输出结果 a.state: 1 b.state: 2 new a.state: 666 new b.state: 2 可以看到，虽然我们把 a 的状态改变了，但是 b 的状态并没有改变 解决如果我们想做到修改 a 的状态以后， b 的状态也随之修改，可以使用 Borg 模式，从父类的 dict 入手 class Borg(object): state = 0 __share_dict = {} def __init__(self, state): self.__dict__ = self.__share_dict self.state = state class BorgA(Borg): pass class BorgB(Borg): pass old = Borg(7) a = BorgA(1) b = BorgB(2) print(&quot;old.state:&quot;, a.state) print(&quot;a.state:&quot;, a.state) print(&quot;b.state:&quot;,b.state) a.state = 666 print(&quot;new old.state:&quot;,a.state) print(&quot;new a.state:&quot;,a.state) print(&quot;new b.state:&quot;,b.state) 输出old.state: 2 a.state: 2 b.state: 2 new old.state: 666 new a.state: 666 new b.state: 666 显然，当我们声明 self.__dict__ = self.__share_dict 的时候，所有 Borg 以及他的子类实例就共享同一个 state 属性了。","link":"/2020/09/26/Borg%E7%8A%B6%E6%80%81%E5%85%B1%E4%BA%AB/"},{"title":"Class-based views","text":"前言Django 中 函数视图 中有个 request 对象，封装了一些请求的数据，比如 post 请求上传来的参数或者当前用户数据： def index(request, *args, **kwargs): print(args) return HttpResponse(&quot;hello&quot;) 在给博客新增第三方登录的时候后端要进行一些用户数据的处理，比如头像链接拼接，而项目的视图函数采用的是 类视图。 解决一开始没有找到 User 对象，然后看了看 View 类的封装，发现有这么一段： def setup(self, request, *args, **kwargs): &quot;&quot;&quot;Initialize attributes shared by all view methods.&quot;&quot;&quot; self.request = request self.args = args self.kwargs = kwargs 显然在 类视图 中 request 对象被封装成一个属性了，那调用的时候就用 self.request 来代替原来的 request，比如获取当前用户就用 self.request.user 即可。 结语遇到问题直接看源码有时候比百度要来得快一些。","link":"/2019/11/23/Class-based%20views/"},{"title":"DRF JWT 配置","text":"前言原本 github 上有一个和 drf 版本对应的开源项目，最近在做项目的时候由于用的是新版本 drf ，特地到网上仓库看了一下之前使用的 django-rest-framework-jwt 已经停止维护了，幸运的是在该仓库的 issues 里发现了另一个持续维护的项目，django-rest-framework-simplejwt，目前已经支持 django3.0了。 使用首先使用pip进行安装: pip install djangorestframework-simplejwt 然后在 DRF 配置加入以下内容 REST_FRAMEWORK = { ... 'DEFAULT_AUTHENTICATION_CLASSES': ( ... 'rest_framework_simplejwt.authentication.JWTAuthentication', ) ... } 那么我们如何获取 token 呢？这时候需要配置一个路由来获取 token，直接配置到项目根目录下的 urls.py 里就好 # urls.py from rest_framework_simplejwt.views import ( TokenObtainPairView, TokenRefreshView, ) urlpatterns = [ ... path('api/token/', TokenObtainPairView.as_view(), name='token_obtain_pair'), path('api/token/refresh/', TokenRefreshView.as_view(), name='token_refresh'), ... ] 然后就可以使用 postman 来测试获取token了 之后发送请求的时候使用上面的 access就好，不用每次请求都输入用户名密码 请求的方式没有太多变化，就是在请求头中多了一个 Authorization ，对应的值格式是 Bearer+一个空格+access。Bearer 也可以改为其他的名字，这个是官方配置的值，比如我习惯用 jwt 开头，在项目的 settings.py 文件中加入如下配置 # settings.py # simple_jwt config SIMPLE_JWT = { 'ACCESS_TOKEN_LIFETIME': timedelta(minutes=5), 'REFRESH_TOKEN_LIFETIME': timedelta(days=1), 'ROTATE_REFRESH_TOKENS': False, 'BLACKLIST_AFTER_ROTATION': True, 'ALGORITHM': 'HS256', 'SIGNING_KEY': SECRET_KEY, 'VERIFYING_KEY': None, 'AUDIENCE': None, 'ISSUER': None, 'AUTH_HEADER_TYPES': ('Bearer',), 'USER_ID_FIELD': 'id', 'USER_ID_CLAIM': 'user_id', 'AUTH_TOKEN_CLASSES': ('rest_framework_simplejwt.tokens.AccessToken',), 'TOKEN_TYPE_CLAIM': 'token_type', 'JTI_CLAIM': 'jti', 'SLIDING_TOKEN_REFRESH_EXP_CLAIM': 'refresh_exp', 'SLIDING_TOKEN_LIFETIME': timedelta(minutes=5), 'SLIDING_TOKEN_REFRESH_LIFETIME': timedelta(days=1), } 其他的参数看官方文档，这里举一个例子 AUTH_HEADER_TYPES 这里值为 Bearer 就是刚才提到 Authorization 开头要加的字符串，可以根据自己喜好设置。 补充如果想让所有的路由都需要 jwt 认证，那么可以在 drf 配置中增加全局配置： # DRF config REST_FRAMEWORK = { # 其他内容 &quot;DEFAULT_PERMISSION_CLASSES&quot;:[ 'rest_framework.permissions.IsAuthenticated' ] } 如果有的路由，比如用户注册的时候并没有办法获取 token ，那么该函数就跳过登陆验证，就是说该请求并不需要在 header 中添加 Authorization，那么我们可以这样： from rest_framework import mixins from rest_framework.viewsets import GenericViewSet from django.contrib.auth import get_user_model from .serializers import UserSerializer User = get_user_model() class CreateUserView(GenericViewSet, mixins.CreateModelMixin): &quot;&quot;&quot; 用户注册 &quot;&quot;&quot; permission_classes = [] queryset = User.objects.all() serializer_class = UserSerializer 把 permission_classes 赋值为空列表即可。","link":"/2020/02/13/DRF%20JWT%20%E9%85%8D%E7%BD%AE/"},{"title":"Django ORM 机制","text":"ORM是什么目前大多数互联网项目都涉及到数据库，不同的数据库有着自己的优势，用的时候就需要查询它们的 sql 语句，学习成本高；另外一段很长的 sql 语句很容易存在被注入的风险。 对象关系映射（Object Relational Mapping，简称ORM）模式是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。 该技术让我们可以使用面向对象的方法来进行数据库的操作，从而不必理会不同数据库之间 sql 语句的差异。 如上图所示，类对应的就是数据库中的表，类中的属性对应数据表中的字段，类的实例对象就是数据库中的一条条数据了。 from django.db import models class Person(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) 这里的 Person 在数据库中就是一张表，表名可以自定义。first_name 和 last_name 就是其中的两个字段，max_length 就是长度约束，比如 MySQL 数据库中对于字符字段可以设置其最大长度。如果我们想新建一条数据，可以通过以下方法： from .models import Person person = Person(first_name=&quot;泷谷&quot;, last_name=&quot;源治&quot;) person.save() 总结ORM 让开发人员大大减少了工作量，使得代码更加清晰，方便维护。当然每个技术有优点就有缺陷，ORM 虽然使开发效率提高了，但是缺牺牲了一些性能；另外一些复杂的 sql 语句并不能通过 ORM 来实现。不过对于大多开发者来说还是利大于弊。","link":"/2020/02/19/Django%20ORM%20%E6%9C%BA%E5%88%B6/"},{"title":"Django 使用 logging 模块的一次记录","text":"起因偶尔浏览 Stack overflow 看到有人提出的关于日志记录的问题，比较感兴趣就尝试了一下，问题截图如下:意思是他想把不同的日志等级分别记录在不同的文件中，比如 INFO 和 ERROR 分别记录到 info.log 以及 error.log 文件中，然而经过上图的尝试发现只有 ERROR 级别的错误记录到 error.log 的文件中了，而 INFO 级别的却没有记录，有一条解答算是比较清晰的 In your settings you have two entries for django, and django is writing logs based on the last entry. 意思是： **当你设置两个 django 的 loggers，那么默认会执行最后一个，也就是倒数第二章图的这部分有效 'django': { 'handlers': ['file.ERROR'], 'level': 'ERROR', 'propagate': True, }, 解决办法也同样给出了： 'loggers': { 'django.request': { 'handlers': ['file.DEBUG'], 'level': 'DEBUG', 'propagate': True, }, 'django': { 'handlers': ['file.INFO', 'file.ERROR'], # &lt;-- Here 'level': 'INFO', 'propagate': True, } } 本着 实践是检验真理的唯一标准 ，忍不住写了个小的demo试了一下： # views.py class IndexView(View): def get(self, request): log.info('info log file') log.error('error log file') return HttpResponse('return') # settings.py 'handlers': { 'info.file': { 'level': 'INFO', 'class': 'logging.handlers.RotatingFileHandler', # 日志位置,日志文件名,日志保存目录必须手动创建 'filename': os.path.join(os.path.dirname(BASE_DIR), &quot;logs/info.log&quot;), # 日志格式:详细格式 'formatter': 'verbose' }, 'error.file': { 'level': 'ERROR', 'class': 'logging.handlers.RotatingFileHandler', # 日志位置,日志文件名,日志保存目录必须手动创建 'filename': os.path.join(os.path.dirname(BASE_DIR), &quot;logs/error.log&quot;), # 日志格式:详细格式 'formatter': 'verbose', }, }, # 日志对象，第一次 'loggers': { 'django': { 'handlers': ['info.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'INFO', }, 'django': { 'handlers': ['error.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'ERROR', }, } 第一次的结果就是，level 为 INFO 的 loggers 没有记录，也就是只记录了 error 的日志 # 日志对象，第二次 'loggers': { 'django': { 'handlers': ['error.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'ERROR', }, 'django': { 'handlers': ['info.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'INFO', }, } 第二次结果相反，只有 info.log 文件中保存有记录。说明回答问题的这位还是很负责的！最后测试了一下正确的方式： 'loggers': { 'django': { 'handlers': ['info.file', 'error.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'INFO', }, } 最终结果是 INFO 级别以及比它更低级别的日志都记录到了 info.log 中，就是说 error 等级别也一块进去了，而 error 以及比他更低级别的日志会记录到 error.log 文件中，也就是说 error 以及比它低级别的日志会保存两份。这符合 logging 库的说明。 后记虽然找到了问题所在，不过提问者貌似想把不同级别的分别存储到一个文件中，就是 info.log 只保存 INFO 级别的日志，而不会保留 error 的日志。虽然这种需求不是很常见，毕竟 ERROR 以下级别的日志同样重要，也许有的公司人员比较充足，可以分2个人来分别解决 ERROR 以及 CRITICAL(严重错误，比如项目根本无法启动)也说不定~","link":"/2019/11/27/Django%20%E4%BD%BF%E7%94%A8%20logging%20%E6%A8%A1%E5%9D%97%E7%9A%84%E4%B8%80%E6%AC%A1%E8%AE%B0%E5%BD%95/"},{"title":"Django2.0 重写用户模型","text":"前言现有的 django 自带的用户模型已经不满足我们的需求了，比如用户有头像以及性别等字段，于是乎我们需要自定义一个新的用户模型，但是有一部分字段还是可以用以前的，比如邮箱什么的，所以采用继承关系就好。 步骤重写用户模型，继承 django.contrib.auth.models.AbstractUser 类 # users.py from django.db import models from django.contrib.auth.models import AbstractUser # Create your models here. class User(AbstractUser): mobiles = models.CharField(verbose_name=&quot;手机号码&quot;, max_length=15, unique=True) avatar = models.ImageField(upload_to='avatar', verbose_name='头像', null=True, blank=True, help_text=&quot;头像图片的大小规格：256*256，或者对应的比例的图片&quot;) class Meta: db_table = 'blog_users' verbose_name = '用户' verbose_name_plural = verbose_name 在 settings.py 中更改用户认证模型的指向 # settings.py # ...其他代码 # 配置让Django的Auth模块调用users子应用下的User模型 AUTH_USER_MODEL = &quot;users.User&quot; # ...其他代码 最后迁移一下数据即可！","link":"/2019/11/27/Django2.0%20%E9%87%8D%E5%86%99%E7%94%A8%E6%88%B7%E6%A8%A1%E5%9E%8B/"},{"title":"Docker 指令","text":"docker images 显示所有镜像 docker build -t image_name . (点就是从当前路径查找Dockerfile) docker container ls 列举当前运行的容器 docker run -it image_name 交互式运行image docker rm/docker container rm container_id 删除container docker rmi/docker image rm image_id 删除image docker container -aq 列出所有container_id (-q代表只列出id) docker rm $(docker container -aq) ($，删除所有列表中的元素) docker rm $(docker container ls -f “status=exited” -q) 删除退出的容器 docker commit container_name new_container_name docker commit frozty_jeew caesar123/centos-vim Dockerfile 用来build一个一模一样的image Dokerfile FROM strach # 制作base image FROM centos # 使用base image FROM ubuntu:14.04 LABEL maintainer = “775650117@qq.com“ (METADATA:注释) LABEL version = “1.0” RUN yum update &amp;&amp; yun install -y vim python-dev 每次运行RUN都会生成新的image，所以尽量合并成一行 WORKDIR /root # 设定工作目录 WORKDIR /test # 如果没有会自动创建test目录 WORKDIR demo RUN pwd # 输出结果应该是/test/demo 用WORKDIR, 不要使用 RUN cd,尽量使用绝对目录 ADD(COPY) ADD hello / ADD test.tar.gz / # 添加到根目录并解压 WORKDIR /root ADD hello test/ # /root/test/hello WORKDIR /root COPY hello test/ # /root/test/hello 大部分情况，COPY优于ADD，ADD除了COPY还有解压功能 添加远程文件/目录请使用curl或者wget ENV MYSQL_VERSION 5.6 # 设置常量 ENV MYSQL_VERSION 5.6 # 设置常量 RUN apt-get install -y mysql-server= &quot;${MYSQL_VERSION}&quot; \\ &amp;&amp; rm -rf /var/lib/apt/lists/* 引用常量 尽量使用ENV增加可维护性","link":"/2019/12/20/Docker%20%E6%8C%87%E4%BB%A4/"},{"title":"Docker 指令2","text":"RUN 执行命令并创建新的Image layer CMD 设置容器启动后默认执行的命令和参数 ENTRYPOINT 设置容器启动时执行的命令 shell 格式 RUN apt-get install -y vim CMD echo &quot;hello docker&quot; ENTRYPOINT echo &quot;hello docker&quot; Exec格式 RUN [&quot;apt-get&quot;, &quot;install&quot;, &quot;-y&quot;, &quot;vim&quot;] CMD [&quot;/bin/echo&quot;, &quot;hello docker&quot;] ENTRYPOINT [&quot;/bin/echo&quot;, &quot;hello docker&quot;]","link":"/2019/12/20/Docker%20%E6%8C%87%E4%BB%A42/"},{"title":"Elasticsearch基本查询","text":"准备数据# 添加映射 PUT lagou { &quot;mappings&quot;: { &quot;job&quot;:{ &quot;properties&quot;: { &quot;title&quot;:{ &quot;store&quot;: true, &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; }, &quot;company_name&quot;:{ &quot;store&quot;: true, &quot;type&quot;: &quot;keyword&quot; }, &quot;desc&quot;:{ &quot;type&quot;: &quot;text&quot; }, &quot;comments&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;add_time&quot;:{ &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd&quot; } } } } } POST lagou/job/ { &quot;title&quot;:&quot;python django 开发工程师&quot;, &quot;company_name&quot;:&quot;美团科技有限公司&quot;, &quot;desc&quot;:&quot;对django的概念熟悉，熟悉python基础知识&quot;, &quot;comments&quot;:20, &quot;add_time&quot;:&quot;2019-5-30&quot; } POST lagou/job/ { &quot;title&quot;:&quot;python scrapy redis分布式爬虫基本&quot;, &quot;company_name&quot;:&quot;百度科技有限公司&quot;, &quot;desc&quot;:&quot;scrapy的概念熟悉，熟悉redis基础知识&quot;, &quot;comments&quot;:5, &quot;add_time&quot;:&quot;2019-5-1&quot; } POST lagou/job/ { &quot;title&quot;:&quot;elasticsearch打造搜索引擎&quot;, &quot;company_name&quot;:&quot;阿里巴巴科技有限公司&quot;, &quot;desc&quot;:&quot;熟悉数据结构算法，熟悉python基础开发&quot;, &quot;comments&quot;:60, &quot;add_time&quot;:&quot;2019-4-15&quot; } POST lagou/job/ { &quot;title&quot;:&quot;python打造推荐引擎系统&quot;, &quot;company_name&quot;:&quot;阿里巴巴科技有限公司&quot;, &quot;desc&quot;:&quot;熟悉推荐引擎的原理以及算法，掌握C语言&quot;, &quot;comments&quot;:60, &quot;add_time&quot;:&quot;2019-1-22&quot; } 查询基本查询 match(会对输入进行分词) GET lagou/_search { &quot;query&quot;: { &quot;match&quot;: { &quot;title&quot;: &quot;爬取&quot; } } } GET lagou/_search { &quot;query&quot;: { &quot;match&quot;: { &quot;title&quot;: &quot;爬取&quot; } } } term(不会分词) GET lagou/_search { &quot;query&quot;: { &quot;term&quot;: { &quot;title&quot;: &quot;python爬虫&quot; } } } terms(满足任何一个) # terms查询 GET lagou/_search { &quot;query&quot;: { &quot;terms&quot;: { &quot;title&quot;: [&quot;工程师&quot;, &quot;django&quot;, &quot;系统&quot;] } } } query查询(控制查询的返回数量) GET lagou/_search { &quot;query&quot;: { &quot;match&quot;: { &quot;title&quot;: &quot;python&quot; } }, &quot;from&quot;:1, &quot;size&quot;:2 } match_all查询 GET lagou/_search { &quot;query&quot;: { &quot;match_all&quot;: {} } } multi_match查询 # 比如可以指定多个字段 # 比如查询title和desc这两个字段里面包含python的关键词文档 # 可以设置权重 GET lagou/_search { &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;python&quot;, &quot;fields&quot;: [&quot;title^3&quot;, &quot;desc&quot;] } } } stored_fields指定返回的字段(mappings设置了store的) GET lagou/_search { &quot;stored_fields&quot;: [&quot;title&quot;], &quot;query&quot;: { &quot;match&quot;: { &quot;title&quot;: &quot;python&quot; } } } sort(排序返回 asc,desc) GET lagou/_search { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;comments&quot;: { &quot;order&quot;: &quot;desc&quot; } } ] } range(范围查询)boost: 权重 GET lagou/_search { &quot;query&quot;: { &quot;range&quot;: { &quot;comments&quot;: { &quot;gte&quot;: 10, &quot;lte&quot;: 20, &quot;boost&quot;: 2.0 } } } } GET lagou/_search { &quot;query&quot;: { &quot;range&quot;: { &quot;add_time&quot;: { &quot;gt&quot;: &quot;2019-4-1&quot; } } } } match_phrase(短语查询，自动分词，满足所有则返回)slop: 两个词之前的距离 GET lagou/_search { &quot;query&quot;: { &quot;match_phrase&quot;: { &quot;title&quot;: { &quot;query&quot;: &quot;python系统&quot;, &quot;slop&quot;: 6 } } } }","link":"/2019/12/28/Elasticsearch%E5%9F%BA%E6%9C%AC%E6%9F%A5%E8%AF%A2/"},{"title":"Elasticsearch操作","text":"# es的文档，索引的 CRUD 操作 # 索引初始化操作 # 指定分片和副本的数量 # shards一旦设置不能修改（副本数量） # 设置索引 PUT lagou { &quot;settings&quot;: { &quot;index&quot;:{ &quot;number_of_shards&quot;: 5, &quot;number_of_replicas&quot;: 2 } } } GET lagou/_settings GET _all/_settings GET .kibana,lagou/_settings GET lagou/job/1/_source # 修改settings PUT lagou/_settings { &quot;number_of_shards&quot;: 2 } # 保存文档 PUT lagou/job/2 { &quot;title&quot;: &quot;python分布式爬虫开发&quot;, &quot;salary_min&quot;: 15000, &quot;city&quot;: &quot;北京&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;百度&quot;, &quot;company_addr&quot;: &quot;北京市软件园&quot; }, &quot;publish_data&quot;: &quot;2019-5-30&quot;, &quot;comments&quot;: 15 } POST lagou/job/1 { &quot;title&quot;: &quot;python django 开发工程师&quot;, &quot;salary_min&quot;: 3000, &quot;city&quot;: &quot;天猫&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;美团科技&quot;, &quot;company_addr&quot;: &quot;北京市软件园A区&quot; }, &quot;publish_data&quot;: &quot;2019-5-30&quot;, &quot;comments&quot;: 2 } GET lagou/job/2?_source=city,company.name # 修改文章 PUT lagou/job/2 { &quot;title&quot;: &quot;python分布式爬虫开发&quot;, &quot;salary_min&quot;: 15000, &quot;city&quot;: &quot;北京&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;百度&quot;, &quot;company_addr&quot;: &quot;北京市软件园&quot; }, &quot;publish_data&quot;: &quot;2019-5-30&quot;, &quot;comments&quot;: 23 } # 修改文章2 POST lagou/job/2/_update { &quot;doc&quot;:{ &quot;comments&quot;: 21 } } DELETE lagou/job/1 DELETE lagou # 批量获取 GET _mget { &quot;docs&quot;:[ { &quot;_index&quot;:&quot;lagou&quot;, &quot;_type&quot;: &quot;job2&quot;, &quot;_id&quot;: 2 }, { &quot;_index&quot;:&quot;lagou&quot;, &quot;_type&quot;: &quot;job&quot;, &quot;_id&quot;: 1 } ] } # index一样 GET lagou/_mget { &quot;docs&quot;:[ { &quot;_type&quot;: &quot;job2&quot;, &quot;_id&quot;: 2 }, { &quot;_type&quot;: &quot;job&quot;, &quot;_id&quot;: 1 } ] } # index,type一样 GET lagou/job2/_mget { &quot;docs&quot;:[ { &quot;_id&quot;: 2 }, { &quot;_id&quot;: 1 } ] } GET lagou/job2/_mget { &quot;ids&quot;: [1,2] } bulk批量操作bulk操作不能分行，json必需一行写完 {&quot;index&quot;: {&quot;_index&quot;: &quot;zhilian&quot;, &quot;_type&quot;: &quot;job&quot;, &quot;_id&quot;: &quot;1&quot;}} {&quot;title&quot;: &quot;python分布式爬虫开发&quot;,&quot;salary_min&quot;: 15000,&quot;city&quot;: &quot;北京&quot;,&quot;company&quot;: {&quot;name&quot;: &quot;百度&quot;,&quot;company_addr&quot;: &quot;北京市软件园&quot;},&quot;publish_data&quot;: &quot;2019-5-30&quot;,&quot;comments&quot;: 23} {&quot;index&quot;: {&quot;_index&quot;: &quot;zhilian&quot;, &quot;_type&quot;: &quot;job&quot;, &quot;_id&quot;: &quot;2&quot;}} {&quot;title&quot;: &quot;爬虫开发&quot;,&quot;salary_min&quot;: 1500,&quot;city&quot;: &quot;太原&quot;,&quot;company&quot;: {&quot;name&quot;: &quot;阿里&quot;,&quot;company_addr&quot;: &quot;太原市软件园&quot;},&quot;publish_data&quot;: &quot;2019-5-30&quot;,&quot;comments&quot;: 23} bulk其他操作{&quot;index&quot;: {&quot;_index&quot;: &quot;test&quot;, &quot;_type&quot;: &quot;type1&quot;, &quot;_id&quot;: &quot;1&quot;}} {&quot;field1&quot; : &quot;value1&quot;} {&quot;delete&quot;: {&quot;_index&quot;: &quot;test&quot;, &quot;_type&quot;: &quot;type1&quot;, &quot;_id&quot;: &quot;2&quot;}} {&quot;create&quot;: {&quot;_index&quot;: &quot;test&quot;, &quot;_type&quot;: &quot;type1&quot;, &quot;_id&quot;: &quot;3&quot;}} {&quot;field1&quot; : &quot;value3&quot;} {&quot;update&quot;: {&quot;_index&quot;: &quot;index1&quot;, &quot;_type&quot;: &quot;type1&quot;, &quot;_id&quot;: &quot;1&quot;}} {&quot;doc&quot;:{&quot;field2&quot;: &quot;value2&quot;} elasticsearch映射# 创建索引 PUT lagou { &quot;mappings&quot;: { &quot;job&quot;:{ &quot;properties&quot;: { &quot;title&quot;:{ &quot;type&quot;: &quot;text&quot; }, &quot;salary_min&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;city&quot;:{ &quot;type&quot;:&quot;keyword&quot; }, &quot;company&quot;:{ &quot;properties&quot;: { &quot;name&quot;:{ &quot;type&quot;:&quot;text&quot; }, &quot;company_addr&quot;:{ &quot;type&quot;:&quot;text&quot; }, &quot;employee_count&quot;:{ &quot;type&quot;:&quot;integer&quot; } } }, &quot;publish_date&quot;:{ &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd&quot; }, &quot;comments&quot;:{ &quot;type&quot;: &quot;integer&quot; } } } } } PUT lagou/job/3 { &quot;title&quot;: &quot;python分布式爬虫开发&quot;, &quot;salary_min&quot;: &quot;abc&quot;, &quot;city&quot;: &quot;北京&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;百度&quot;, &quot;company_addr&quot;: &quot;北京市软件园&quot;, &quot;employee_count&quot;:50 }, &quot;publish_data&quot;: &quot;2019-5-30&quot;, &quot;comments&quot;: 15 } GET lagou/_mapping/job GET _all/_mapping/job","link":"/2019/12/28/Elasticsearch%E6%93%8D%E4%BD%9C/"},{"title":"Elasticsearch组合查询","text":"准备数据POST lagou/testjob/_bulk {&quot;index&quot;:{&quot;_id&quot;:1}} {&quot;salary&quot;:10, &quot;title&quot;: &quot;Python&quot;} {&quot;index&quot;:{&quot;_id&quot;:2}} {&quot;salary&quot;:20, &quot;title&quot;: &quot;Scrapy&quot;} {&quot;index&quot;:{&quot;_id&quot;:3}} {&quot;salary&quot;:30, &quot;title&quot;: &quot;Django&quot;} {&quot;index&quot;:{&quot;_id&quot;:4}} {&quot;salary&quot;:40, &quot;title&quot;: &quot;Elasticsearch&quot;} 组合查询bool查询 用 bool 包括 must should must_not filter 来完成，格式如下 filter 过渡字段 must 所有都要有 should 满足一个或多个 must_not 一个都不能满足 bool: { &quot;filter&quot;: [], &quot;must&quot;: [], &quot;should&quot;: [], &quot;must_not&quot; } filter查询 select * from testjob where salary=20 薪资为20k的工作 GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match_all&quot;:{} }, &quot;filter&quot;: { &quot;term&quot;: { &quot;salary&quot;: &quot;20&quot; } } } } } # 多个 GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;terms&quot;: { &quot;salary&quot;: [&quot;10&quot;, &quot;20&quot;] } } } } } # select * from testjob where title=&quot;Python&quot; # text字段会先分词，再全部转为小写入库 # term不会预处理，直接大写查询，但是倒排索引已经全部小写了 # 所以查不到，要不就用小写，要不就用match GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;term&quot;: { &quot;title&quot;:&quot;Python&quot; } } } } } bool组合过滤查询# 查询薪资等于20k或者工作为Python的工作，排除价格为30k的 # select * from testjob where (salary=20 OR title=&quot;Python&quot;) AND (salary !=30) GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;:[ {&quot;term&quot;: {&quot;salary&quot;:20}}, {&quot;term&quot;:{&quot;title&quot;:&quot;python&quot;}} ], &quot;must_not&quot;: [ {&quot;term&quot;:{&quot;salary&quot;:30}}, {&quot;term&quot;:{&quot;salary&quot;:10}} ] } } } # 嵌套查询 # select * from testjob where title=&quot;python&quot; or (title=&quot;django&quot; AND salary=40) GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;:[ {&quot;term&quot;: {&quot;title&quot;:&quot;python&quot;}}, {&quot;bool&quot;:{ &quot;must&quot;: [ {&quot;term&quot;: {&quot;title&quot;:&quot;elasticsearch&quot;}}, {&quot;term&quot;: {&quot;salary&quot;: 40}} ]} } ] } } } 过滤空和非空 # 建立测试数据 POST lagou/testjob2/_bulk {&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}} {&quot;tags&quot;:[&quot;search&quot;]} {&quot;index&quot;:{&quot;_id&quot;:&quot;2&quot;}} {&quot;tags&quot;:[&quot;search&quot;, &quot;python&quot;]} {&quot;index&quot;:{&quot;_id&quot;:&quot;3&quot;}} {&quot;orther_field&quot;:[&quot;some data&quot;]} {&quot;index&quot;:{&quot;_id&quot;:&quot;4&quot;}} {&quot;tags&quot;:null} {&quot;index&quot;:{&quot;_id&quot;:&quot;5&quot;}} {&quot;tags&quot;:[&quot;search&quot;, null]} # 处理非空值的方法 # select tags from testjob2 where tags is not NULL GET lagou/testjob2/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;exists&quot;: { &quot;field&quot;: &quot;tags&quot; } } } } }","link":"/2019/12/28/Elasticsearch%E7%BB%84%E5%90%88%E6%9F%A5%E8%AF%A2/"},{"title":"Elasticsearch配置","text":"安装 Java环境 Git 下载 elasticsearch-rtf 压缩包，解压 进入bin 运行 elasticsearch.bat Git clone elasticsearch-head 进入，npm install,npm run start 配置elasticsearch.yml http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; http.cors.allow-methods: OPTIONS, HEAD, GET, PUT, DELETE http.cors.allow-headers: &quot;X-Requested_With, Content-Type, Content_Length, X-User&quot; 安装 kibana ,版本与 elasticsearch相对应 elasticsearch概念 集群 节点 分片 副本 Elasticsearch Mysql index 数据库 type 表 documents 行(一条数据) fields 列","link":"/2019/12/28/Elasticsearch%E9%85%8D%E7%BD%AE/"},{"title":"Git 更新fork代码的内容","text":"前言公司有个开源项目需要维护，之前在校的时候和同学开发一个项目双方都是admin权限可以直接 push 到主分支，但一般来说新的代码还是通过 pr 的方式提交比较稳妥。现在遇到的问题是：这次我 pr 了以后，下次又改动代码 pr 的时候就要兼顾 fork 源的代码有没有更新，如果更新了这边不 pull 下来直接提交会引起冲突。以往的操作是如果 fork 源更新了代码，我就把自己仓库删掉重新 fork 一次。。。一次两次还好，后来无法忍受这种低能操作了，决定重新做人。 步骤其实解决这个问题很简单，只需要几个步骤即可：就拿我现在维护的项目来说 项目的地址是 rqalpha , 我 fork 以后的地址是 mar-heaven/rqalpha。 这时我在本地的 develop 分支改好代码准备提交，但是发现和 rqalpha 的 develop 分支是冲突的，因为在此期间又有了新的 commit。先看一下 remote (base) tangxinyingdeiMac:rqalpha xinglitao$ git remote -v origin https://github.com/mar-heaven/rqalpha.git (fetch) origin https://github.com/mar-heaven/rqalpha.git (push) 执行 git remote add upstream git@github.com:ricequant/rqalpha.git再看一下 (base) tangxinyingdeiMac:rqalpha xinglitao$ git remote -v origin https://github.com/mar-heaven/rqalpha.git (fetch) origin https://github.com/mar-heaven/rqalpha.git (push) upstream git@github.com:ricequant/rqalpha.git (fetch) upstream git@github.com:ricequant/rqalpha.git (push) fetch 一下 (base) tangxinyingdeiMac:rqalpha xinglitao$ git fetch upstream remote: Enumerating objects: 16, done. remote: Counting objects: 100% (16/16), done. remote: Compressing objects: 100% (10/10), done. remote: Total 16 (delta 10), reused 8 (delta 6), pack-reused 0 Unpacking objects: 100% (16/16), done. From github.com:ricequant/rqalpha * [new branch] 0.3.x -&gt; upstream/0.3.x * [new branch] 2.1.x -&gt; upstream/2.1.x * [new branch] 2.2.x -&gt; upstream/2.2.x * [new branch] 3.0.x -&gt; upstream/3.0.x * [new branch] 3.1.1.x -&gt; upstream/3.1.1.x * [new branch] 3.3.0.x -&gt; upstream/3.3.0.x * [new branch] 3.3.x -&gt; upstream/3.3.x * [new branch] 3.4.x -&gt; upstream/3.4.x * [new branch] develop -&gt; upstream/develop * [new branch] feature/broker_refactory -&gt; upstream/feature/broker_refactory * [new branch] feature/stat -&gt; upstream/feature/stat * [new branch] master -&gt; upstream/master 然后就可以 merge 了 (base) tangxinyingdeiMac:rqalpha xinglitao$ git merge upstream/develop Merge made by the 'recursive' strategy. rqalpha/mod/rqalpha_mod_sys_progress/mod.py | 8 ++++---- rqalpha/model/bar.py | 2 ++ rqalpha/utils/log_capture.py | 1 + 3 files changed, 7 insertions(+), 4 deletions(-) 收工！","link":"/2020/05/09/Git%20%E6%9B%B4%E6%96%B0fork%E4%BB%A3%E7%A0%81%E7%9A%84%E5%86%85%E5%AE%B9/"},{"title":"Github搜索开源项目方式","text":"前言作为全球最大的同性交友网站，Github 上有很多优秀的开源项目，使用正确的方式搜索可以很方便地找到自己需要的资源。 使用筛选的语法非常简单 # 按照项目名/仓库名搜索（大小写不敏感） in:name xxx # 按照README搜索（大小写不敏感） in:readme xxx # 按照description搜索（大小写不敏感） in:description xxx # stars数大于xxx stars:&gt;xxx # forks数大于xxx forks:&gt;xxx # 编程语言为xxx language:xxx # 最新更新时间晚于YYYY-MM-DD pushed:&gt;YYYY-MM-DD 举个例子，如果需要搜索一个基于 Django 的后台管理项目，可以通过以下方式，搜索仓库名包含 django 关键字并且项目描述中包含 后台 关键字。就是这么方便，当然可以通过更新时间来过滤一些不维护的项目。","link":"/2020/05/02/Github%E6%90%9C%E7%B4%A2%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%96%B9%E5%BC%8F/"},{"title":"Git设置代理","text":"Git代理开了VPN以后发现执行 git clone 还是不够快，经大佬指点发现还需要配置 git 的代理。 https://gist.github.com/evantoli/f8c23a37eb3558ab8765 git config –global http.proxy http://127.0.0.1:1087","link":"/2020/03/31/Git%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"title":"Linux 文件隐藏属性","text":"前言我们都知道 Linux 系统文件都有 r(read)/w(write)/x(execute) 三个属性，但是文件系统还提供了隐藏属性，这些隐藏属性非常实用，可以进一步起到对文件的保护作用。 chattr(配置文件隐藏属性)配置文件隐藏属性的指令是 chattr [+- - =][ASacdistu] 文件或目录名其中选项和参数如下: 选项与参数： + ：增加某一个特殊参数，其他原本存在参数则不动。 - ：移除某一个特殊参数，其他原本存在参数则不动。 = ：设定一定，且仅有后面接的参数 A ：当设定了 A 这个属性时，若你有存取此文件(或目录)时，他的访问时间 atime 将不会被修改，可避免 I/O 较慢的机器过度的存取磁盘。(目前建议使用文件系统挂载参数处理这个项目) S ：一般文件是异步写入磁盘的(原理请参考前一章 sync 的说明)，如果加上 S 这个属性时，当你进行任何文件的修改，该更动会『同步』写入磁盘中。 a ：当设定 a 之后，这个文件将只能增加数据，而不能删除也不能修改数据，只有 root 才能设定这属性 c ：这个属性设定之后，将会自动的将此文件『压缩』，在读取的时候将会自动解压缩，但是在储存的时候，将会先进行压缩后再储存(看来对于大文件似乎蛮有用的！) d ：当 dump 程序被执行的时候，设定 d 属性将可使该文件(或目录)不会被 dump 备份 i ：这个 i 可就很厉害了！他可以让一个文件『不能被删除、改名、设定连结也无法写入或新增数据！』对于系统安全性有相当大的帮助！只有 root 能设定此属性 s ：当文件设定了 s 属性时，如果这个文件被删除，他将会被完全的移除出这个硬盘空间，所以如果误删了，完全无法救回来了喔！ u ：与 s 相反的，当使用 u 来配置文件案时，如果该文件被删除了，则数据内容其实还存在磁盘中，可以使用来救援该文件喔！ 注意 1：属性设定常见的是 a 与 i 的设定值，而且很多设定值必须要身为 root 才能设定 注意 2：xfs 文件系统仅支援 AadiS 而已 admin@iZwz93u7y9mplneahfm5doZ:~$ cd /tmp/ admin@iZwz93u7y9mplneahfm5doZ:/tmp$ touch attrtest admin@iZwz93u7y9mplneahfm5doZ:/tmp$ chattr +i attrtest chattr: Operation not permitted while setting flags on attrtest admin@iZwz93u7y9mplneahfm5doZ:/tmp$ sudo chattr +i attrtest admin@iZwz93u7y9mplneahfm5doZ:/tmp$ sudo rm attrtest &lt;=此时sudo也就是root都无法删除了 rm: cannot remove 'attrtest': Operation not permitted admin@iZwz93u7y9mplneahfm5doZ:/tmp$ chattr -i attrtest chattr: Operation not permitted while setting flags on attrtest admin@iZwz93u7y9mplneahfm5doZ:/tmp$ sudo chattr -i attrtest &lt;=把i属性取消掉就可以删除了 admin@iZwz93u7y9mplneahfm5doZ:/tmp$ rm attrtest 其中最常用的就是 i 和 a 属性了，i 让一个文件无法修改，无法被删除，也不能被软链接，对系统安全性有很重要的意义。a 让一个文件只能增加数据，无法修改和删除数据。 lsattr(显示文件隐藏属性)显示隐藏属性的指令如下： lsattr [- adR] 文件 或者 目录选项与参数: -a ：将隐藏文件的属性也秀出来 -d ：如果接的是目录，仅列出目录本身的属性而非目录内的文件名 -R ：连同子目录的数据也一并列出来","link":"/2020/02/21/Linux%20%E6%96%87%E4%BB%B6%E9%9A%90%E8%97%8F%E5%B1%9E%E6%80%A7/"},{"title":"Linux文件属性","text":"前言以前一直只知道 chmod + 777 文件或者目录 就是把文件或者文件夹的权限提升到所有人都可以使用，至于为什么是 777 一直没有了解过，最近在看 《鸟叔的Linux私房菜-基础篇》，记录下这部分。 查看文件属性执行 ls -al 来查看一个目录下的文件和文件夹（包含隐藏的）属性。 分为七部分，以最后一行说明 -rw-r–r– 文件的类型权限，一共十个字母。第一个字母是文件类型， - 表示是个文件，d 表示是个目录。后面九个每三个分为一组，表示执行权限,[rwx]分别表示可读，可写，可执行：第一组是文件所有者的权限，第二组是此所有者所在的组权限，第三组是非本人且没有加入本人所在组的权限。 第二个为连接到此节点的链接数，包括硬链接和软链接 第三个是文件（目录）所属用户 第四个是文件所在的群组 第五个是文件大小 第六个是文件创建日期 第七个是文件名 改变文件属性和权限 chgrp: 改变文件所属群组 chown: 改变文件拥有者 chmod: 改变文件权限，SUID, SGID, SBIT 等等的特性 改变文件所属组chgrp users myblog.ini把 myblog.ini 文件所在组改为 uses，如果组不存在则会报错 改变文件的拥有者chown ginta myblog.ini把 myblog.ini 文件拥有者改为 ginta 改变文件的权限Linux文件一共有9个基本权限，分别是owner/group/others三个身份以及read/write/execute三个权限，三个三个为一组可以排列出9种权限。 r:4 w:2 e:1其中身份(owner/group/others)和权限(r/w/x)是累加的， 比如我们上边的 [-rw-r–r–] 就代表 owner = -rw = 0 + 4+2 =6 group = r– = 4 +0 + 0 = 4 others = r– = 4 + 0 + 0 = 4那么此文件的权限就是 644修改文件权限的命令是chmod 777 myblog.ini这条命令就是我之前无脑操作的，权限全开。 总结以前的文件操作方式相当于把文件整个暴漏给了其他人，可读可写！！无知是多么可怕~","link":"/2020/02/18/Linux%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7/"},{"title":"Python 线程池 ThreadPoolExecutor","text":"线程池以前我们定义多线程任务的时候都是通过循环来控制线程数量，很不优雅： import threading class MyThread(threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print(self.name) if __name__ == &quot;__main__&quot;: t_list = [] for i in range(4): name = &quot;线程-&quot; + str(i) t = MyThread(i, name, i) t.start() t_list.append(t) for t in t_list: t.join() 这样做当然也是可以的，不过一方面是代码有些难看，虽然逻辑上是清晰的，另外一方面是我们无法知道哪个线程完成了，而且控制并发的方式也仅限于给循环的变量不同，说白了还是看起来不舒服。 目标我们要寻求一种方式既可以实现多线程的效果，让代码看起来优雅一点。而且程序还可以知道哪些任务完成了 线程池Python3 的线程池是在 concurrent 包下的 ThreadPoolExecutor 来实现的现在我们写一个简单的线程池例子 from concurrent.futures import ThreadPoolExecutor, def get_html(times): time.sleep(times) print(&quot;get page {} success&quot;.format(times)) return times executor = ThreadPoolExecutor(max_workers=32) task1 = executor.submit(get_html, (3)) task2 = executor.submit(get_html, (2)) task3 = executor.submit(get_html, (3)) 如果我们想知道哪个任务执行完没有，可以用到 done() 方法 task1.done() 返回是 True 说明执行完了， False 说明没有执行完 在任务 还未开始 的时候我们可以使用 cancel 方法取消，如：task2.cancel() 通过 submit() 函数提交执行的函数到线程池中, 是立即返回，也就是说主线程还是在向下进行的。max_workers 参数是控制同时执行的最大任务数，这里我们有三个任务，但是最大任务数为 2。submit 有两个参数，一个就是所要执行的函数，一定不能加括号，另一个就是函数参数，这里哪怕只有一个参数也要像我这样括起来，不然会出问题！。由于max_workers 是2，一开始有两个在执行，如果有一个先执行完毕了，第三个任务才会开始执行。比起之前的 for 循环要好看不少。 如果有N个任务我们肯定不能一个个定义，用列表生成式就可以： # ... 其他代码 def get_html(url): time.sleep(times) print(&quot;get page {} success&quot;.format(times)) return times executor = ThreadPoolExecutor(max_workers=2) urls = [3,2,4] all_task = [executor.submit(get_html, (url) ) for url in urls] 高级我们想看看有多少个任务完成了，可以用 concurrent.futures 里的 as_completed(task) 方法，有一个参数可以是单独的 task 或者一个列表： # ... 其他代码 all_task = [executor.submit(get_html, (url) ) for url in urls] for future in as_completed(all_task): data = future.result() print(&quot;get {} page&quot;.format(data)) 我们的 task 返回值在 future.result() 中 as_completed 在遍历的时候如果有函数执行完了就会返回执行完的结果，以后的任务执行完一个这里就会返回一个，可以理解为 as_completed 会等待任务执行，比如我们这里在遍历的时候只有一个执行完了，那就只会打印一个，如果有第二个执行完了，它就会打印第二个，而且这个也不会影响到主线程。 等待如果我们想计算一下整个项目执行的时间，但是线程池不会阻塞主线程，就无法实现。 # ... 其他代码 start = time.time() all_task = [executor.submit(get_html, (url)) for url in urls] print(&quot;all tasks have done,used {}s&quot;.format(time.time()-start)) all tasks have done,used 0.0010027885437011719sget page 2 successget page 3 successget page 4 success 可以看到，任务开始以后主线程继续执行了，所以才会看到主线程的打印。 不过 concurrent.futures 给我们提供了一个 wait() 方法，可以让我们等待一个任务执行完，否则一直阻塞在当前位置，当然他也可以传一个列表： start = time.time() all_task = [executor.submit(get_html, (url)) for url in urls] wait(all_task) print(&quot;all tasks have done&quot;) get page 2 successget page 3 successget page 4 successall tasks have done,used 6.002103328704834s 可以看到，这里就会等待所有任务执行完主线程才会继续，至于为什么打印的是 6s 而不是最长线程所用的 4s，是因为我们前面设置了 executor = ThreadPoolExecutor(max_workers=2)，限制了它最大的并发数，也就是说 2s 后才会执行第三个任务所以用时就是 2s + 4s = 6s。","link":"/2019/12/20/Python%20%E7%BA%BF%E7%A8%8B%E6%B1%A0%20ThreadPoolExecutor/"},{"title":"Redis 数据保留","text":"Windows所谓数据丢失是因为 redis 有个专门保存数据的文件，而这个文件一开始是只读的，我直接把整个 Redis 文件夹的权限都开放给当前用户，这样退出时数据就会保留下来了。还有就是启动时要用redis-server.exe redis.windows.conf命令。","link":"/2019/11/27/Redis%20%E6%95%B0%E6%8D%AE%E4%BF%9D%E7%95%99/"},{"title":"Ubuntu系统安装redis","text":"前言一般爬虫是在 Ubuntu 系统下进行配置的，这次的任务就是在 Ubuntu 系统下安装 redis。 步骤 sudo apt-get install redis-server，遇到依赖包输入 Y 回车即可 启动，安装以后自动启动，可以查看 ps aux|grep redis 手动启动， sudo service redis-server start 停止， sudo service redis-server stop 卸载sudo apt-get purge --auto-remove redis-server Ubuntu连接Windows redis我这里 Windows 用的是本机 redis 服务，ubuntu 使用的虚拟机，也就是说是在同一个局域网下的，不同网络其实也差不多，连接其他服务器 redis 的命令是 redis-cli -h host -p port，比如我的 Windows 局域网 ip 是 192.168.199.168redis端口是 6379 ，那命令就是 redis-cli -h 192.168.199.168 -p 6379：ubunu 下：我们用 ubuntu 系统连接 Windows 系统 redis ，这里显示失败了，我们开 windows 的 redis 配置文件 redis.windows.conf 有这么一行意思是其他人访问 redis 的时候地址是这个，我们都知道 127.0.0.1 永远指向本机，当然不能访问成功了，我们改成本机地址就可以，一定是当前局域网的 ip，也就是 bind 一定是服务器的 ip 地址，而不是客户端的 ip，如果是 0.0.0.0 表示其他机器可以通过本机的所有网卡（一台电脑可能有多个网卡） ip 地址连接本机 redis:保存之后重启 windows 的 redis 服务，再用 ubuntu 连接一下：我们可以看到，成功了，并且访问 username 键，获得了它的值。","link":"/2019/11/27/Ubuntu%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85redis/"},{"title":"Windows10 docker desktop k8s","text":"##前言家里的台式机换了主板，cpu和内存之后流畅很多，图形化界面是 Windows 系统天然的优势，所以装了个 docker desktop，装完后发现可以一键安装k8s，果断开干。 虽说是一键，但还是有个小问题。一起在启动中，等了很久都没反应，猜测是因为依赖都是外网，需要开代理。我的本机代理端口是1080。最终成功安装！可能有细心的发现 k8s 版本变了，是因为我已经成功安装，看不到 starting 了，于是在网上找了一张，不过这不重要~ 2021.3.12docker pull 用的是https之前imac上的k8s一直无法启动，配置了 https 代理就好了。","link":"/2020/11/14/Windows10%20docker%20desktop%20k8s/"},{"title":"apscheduler","text":"引言apscheduler 可以拆分成两部分： aps: 进阶生产规划及排程系统 scheduler: 调度程序，日程安排程序 当程序希望某个函数每隔一段时间执行一次，或者某个函数在某天（每天）的某个时间执行，就可以引入 apscheduler 库。 from apscheduler.schedulers.blocking import BlockingScheduler import time def doing(): print(&quot;do doing!!&quot;) if __name__==&quot;__main__&quot;: sched = BlockingScheduler() # 1 sched.add_job(doing, 'interval', seconds=10) # 2 sched.start() # 3 实例化 BlockingScheduler 对象 添加任务 add_job() 函数4个常用参数，第一个是所要执行的函数第二个是触发器，可以定时触发，或者间歇性触发 date 日期：触发任务运行的具体日期 interval 间隔：触发任务运行的时间间隔 cron 周期：触发任务运行的周期第三个参数是在选择触发器以后设置的，比如scconds=10就是10s执行一次args用来给函数传参。args=[‘text’] 启动日程可以通过sched.add_job()启动多个定时任务后再执行整个调度器比如 import time from apscheduler.schedulers.background import BackgroundScheduler def func1(): print(&quot;func1&quot;) def func2(): print(&quot;func2&quot;) def func3(): print(&quot;func3&quot;) if __name__ == &quot;__main__&quot;: func_list = [func1, func2, func3] # 设置多个函数 sched = BackgroundScheduler() for index, func in enumerate(func_list): sched.add_job(func, 'interval', seconds=int(index)+1) sched.start() # 最后一次性启动 while True: time.sleep(1) print('*'*50)","link":"/2020/03/28/apscheduler/"},{"title":"django Signals","text":"前言在平时应用中我们经常遇到比如新增加一个用户就发送短信，新增加一条留言就给我们 发送邮箱 这种需求，一般来说都可以在视图函数中完成这些操作。但是如果有多个地方都需要类似的操作，比如用户在N个应用中都可以留言，如果在每个视图函数中都写一遍 发送邮箱 这种操作无疑是不明智的，好在 django 框架中内置了 signals(信号) 机制，可以辅助我们监听某些行为，比如 model 新增，或者请求前和请求后。 信号官方的信号主要分为以下几种，具体介绍详见 Django信号。 Model signals pre_init post_init pre_save post_save pre_delete post_delete class_prepared Management signals post_syncdb Request/response signals request_started request_finished got_request_exception Test signals template_rendered 举例这里举一个例子，官方推荐在应用目录下新增一个 signals.py文件 新建并注册app，我这里app名字是 signalapp 在app下方新建signals.py文件 修改 app下面的 apps.py # 原来 from django.apps import AppConfig class SignalappConfig(AppConfig): name = 'signalapp' # 现在 from django.apps import AppConfig class SignalappConfig(AppConfig): name = 'signalapp' def ready(self): # signals are imported, so that they are defined and can be used import signalapp.signals 编写 signals.py # signalapp/signals.py from django.dispatch import receiver from django.db.models.signals import post_save from signalapp.models import Post def send(): print(&quot;发送邮件&quot;) @receiver(post_save, sender=Post, dispatch_uid='Post_post_save') def send_email(instance, **kwargs): send() 然后重启服务，接下来在任意地方只要新建了 Post 实例并保存了，该函数都将在保存之后执行。与之相对应的是函数是 pre_save，显然，这是在保存前执行的。 receiver 装饰器有三个参数： 第一个是要监听的信号，我这里是 post_save 第二个是所要监听的模型，我这里是 Post 是文章模型，所以这个函数会在每次有文章保存（新建或者更新）的时候触发 post_save 在某个Model保存之后调用, 对于每个唯一的dispatch_uid,接收器都只被信号调用一次 这个信号的功能就是每次新建或者更改文章的时候发送一个邮件（邮件函数没写。。） 补充其他的可以参考文档，django 的文档写得确实很好，另外想说的就是 sender 不一定是模型，也可以是函数： import datetime import os import django from django.dispatch import receiver, Signal from django.http import HttpResponse # 发送信号 def signal_sender(request): hostname = request.get_host() msg = 'Django Signal Test' time = datetime.date.today() signal_obj.send(sender=signal_sender, hostname=hostname, msg=msg, time=time) # 关键一行 return HttpResponse('200 OK') # 接收和处理信号 @receiver(signal_obj, sender=signal_sender) # 装饰器把处理函数注册成接收器 def signal_handler(sender, **kwargs): # 接收到信号后，在此处理。kwargs字典用来传递Signal信号参数 print('接收到信号内容：{hostname}|&quot;{msg}&quot;|{time}'.format(hostname=kwargs['hostname'], msg=kwargs['msg'], time=kwargs['time']))","link":"/2019/11/27/django%20Signals/"},{"title":"django 图片储存七牛云","text":"前言每次给博客添加一篇文章的时候，上传图片的时候总要心痛一下，因为服务器的空间很有限，最主要的还是感觉把博客的图片和代码放到一个地方总有种污染代码的感觉，以前就听说了七牛云很方便，于是就用一下了。 开始首先我们要新建一个七牛云的储存空间，具体操作如下。进入这里，点击 对象存储新建存储空间 ，存储空间的名称随意就好，配置可以仿照这里图片这个样子，然后就OK了，对于新用户首先要实名认证，不过挺快的，我申请了2个小时不到就通过了。 使用 首先安装依赖包pip install django-qiniu-storage 然后 settings.py 配置新增如下 # 七牛云配置 QINIU_ACCESS_KEY = 'ACCESS_KEY' # 七牛给开发者分配的AccessKey QINIU_SECRET_KEY = 'SECRET_KEY' # 七牛给开发者分配的Secret QINIU_BUCKET_NAME = 'myblog' # 就是刚才新建的存储空间名称 # 用来存放文件的七牛空间(bucket)的名字 QINIU_BUCKET_DOMAIN = '*****.bkt.clouddn.com/' # 七牛空间(bucket)的域名，别遗漏了后面的/ DEFAULT_FILE_STORAGE = 'qiniustorage.backends.QiniuStorage' # 只用七牛托管动态生成的文件（例如用户上传的文件） QINIU_SECURE_URL = False # 使用http PREFIX_URL = 'http://' # 文件系统更改 MEDIA_URL = PREFIX_URL + QINIU_BUCKET_DOMAIN MEDIA_ROOT = 'media/' QINIU_BUCKET_DOMAIN 的位置如下 我的轮播图 model 如下 class Banner(BaseModel): STATUS_NORMAL = 1 STATUS_DELETE = 0 STATUS_ITEMS = ( (STATUS_NORMAL, '正常'), (STATUS_DELETE, '删除'), ) &quot;&quot;&quot; 轮播图 &quot;&quot;&quot; # upload_to 存储子目录，真实存放地址会使用配置中的MADIE_ROOT+upload_to image = models.ImageField(upload_to='banner', verbose_name='轮播图', null=True, blank=True, help_text=&quot;轮播图片的大小规格：1920x720，或者对应的比例的图片&quot;) name = models.CharField(max_length=150, verbose_name='轮播图名称') desc = models.CharField(max_length=250, verbose_name='描述信息', help_text=&quot;请填写描述信息&quot;) status = models.PositiveIntegerField(default=STATUS_NORMAL, choices=STATUS_ITEMS, verbose_name='状态') link = models.CharField(max_length=150, verbose_name='轮播图广告地址') class Meta: db_table = 'home_banner' verbose_name = '轮播图' verbose_name_plural = verbose_name def __str__(self): return self.name 注意 image 这个字段，我设置了 upload_to='banner' ，他就会保存到 MADIE_ROOT+’banner’ 这个路径下，而 MADIE_ROOT 在配置中是 MEDIA_URL = PREFIX_URL + QINIU_BUCKET_DOMAIN ,也就是 'http://*****.bkt.clouddn.com/'于是我们的轮播图图片就会保存到类似这样的url下：http://*****.bkt.clouddn.com/banner/20160923084104779_jAQ76Kw.jpg 总结基本操作就是这样了，因为网上有很多大佬已经踩过坑了，所以避免了不少麻烦。七牛云不止可以存储图片，也可以存储其他文件，CDN加速等等，以后有需要会补充上的。","link":"/2019/11/27/django%20%E5%9B%BE%E7%89%87%E5%82%A8%E5%AD%98%E4%B8%83%E7%89%9B%E4%BA%91/"},{"title":"django-allauth 阿里云发送邮件出现nginx 504解决方法","text":"前言在博客的认证中使用到了 django-allauth 模块进行用户注册登录，但是在注册环节配置邮箱系统的时候出了问题，搞了好几个小时终于解决了原来我的配置如下首先是github配置： Homepage URL: http://ginta.top/ Authorization callback URL: http://ginta.top/accounts/github/login/callback/ 这是settings.py django-allauth 配置 # django-allauth配置 ACCOUNT_EMAIL_VERIFICATION = 'mandatory' # 强制注册邮箱验证(注册成功后，会发送一封验证邮件，用户必须验证邮箱后，才能登陆) ACCOUNT_AUTHENTICATION_METHOD = &quot;username_email&quot; # 登录方式(选择用户名或者邮箱都能登录) ACCOUNT_EMAIL_REQUIRED = True # 设置用户注册的时候必须填写邮箱地址 ACCOUNT_LOGOUT_ON_GET = False # 用户登出(需要确认) # smtp 服务器地址 EMAIL_HOST = &quot;smtp.qq.com&quot; # 默认端口25，若请求超时可尝试465 EMAIL_PORT = 25 # 用户名 EMAIL_HOST_USER = &quot;.....@qq.com&quot; # 邮箱代理授权码（不是邮箱密码） EMAIL_HOST_PASSWORD = &quot;******&quot; # 发送人 EMAIL_FROM = &quot;.....@qq.com&quot; # # 默认显示的发送人，（邮箱地址必须与发送人一致），不设置的话django默认使用的webmaster@localhost DEFAULT_FROM_EMAIL = &quot;.....@qq.com&quot; 线下测试的时候没有问题，邮件也能发送，但是发布到阿里云上就是不行，一直出现邮件超时，也就是 nginx 504 的情况，网上有说把 nginx 超时时间改一下，我没尝试，一方面是因为默认已经是一分钟了，用户哪能等那么久，另一个是看到有说 25端口 在阿里云默认是关闭的，总之要进行一系列操作什么的，好在还可以用465端口，但是只把25端口改成465端口还是出现超时状态！！ ，后来有看到有加上一句 EMAIL_USE_SSL = True，于是试了一下，解决了。最后附上完整配置, github 配置不变，只改 settings.py 就好 ： # django-allauth配置 ACCOUNT_EMAIL_VERIFICATION = 'mandatory' # 强制注册邮箱验证(注册成功后，会发送一封验证邮件，用户必须验证邮箱后，才能登陆) ACCOUNT_AUTHENTICATION_METHOD = &quot;username_email&quot; # 登录方式(选择用户名或者邮箱都能登录) ACCOUNT_EMAIL_REQUIRED = True # 设置用户注册的时候必须填写邮箱地址 ACCOUNT_LOGOUT_ON_GET = False # 用户登出(需要确认) SOCIALACCOUNT_EMAIL_VERIFICATION = 'mandatory' # smtp 服务器地址 EMAIL_HOST = &quot;smtp.qq.com&quot; # 默认端口25，若请求超时可尝试465 EMAIL_PORT = 465 EMAIL_USE_SSL = True # 用户名 EMAIL_HOST_USER = &quot;***@qq.com&quot; # 邮箱代理授权码（不是邮箱密码） EMAIL_HOST_PASSWORD = &quot;****&quot; # 发送人 EMAIL_FROM = &quot;***@qq.com&quot; # # 默认显示的发送人，（邮箱地址必须与发送人一致），不设置的话django默认使用的webmaster@localhost DEFAULT_FROM_EMAIL = &quot;***@qq.com&quot;","link":"/2019/11/28/django-allauth%20%E9%98%BF%E9%87%8C%E4%BA%91%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E5%87%BA%E7%8E%B0nginx%20504%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"title":"django3 choices 新特性","text":"前言等了好久的 Django3 正式版本终于发布了！在看官方文档的时候看到有这么一句 Custom enumeration types TextChoices, IntegerChoices, and Choices are now available as a way to define Field.choices. TextChoices and IntegerChoices types are provided for text and integer fields 具体是什么意思呢，解释起来比较麻烦，还是上代码比较清晰： from django.db import models # Create your models here. class Student(models.Model): class Gender(models.IntegerChoices): MALE = 1 FEMALE = 2 gender = models.IntegerField(choices=Gender.choices) 这里新建了一个学生模型，里面只有一个性别字段。如果是以前的写法应该是这样： from django.db import models # Create your models here. class Student(models.Model): gender_choices = ( (1, '男'), (2, '女'), ) gender = models.IntegerField(choices=gender_choices) 直接看起来好像并没有方便多少，只是在内部新建了一个类而已，确实如此，不过还是有区别的，比如这里我们要求字段的值是 整数 ，新的写法会自动进行类型检查： class Student(models.Model): class Gender(models.IntegerChoices): MALE = &quot;ga&quot;, gettext_lazy('男') FEMALE = 2, gettext_lazy('女') gender = models.IntegerField(choices=Gender.choices) 如果我们这样写，MALE 的值改为 “ga”，在执行 python manage.py makemigrations 的时候会抛出以下错误： ValueError: invalid literal for int() with base 10: ‘ga’ 如果是以前的代码则不会报错。 这是后台显示，如果想显示中文也是可以的，把代码改成如下 from django.db import models from django.utils.translation import gettext_lazy # Create your models here. class Student(models.Model): class Gender(models.IntegerChoices): MALE = 1, gettext_lazy('男') FEMALE = 2, gettext_lazy('女') gender = models.IntegerField(choices=Gender.choices) 这就是效果了。如果是要求值是字符串，同理，只不过继承的类就不是 models.IntegerChoices ， 而是 models.TextChoices 。","link":"/2019/12/04/django3%20choices%20%E6%96%B0%E7%89%B9%E6%80%A7/"},{"title":"docker pull更换源","text":"前言每次使用docker pull的时候总是要等待很久，在不翻墙的情况下建议使用国内的源 步骤 在 /etc/docker/daemon.json 文件中添加以下参数（没有该文件则新建）： { &quot;registry-mirrors&quot;: [&quot;https://9cpn8tt6.mirror.aliyuncs.com&quot;] } 服务重启 systemctl daemon-reload systemctl restart docker","link":"/2020/08/30/docker%20pull%E6%9B%B4%E6%8D%A2%E6%BA%90/"},{"title":"do things matters","text":"最近在网上看到这么一句话，“do things matters”，后面的解释触发了共鸣： 这不仅意味着努力去核心岗位做重要的事情，还意味着每一件事都会因为是我做的，而 ‘matters’. 英雄联盟很多年前玩这个游戏的目的只有一个，上分。随着这款风靡全球的游戏流行，更多的玩家会选择在周末去网吧和朋友放飞自我，即使家用电脑已经普及，去网吧只是为了体验一种氛围。游戏机制导致天梯最多可以双人一起，因而大部分玩家更倾向于可以5人一起的匹配模式。同学几个人一起开黑的时候，我选择了单人Rank，而且选择相对较难的位置。室友曾经调侃：“你看我们大家一起玩多有意思，这游戏对于你来说简直就是孤儿游戏！” 每个人对游戏都有自己的理解，诚然游戏于大部分人来说只是一种释放压力的途径，我也一样，只是挑战更高难度对我来说也是十分重要的。 个体经济周末偶尔和朋友出门约饭，酒过三巡之后总要讨论一些时髦话题，比如哪个明星又怎样了，哪个国家政府被赶下去了，比特币最近又在作妖了……，不过此类话题基本都是几句带过，因为明星太过遥远，而币价也非我等韭菜可以操控的。最终个体经济这类话题占了上风，也往往会讨论很长时间，比如周边哪位同学的家里又帮忙购置不动产了，哪个亲戚又出国了。 对于家庭对个人的经济影响我始终保留自己的意见，天下家庭何其多，富甲终是少数，纵使家里没有条件给予更多的支持，亦或是可以包揽一切，由于着更多是上一辈人的结果，也就不会有更多的感触了。 do things matters维护一个开源项目，需要经常回答群里的问题，有人问过我：“为什么喜欢做开源”。 开源的话可以和很多用户沟通，他们会给出很多有趣的想法，有些建议是很有价值的，即使代码没有优化，修改之后产品本身对于用户也会更加友好。 不只是开源，即使是内部项目自己也是更希望能选择更有挑战性，反馈更多的项目去尝试，如果简单的事情太多了，也会和leader申请更具挑战的项目。 又回到开头的那句话了，“do things matters”。","link":"/2021/10/05/do%20things%20matters/"},{"title":"drf 一次错误排查","text":"前言在使用最新版本的 DRF 框架时，注册路由阶段报了一个错 “django.core.exceptions.ImproperlyConfigured: The included URLconf ‘bingo.urls’ does not appear to have any patterns in it. If you see valid patterns in the file then the issue is probably caused by a circular import.” 找了半天错误，期间反复查看官方文档都没有什么问题，最后使用删减排除了错误,原本用户的路由是这个 user_router.register(&quot;user&quot;, UserViewSet, base_name=&quot;user&quot;) 结果报错了，我改成以下代码： user_router.register(&quot;user&quot;, UserViewSet) 问题得到了解决，然而还是睡不着，这个参数在使用中还是很方便的，就这么删掉了肯定不好，于是上 github 查看了该项目的 issues，最后发现新版本的 base_name 已经被替换了： 于是把 base_name 改成了 basename，问题解决！","link":"/2020/02/12/drf%20%E4%B8%80%E6%AC%A1%E9%94%99%E8%AF%AF%E6%8E%92%E6%9F%A5/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/07/07/hello-world/"},{"title":"路明非","text":"衰小孩12345678910111、所谓弃族的命运，就是要穿越荒原，再次竖起战旗，返回故乡。死不可怕，只是一场长眠。在我可以吞噬这个世界之前，与其孤独跋涉，不如安然沉睡。我们仍会醒来。2、同一条路，和某些人一起走，就长得离谱，和另外一些人走，就短得让人舍不得迈开脚步。3、可人不是断气的时候才真的死了。有人说人会死三次，第一次是他断气的时候，从生物学上他死了；第二次是他下葬的时候，人们来参加他的葬礼，怀念他的一生，然后在社会上他死了，不再会有他的位置；第三次是最后一个记得他的人把他忘记的时候，那时候他才真正的死了。4、这个世界其实从不曾有一个人能取代另一个人的位置，所谓的取代，只是以前的那个人被遗忘了。5、比孤独更可悲的事情，就是根本不知道自己很孤独，或者分明很孤独，却把自己都骗得相信自己不孤独。6、不需要计划，在我们的战场上是没有计划的。用绝对的力量，抹掉它。","link":"/2021/07/07/first/"},{"title":"pathlib模块用法","text":"前言Python 中对于路径处理有一个 os.path 模块，基本上所有常见的需求都可以满足，不过也有一些弊端 import os.path BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) TEMPLATES_DIR = os.path.join(BASE_DIR, 'templates') 以上用法在 Django 项目中应该是十分常见的，阅读起来非常不方便。 福利在 python3.5 之后引入了一个新的内置包 pathlib。有了它很多操作都会变得简单明了，直接上代码：上述的例子如果用 pathlib 可以写成如下样子： from pathlib import Path BASE_DIR = Path(__file__).resolve().parent.parent TEMPLATES_DIR = BASE_DIR.joinpath('templates') 其他用法： # 路径拼接 Path('D:/test','pb','123.txt') # WindowsPath('D:/test/pb/123.txt') # 分割路径 from pathlib import PurePath p = PurePath('/usr/bin/python3') p.parts # ('\\\\', 'usr', 'bin', 'python3') # 获取指定类型的文件 p = Path('.') list(p.glob('*.py')) # [WindowsPath('day_close_not_equal_min.py'), WindowsPath('day_h5.py'), WindowsPath('local_run.py'), WindowsPath('min_h5.py'), WindowsPath('min_h5_1.py'), WindowsPath('prev_iopv2tick.py'), # # # # WindowsPath('read_h5.py'), WindowsPath('repair_close.py'), WindowsPath('rep_nan.py 结语基本上 os.path 中常用的方法在 pathlib 都可以找到，而且面向对象的思想更容易被理解，代码也会相对清晰一些。","link":"/2020/05/07/pathlib%E6%A8%A1%E5%9D%97%E7%94%A8%E6%B3%95/"},{"title":"plan","text":"Vue vue-element-admin FastAPI cookiecutter-fastapi","link":"/2020/04/27/plan/"},{"title":"pipenv 使用","text":"前言以前做开发的时候一直使用的 virtualenv 作为虚拟环境库，当时也知道有其他工具，只是一直没有了解，在做项目的时候看到网上有一篇文章可以解决项目依赖库的问题：比如说，之前有个项目开发使用的是 django1.10 版本，但是使用 pip freeze &gt;requirements.txt 命令生成的文件中只有 django 没有具体哪个版本（现在貌似具体到版本了…），或者每次启动虚拟环境的时候都要输入一系列操作，现在只需要 pipenv shell 就可以了！ 安装 Windows系统下直接输入 pip install pipenv就可以了 Ubuntu 系统下可能涉及到环境变量问题:具体步骤如下 运行python3 -m site(如果使用默认的可以运行 python -m site，这里我是python3)然后找到 USER_BASE: ‘/root/.local’ (exists) ，然后在 ~/.profile 最后一行加入export PATH=$PATH:/root/.local/bin我是ubuntu系统，mac或者其他系统的 profile 文件到网上找找，最后执行 source ~/.profile 就可以了 使用在任何地方执行 pipenv install django ，pipenv 会自动生成2个文件，分别是 Pipfile 和 Pipfile.lock ， Pipfile.lock 文件就会自动配置好 django 框架了： &quot;default&quot;: { &quot;django&quot;: { &quot;hashes&quot;: [ &quot;sha256:4025317ca01f75fc79250ff7262a06d8ba97cd4f82e93394b2a0a6a4a925caeb&quot;, &quot;sha256:a8ca1033acac9f33995eb2209a6bf18a4681c3e5269a878e9a7e0b7384ed1ca3&quot; ], &quot;index&quot;: &quot;pypi&quot;, &quot;version&quot;: &quot;==2.2.6&quot; }, ....其他内容 激活虚拟环境的命令是 pipenv shell，需要注意的是，如果激活后使用 pip install flask 则只会在虚拟环境中安装 Flask 框架，并不会写入到 Pipfile.lock 配置中，如果想写入配置则执行 pipenv install flask 命令，然后如果需要生成 requirements.txt 文件则执行 pipenv lock -r &gt; requirements.txt 命令，只会打包 Pipfile.lock文件中的package。 最后一般来说在项目根目录下生成 Pipfile 和 Pipfile.lock 文件，方便后续操作，比如执行 docker 命令什么的都可以很简单安装好一个项目的依赖。","link":"/2019/11/27/pipenv%20%E4%BD%BF%E7%94%A8/"},{"title":"supervisor + pipenv + uwsgi","text":"前言目前我部署 django 项目的方式是 uwsgi + nginx ，uwsgi 重启也很方便，只需要写一句 uwsgi –reload xxx.pid 即可，但是即使是一句我也不想输入了，就是比较懒，于是乎就有了 supervisor 管理 uwsgi 进程，配置好以后通过 web 网页点一下即可。 开始至于怎么配置 uwsgi 网上教程有很多，这里只讲一下怎么用 supervisor 启动。通过网上的教程可以先安装好 supervisor ，我这里有一篇 ubuntu python3 配置 supervisor 可供参考。我的 supervisor 配置目录结构如下： supervisor/ ├── conf.d │ ├── myblog.ini # 自己配的 ├── supervisord.conf # 初始化生成的配置文件（一开始就有，网上可以找到如何生成） └── var ├── log │ ├── myblog-stderr.log # 后续生成的 │ ├── myblog-stdout.log # 后续生成的 │ └── supervisord.log # 后续生成的 ├── supervisord.pid # 后续生成的 └── supervisor.sock # 后续生成的 supervisor 文件夹是在 /etc 下面。首先配置 supervisor/supervisord.conf 文件，有几个地方改了一下： 让 socket 文件生成在 ~/etc/supervisor/var/ 目录下。注意 supervisor 不支持将 ~ 展开为用户 home 目录，所以要用绝对路径指定。我这里是 root 用户，这样直接写就可以，其他用户的路径类似于 /home/username/etc/supervisor…** [unix_http_server] file=/etc/supervisor/var/supervisor.sock ; the path to the socket file 修改 [inet_http_server] ，这一步主要是可以通过外部浏览器来进行控制 supervisor 进程，其中 端口号像我这样配置成 port=*:9001 ，就可以在外网通过服务器的域名下的 9001 端口来控制，默认是没有密码的，但是最好配置一下 [inet_http_server] ; inet (TCP) server disabled by default port=*:9001 ; ip_address:port specifier, *:port for all iface ;username=user ; default is no username (open server) ;password=123 ; default is no password (open server) 类似的修改 [supervisord] 板块下的 logfile 和 pidfile 文件的路径，还有 user 改为系统用户，这样 supervisor 启动的进程将以系统用户运行，避免可能的权限问题,**注意 supervisor 不支持将 ~ 展开为用户 home 目录，所以要用绝对路径指定。我这里是 root 用户，这样直接写就可以，其他用户的路径类似于 /home/username/etc/supervisor…**： [supervisord] logfile=/etc/supervisor/var/log/supervisord.log ; main log file; default $CWD/supervisord.log pidfile=/etc/supervisor/var/supervisord.pid ; supervisord pidfile; default supervisord.pid user=root ; setuid to this UNIX account at startup; recommended if root [supervisorctl]板块下： [supervisorctl] serverurl=unix:///etc/supervisor/var/supervisor.sock ; use a unix:// URL for a unix socket [include] 版块,将 /etc/supervisor/conf.d/ 目录下所有以 .ini 结尾的文件内容包含到配置中来，这样便于配置的模块化管理。 [include] files = /etc/supervisor/conf.d/*.ini 配置 管理uwsgi进程 的配置文件在 /etc/supervisor/conf.d/ 目录下新建一个配置文件，名字以 .ini 结尾就好，是因为我们在 supervisor.conf 文件中修改了配置 [include] ，所以 supervisor 会搜索 /etc/supervisor/conf.d/ 目录下所有以 .ini 结尾的文件。这是我的配置文件 [program:myblog] command=pipenv run uwsgi --ini /root/mysite_uwsgi/myblog.ini directory=/root/code/Workspace/ginta.top autostart=true autorestart=unexpected user=root stdout_logfile=/etc/supervisor/var/log/myblog-stdout.log stderr_logfile=/etc/supervisor/var/log/myblog-stderr.log program:hellodjango-blog-tutorial] 指明运行应用的进程，名为 hellodjango-blog-tutorial。 command 为进程启动时执行的命令， 我的环境是用 pipenv 来进行包管理的所以要这样执行，如果没有用包管理直接执行 uwsgi --ini /root/mysite_uwsgi/myblog.ini 即可，也就是 uwsgi 的启动命令。 directory 指定执行命令时所在的目录。 autostart 随 Supervisor 启动自动启动进程。 autorestart 进程意外退出时重启。 user 进程运行的用户，防止权限问题。 stdout_logfile，stderr_logfile 日志输出文件。6. 启动 Supervisor supervisord -c ~/etc/supervisord.conf 进入 supervisorctl 进程管理控制台： supervisorctl -c ~/etc/supervisord.conf 执行 update 命令更新配置文件并启动应用。 浏览器输入域名，可以看到服务已经正常启动了。 注意 由于我们 supervisor 有配置项目的日志，所以如果在 uwsgi.ini 中配置有日志，请把它注释掉 # myblog.ini （项目的uwsgi配置） # daemonize = /root/mysite_uwsgi/myblog.log # 日志管理 如果之前就已经运行了 uwsgi，请一定要先退出再重启 supervisor supervisor/supervisord.conf 文件的注释符号是 **;**，比如 *;[eventlistener:theeventlistenername]*，所以我们所有的配置前面如果有 ; ，请删掉，比如把 ;[eventlistener:theeventlistenername] 改成 [eventlistener:theeventlistenername] ，不然会视作没有配置。 本文配置参考了追梦人物的博客。","link":"/2019/11/20/supervisor%20+%20pipenv%20+%20uwsgi/"},{"title":"ubuntu python3.7 安装uwsgi 常见错误","text":"前言由于需要在 ubuntu18.04 系统部署 django 项目，用到了 uWSGI 库，在安装的时候遇到了几个问题在这里记录一下原因，并附上解决方法。 Retrying (Retry(total=4, connect=None….这是比较常见的问题，原因是安装超时，因为我们下载的库的源一般都是在国外，涉及到翻墙问题，解决方法是更换国内的源，注明的有阿里，豆瓣等，这里我用到的是豆瓣源:pip install -i https://pypi.doubanio.com/simple uwsgi前面 -i 是指明更换源路径，最后的 uwsgi 就是本次我要安装的 uWSGI 库 error: invalid command ‘bdist_wheel’这个问题一般是 pip 版本比较老了，更新一下即可尝试用以下命令升级以下pip版本后再试一下:python -m pip install –upgrade pip如果装着python3.X ，那么就用:python3 -m pip install –upgrade pip fatal error: Python.h网上说的是因为环境不完整，安装如下这个包：python2：sudo apt-get install python-devpython3:sudo apt-get install python3-dev确实是这个问题，不过可能是我的 python 版本比较新吧，是 python3.7.2 ，也可能是其他原因总之最后安装 uWSGI 还是失败了，网上还有一个库是真的比较新版本的 python3.7+ ：sudo apt install python3.7-dev安装成功~","link":"/2019/11/27/ubuntu%20python3.7%20%E5%AE%89%E8%A3%85uwsgi%20%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"},{"title":"ubuntu 部署 django2.0 + uwsgi + nginx","text":"django 默认的服务是单进程的，而且处理静态文件也比较慢，我们采用 django + uwsgi + nginx 来提高并发数的同时减少静态文件的访问时间。 nginx 安装nginxapt-get install nginx 进入 /etc/nginx 路径下可以看到两个文件夹，sites-available 和 sites-enabled，前者是网站的可用配置文件夹，后者是启用的配置，一般都是把配置文件放到 sites-available 再通过软链接的方式在 sites-enabled 中启用配置。 进入 sites-available 文件夹中，新建配置文件arrange.conf，内容如下 server { listen 80; # 网站对外的端口为80 server_name ginta.top; # 服务名字（一般是用域名方便理解） charset utf-8; # 字符编码 client_max_body_size 75M; # 上传文件的最大尺寸 location /static { alias /home/admin/code/Workspace/arrange/static; # 静态文件的访问路径 } location /media{ alias /home/admin/code/Workspace/arrange/media; # 媒体资源的访问路径 } location / { # 发送请求给django，nginx处理不了，我们要转发给uwsgi，除了 static 和 media 其他的转发给uwsgi uwsgi_pass 127.0.0.1:8001; include /etc/nginx/uwsgi_params; # uwsgi协议配置文件，类似于nginx.conf，django没有，但是nginx下有个这样的文件 } } 删除 sites-enabled 文件夹下的default文件，否则服务可能无法启动，卡在nginx欢迎界面 uWSGI 安装uWSGI，可能出现的错误在这里有 解决方式. pip install uwsgi2. 测试，创建一个 foobar.py 的文件，内容如下 : def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return [b&quot;Hello World&quot;] 然后通过服务器的 9090 端口进行测试uwsgi --http :9090 --wsgi-file foobar.py访问成功即可。3. 编写项目uwsgi配置文件然后选择一个目录新建个文件作为项目的 uwsgi 配置文件,我这里是 arrange.ini [uwsgi] chdir = /home/admin/code/Workspace/arrange # 项目的绝对路径 virtualenv = /home/admin/code/Envs/blog # 我这里用的是虚拟环境 module = arrange.wsgi:application # 项目的wsgi，我的项目名是 **arrange** master = True # 启动主程序 processes = 4 # 使用的进程数 harakiri = 60 # 请求60s超时关闭 max-requests = 5000 # 请求超过5000进程重启防止内存泄漏 socket = 127.0.0.1:8001 # 监听的端口 uid = nginx # 使用nginx代替root用户 （安全一些） gid = nginx # 使用nginx代替root用户 pidfile = /home/admin/mysite_uwsgi/master.pid # 通过 pidfile 对主进程进行关闭，启动或者重启操作 daemonize = /home/admin/mysite_uwsgi/arrange.log # 指定日志存放路径 vacuum = True # 当服务器关闭会自动把pidfile和daemonize进程回收 启动项目uwsgiuwsgi --ini arrange.ini 进入 /etc/nginx/ 路径，简历配置文件软链接sudo ln -s /etc/nginx/sites-available/arrange.conf /etc/nginx/sites-enabled/arrange.conf 测试一下nginx有没有问题sudo nginx -t出现 successful 表示没有问题 重启nginxsudo service nginx restart 补充uwsgi 重启服务,由于我们配置了pidfile路径，所以可以很快捷地重启uwsgi --reload /home/admin/mysite_uwsgi/master.pid想看看启动没有可以通过 ps 指令ps -aux | grep uwsgi","link":"/2019/11/27/ubuntu%20%E9%83%A8%E7%BD%B2%20django2.0%20+%20uwsgi%20+%20nginx/"},{"title":"win10 osg.js 使用","text":"引言有位朋友希望可以在win10上部署一个 osg.js 服务，虽然在这之前我也没用过 osg.js ，不过看了下官方基本的 doc，由于是涉及到美术行业内容不是很懂，不过部署貌似也不复杂。 安装依赖该工程一共需要2个依赖，一个是 Git ，另外就是 npm。首先安装 Git ，点击此处的下载链接下载安装包，一直下一步就好。其次安装 npm，这里参考廖雪峰教程就可以。 下一步这是官方链接，部署非常简单，首先在电脑上安装一个 git 把代码 clone 下来，找一个存放工程的目录，右键，点击 Git Bash Here： 然后执行 $ git clone git://github.com/cedricpinson/osgjs.git，接下来就可以在目录下看到一个 osgjs 文件夹。接下来进入这个文件夹 $ cd osgjs/，依次执行四条命令： npm install -g grunt-cli npm install grunt build grunt serve不出意外可以看到这个界面 打开浏览器访问 http://localhost:9000/ ，然后就可以体验了 虽然不是这个方向，但感觉还是挺不错的。 小结整个过程还是挺简单的，最费时间的是执行 grunt serve 这一步，因为要从其他仓库下载模型，而且还是外网，所以非常耗时，建议采用 科学上网 的方式执行。我当时执行这一步的时候真的是失败了N次，但是想着答应要尽力的，最终还是耐心多尝试，最后成功了，挺高兴的。","link":"/2019/12/03/win10%20osg.js%20%E4%BD%BF%E7%94%A8/"},{"title":"windows 安装 helm","text":"安装到 helm的Github仓库 找到解压后把这个目录加入环境变量就可以了","link":"/2021/07/01/windows%20%E5%AE%89%E8%A3%85%20helm/"},{"title":"windows终端命令行下使用网络代理","text":"右键打开 ShadowsocksR 的 选项设置 设置你的HTTP和HTTPS的代理端口 打开cmd窗口，设置代理变量 set HTTP_PROXY=http://127.0.0.1:1080 set HTTPS_PROXY=http://127.0.0.1:1080 如果设置了用户名和密码 set HTTP_PROXY=http://proxy.com:port set HTTP_PROXY_USER=username set HTTP_PROXY_PASS=password set HTTPS_PROXY=http://proxy.com:port set HTTPS_PROXY_USER=username set HTTPS_PROXY_PASS=password 上面命令的作用是设置环境变量，不用担心，这种环境变量只会持续到cmd窗口关闭，不是系统环境变量。 如何取消代理呢: netsh winhttp reset proxy","link":"/2020/05/05/windows%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E4%BD%BF%E7%94%A8%E7%BD%91%E7%BB%9C%E4%BB%A3%E7%90%86/"},{"title":"wsl2 安装 Centos8","text":"前言由于开发需要安装 centos 版本的 wsl， 但 Windows Store 里只有 Ubuntu、Debian 等 kernel，好消息是 Github 上可以找到对应版本的安装包。 安装 ChocolateyNuGet（读作New Get）是用于微软.NET开发平台的软件包管理器，是一个Visual Studio的扩展。Chocolatey 是基于 NuGet 的一个软件包管理器，就像 Linux 中的 yum 或 apt 一样，在 Windows10 中也可以用命令行安装程序了。 右键单击开始菜单，选择 Windows PowerShell(管理员)，打开一个具有管理员权限的 PowerShell 窗口，输入命令并回车： 1Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) 完成后，输入命令：choco ，如果能正确显示版本号，说明安装成功。 详情请查看官网文档安装说明 LxRunOffline 是非常实用的 WSL 管理软件，可以备份、创建、恢复、导出WSL子系统，也可以安装适配 WSL 的任何 Linux 发行版，可以将 WSL 子系统安装到任意目录中。在 PowerShell 窗口中输入命令安装LxRunOffline，安装完成后重启 PowerShell。 1choco install lxrunoffline -y 安装 Centos8 wsl打开链接，这里直接下载 CentOS8-stream.zip ，解压后会发现有一个 rootfs.tar.gz 文件，使用 lxrunoffline install -n CentOS -d F:/centos -f E:\\CentOS8-stream\\rootfs.tar.gz 命令来安装，其中 -d 后面是 kernel 想要安装到的位置，**-f** 的参数是 rootfs.tar.gz 的所有路径。然后将这个发行版设置为 WSL2：wsl --set-version CentOS 2 换源由于默认源都用的国外安装路径，下载东西很慢，需要换成阿里源 备份原文件123456cd /etc/yum.repos.dmv CentOS-Base.repo CentOS-Base.repo.bakmv CentOS-extras.repo CentOS-extras.repo.bakmv CentOS-centosplus.repo CentOS-centosplus.repo.bakmv CentOS-PowerTools.repo CentOS-PowerTools.repo.bakmv CentOS-AppStream.repo CentOS-AppStream.repo.bak 下载12# wget -O CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repovi CentOS-Stream-BaseOS.repo 这里有两点需要解释一下，目前安装的 centos8 没有内置 wget 和 vim ，不过上边只是一个文件，可以用 windows 下载完之后将里面的内容复制一下，然后粘贴到 CentOS-Stream-BaseOS.repo 保存就好。 删除缓存并生成新的缓存12dnf clean alldnf makecache wsl2配置使用windows网络代理我想要在 wsl2 上安装 helm ，脚本中有需要访问外网，这就需要一个代理。不过我的 windows 已经有代理了，只需要让它使用 windows 的代理就好。 wsl2获取win10 ip cat /etc/resolv.conf|grep nameserver|awk ‘{print $2}’ =&gt; 例如：172.20.192.1注：由于windows防火墙的存在，此时可能出现ping 172.20.192.1失败 新建防火墙入站规则 打开控制面板\\系统和安全\\Windows Defender 防火墙 点击入站规则-&gt;新建规则 规则类型：自定义 程序：所有程序 协议和端口：默认即可 作用域： 本地ip处选择“任何IP地址” 远程ip处选择“下列IP地址”，并将wsl2的IP添加进去。（请根据自己wsl2的ip进行计算，我这里添加了172.20.192.1/20）（掩码一般是20位） 操作：允许连接 配置文件：三个全选 名称描述：请自定义 注意：这一步完成后，从wsl2 ping主机的ip应该可以ping通了。 防火墙配置 打开控制面板\\系统和安全\\Windows Defender 防火墙\\允许的应用。 将与代理相关的应用程序均设置为：允许其进行专用、公用网络通信。 特别注意的是：将Privoxy也配置为允许 windows端代理软件配置 启用“允许来自局域网的连接” 测试 在wsl2中配置http代理，如export http_proxy=”http://172.20.192.1:1080&quot;。注意：端口号请结合自己的代理设置进行修改 执行命令curl cip.cc查看ip地址 部分资料参数文章 arp命令 centos 安装_WSL2子系统安装CentOS8及源码编译Nginx1.18+PHP7.4+MySql8.0开发环境… wsl2配置使用windows网络代理","link":"/2021/07/04/wsl2%20%E5%AE%89%E8%A3%85%20Centos8/"},{"title":"《大秦帝国》终于到了","text":"NNQI前天下单的书终于到了！！！ 一度上次看《大秦帝国》 还是在四川。那时周末会在成都图书馆做志愿者，一般休息的时候都会看看杂志，读者、格言、意林、青年文摘，有时也会看看达芬奇和梵高的作品，虽然始终无法领会他们的境界。偶尔到借阅区转了一圈，就在书架最上层看到了一本《大秦帝国》，当时第一部已经外借出去了，只留下一本第二部的“国命纵横”，大致翻了一下感觉还行，讲的是纵横家苏秦和张仪各自选择不同的国家实现自己的抱负，书中用词没有让我感到浮夸的地方，整体印象就是行文恰到好处。回家的时候顺便也就借走了，不过那一个月也比较忙，没看完就还回去了。 二重平时在公司午休的时候也基本都是看看杂志，周末的话会多睡几个小时。一段时间没有认真地阅读一部小说总是会感到有些不安，前两天考虑了一下还是决定把之前没有读完的《大秦帝国》通读一遍，至于读完以后再买什么书就是之后的事情了。 当我还是个孩子的时候，我吃过很多食物，现在已经记不起来吃过什么了。但可以肯定的是，它们中的一部分已经成长为我的骨头和肉。 –三毛","link":"/2020/04/02/%E3%80%8A%E5%A4%A7%E7%A7%A6%E5%B8%9D%E5%9B%BD%E3%80%8B%E7%BB%88%E4%BA%8E%E5%88%B0%E4%BA%86/"},{"title":"仿佛重生","text":"就在一个小时前整个人都感觉不好了，现在好像又活过来了。服务器上竟然有一个当初为了迁移方便的压缩包！！","link":"/2020/03/27/%E4%BB%BF%E4%BD%9B%E9%87%8D%E7%94%9F/"},{"title":"写了个脚本把以前的博客从sqlite转成md","text":"前言以前的博客是用 django 写的，现在要迁移到 hexo 了，于是乎简单粗暴的写了个脚本把 sqlite3 数据转换成了文件。有几点需要改进 脚本暴力过滤了所有异常数据，虽然没有一个是异常的 封面图全部是一样的，其实可以随机生成的 文章只生成了分类，其实tags也可以生成的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import datetimeimport sqlite3conn = sqlite3.connect('db.sqlite3')print(conn)cur = conn.cursor()CATEGORY_MAP = {}template = &quot;&quot;&quot;---title: {}date: {}author: Gintaimg: /medias/images/mingfei.jpgtop: falsehide: falsecover: falsecoverImg: /medias/images/mingfei.jpgtoc: falsemathjax: falsesummary:categories: {}---&quot;&quot;&quot;sql = &quot;SELECT * FROM blog_category&quot;categories = cur.execute(sql)for category in categories: category_id = category[0] category_title = category[3] CATEGORY_MAP[str(category_id)] = category_titleprint(CATEGORY_MAP)sql = &quot;SELECT * FROM blog_post&quot;res = cur.execute(sql)for post in res: date = post[2] create_date = datetime.datetime.fromisoformat(date).strftime(&quot;%Y-%m-%d %H:%M:%S&quot;) post_category = post[-4] title = post[3] content = post[4] head = template.format(title, create_date, CATEGORY_MAP[str(post_category)]) try: f = open(title+ '.md', 'w', encoding=&quot;utf-8&quot;) f.write(head+content) f.close() except: print(title)","link":"/2021/07/08/%E5%86%99%E4%BA%86%E4%B8%AA%E8%84%9A%E6%9C%AC%E6%8A%8A%E4%BB%A5%E5%89%8D%E7%9A%84%E5%8D%9A%E5%AE%A2%E4%BB%8Esqlite%E8%BD%AC%E6%88%90md/"},{"title":"删除排序数组中的重复项","text":"给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。 不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。 给定数组 nums = [1,1,2],函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。你不需要考虑数组中超出新长度后面的元素。 思路使用双游标方法 flag 来记录当前数组不重复的位置，而变量 j 控制整个数组的遍历；当 flag 位置的数据和 j 位置的数据不同时则说明有新的，也就是有效变量进入，此时 flag 加 1，同时也要把 j 位置的值给 flag 位置。 class Solution: def removeDuplicates(self, nums: List[int]) -&gt; int: flag = 0 for j in range(1, len(nums)): if nums[j] != nums[flag]: flag += 1 nums[flag] = nums[j] return flag+1","link":"/2019/12/21/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"title":"围棋第一次胜局","text":"心血来潮前几天弟弟说考试比上次进步了，想让得到茫茫多的零食大礼包作为鼓励。考虑到现在的学生也是蛮辛苦的，于是果断奖励了三本课外书，除了《活着》是应付老妈的，《禁区法则》和《天局》一如既往地中二。其中《天局》讲的就是凡人与天人下围棋最终以半子取胜的故事。 入门给他普及了《天局》故事后顺手就下了个围棋app，百度了一下教程就算入门了。开始是和玩家对弈，想了想不恶心别人了，就人机互啄，难度从入门级降到了儿童级。几天之内下了10几局吧，无一例外全输了，直到今天晚上，终于赢了一局，万分感动。附上图以作记录 其他想说的事实证明围棋入门并不难，只是想要精通还是不容易的。比较考验大局观，一子的得失有时候并不重要，总之能赢第一局还是挺高兴的。","link":"/2021/07/08/%E5%9B%B4%E6%A3%8B%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%83%9C%E5%B1%80/"},{"title":"数据库定时备份任务","text":"前言最近因为一次误操作不小心把博客的数据库文件删除了，当时感觉自然是难受的。不过幸运的是之前移动博客文件的时候曾把数据和项目打包了，所以文件又找回来了！！！虽然文件是找回来了，不过这种情况难免再次发生，而且下次就不一定能找回来了。于是决定写一个定时任务每天备份一下数据库文件。 使用的第三方库是 apscheduler，简单的介绍可以看 apscheduler，更具体的请参考 文档 代码如下： # backup_db.py import os import datetime from apscheduler.schedulers.blocking import BlockingScheduler file_path = &quot;/root/Workspace/ginta.top/myblog/myblog/db.sqlite3&quot; backup_dir = &quot;/root/data/backup_blog_db&quot; def backup_db(file_path, backup_dir): now = datetime.datetime.now() date = datetime.datetime.strftime(now, &quot;%Y-%m-%d&quot;) backup_dir = os.path.join(backup_dir, date) os.system(&quot;mkdir {}&quot;.format(backup_dir)) backup_file_dir = os.path.join(backup_dir) os.system(&quot;cp {} {}&quot;.format(file_path, backup_file_dir)) print(&quot;{} backup_finished&quot;.format(date)) if __name__ == &quot;__main__&quot;: print(&quot;backup_script start!&quot;) sched = BlockingScheduler() sched.add_job(backup_db, 'interval', [file_path, backup_dir], seconds=60 * 60 * 24) sched.start() 然后执行 nohup python -u backup_db.py &gt; /root/data/log/back_db/backup_db.log 2&gt;&amp;1 &amp; 就放到后台了 总结实现了每天定时备份一次数据库，但是也很不优雅。 在 python 脚本中执行 mkdir 和 cp 命令是很不好的. 以后脚本多了就很不好管理，问了一下公司我带的大佬推荐了两种管理方式，分别是 jenkins 和 crontab.","link":"/2020/03/28/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD%E4%BB%BB%E5%8A%A1/"},{"title":"来到深圳","text":"很早以前，还是上大二的时候就一直想到深圳发展，后来毕业了就在成都工作。想了很久最后还是来到了深圳，虽然没有亲戚和同学，幸运的是仍有朋友在我刚到深圳的时候招待了一天，还帮我一起去租房。虽然今后怎样还是个未知数，但想想曾经帮助过我的人，还是有了奋斗的动力！！","link":"/2019/12/16/%E6%9D%A5%E5%88%B0%E6%B7%B1%E5%9C%B3/"},{"title":"树莓派4b ubuntu 20 设置阿里源","text":"前言设置国内源其实很简单，但是由于我是下载的 64位 操作系统，并且树莓派是arm架构，所以有一点不同执行 lsb_release -a 查看发行版本 ubuntu@ubuntu:/etc/netplan$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.1 LTS Release: 20.04 Codename: focal 所以修改配置文件 sudo vim /etc/apt/sources.list: ## Note, this file is written by cloud-init on first boot of an instance ## modifications made here will not survive a re-bundle. ## if you wish to make changes you can: ## a.) add 'apt_preserve_sources_list: true' to /etc/cloud/cloud.cfg ## or do the same in user-data ## b.) add sources in /etc/apt/sources.list.d ## c.) make changes to template file /etc/cloud/templates/sources.list.tmpl # See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to # newer versions of the distribution. deb http://mirrors.aliyun.com/ubuntu-ports focal main restricted # deb-src http://mirrors.aliyun.com/ubuntu-ports focal main restricted ## Major bug fix updates produced after the final release of the ## distribution. deb http://mirrors.aliyun.com/ubuntu-ports focal-updates main restricted # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-updates main restricted ## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu ## team. Also, please note that software in universe WILL NOT receive any ## review or updates from the Ubuntu security team. deb http://mirrors.aliyun.com/ubuntu-ports focal universe # deb-src http://mirrors.aliyun.com/ubuntu-ports focal universe deb http://mirrors.aliyun.com/ubuntu-ports focal-updates universe # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-updates universe ## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu ## team, and may not be under a free licence. Please satisfy yourself as to ## your rights to use the software. Also, please note that software in ## multiverse WILL NOT receive any review or updates from the Ubuntu ## security team. deb http://mirrors.aliyun.com/ubuntu-ports focal multiverse # deb-src http://mirrors.aliyun.com/ubuntu-ports focal multiverse deb http://mirrors.aliyun.com/ubuntu-ports focal-updates multiverse # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-updates multiverse ## N.B. software from this repository may not have been tested as ## extensively as that contained in the main release, although it includes ## newer versions of some applications which may provide useful features. ## Also, please note that software in backports WILL NOT receive any review ## or updates from the Ubuntu security team. deb http://mirrors.aliyun.com/ubuntu-ports focal-backports main restricted universe multiverse # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-backports main restricted universe multiverse ## Uncomment the following two lines to add software from Canonical's ## 'partner' repository. ## This software is not part of Ubuntu, but is offered by Canonical and the ## respective vendors as a service to Ubuntu users. # deb http://archive.canonical.com/ubuntu focal partner # deb-src http://archive.canonical.com/ubuntu focal partner deb http://mirrors.aliyun.com/ubuntu-ports focal-security main restricted # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-security main restricted deb http://mirrors.aliyun.com/ubuntu-ports focal-security universe # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-security universe deb http://mirrors.aliyun.com/ubuntu-ports focal-security multiverse # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-security multiverse 注意由于是 arm架构，一定要改成 http://mirrors.aliyun.com/ubuntu-ports 而不是 http://mirrors.aliyun.com/ubuntu，否则无法正常更新下载！！！。","link":"/2020/09/05/%E6%A0%91%E8%8E%93%E6%B4%BE4b%20ubuntu%2020%20%E8%AE%BE%E7%BD%AE%E9%98%BF%E9%87%8C%E6%BA%90/"},{"title":"树莓派frp内网穿透","text":"前言目的是实现外网连接树莓派 步骤# 客户端（树莓派）frpc.ini [common] server_addr = 120.79.215.235 server_port = 7000 [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 然后执行 ./frps -c ./frps.ini # 服务端（阿里云服务器） [common] [common] # 本机公网ip 120.79.215.235 bind_port = 7000 然后执行 ./frpc -c ./frpc.ini 最后通过 xshell 连接 或者命令行 ssh -oPort=6000 pi@120.79.215.235但是不知道为什么命令行的方式在 xshell 老提示密码错误。","link":"/2020/05/31/%E6%A0%91%E8%8E%93%E6%B4%BEfrp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"title":"树莓派ubuntu 20 网络设置","text":"前言在树莓派4B上配置一个 ubuntu 20 LTS 网络环境折腾了挺久的，在此记录一下以免下次再次采坑。 1234567891011121314151617181920212223242526272829# 编辑 /etc/netplan/50-cloud-init.yaml 改成如下network: ethernets: eth0: dhcp4: true optional: true version: 2 wifis: wlan0: access-points: &quot;Danke42168_1&quot;: # 这个是wifi名字 password: &quot;wifi.danke.life&quot; # 这是wifi密码 dhcp4: true optional: true 最后如果没有显示器可以先修改 root文件夹下的 network-config 文件， 一定要在第一次开机前设置，否则无法生效。不过由于安装包用的是国外的源，所以一般还是要接上显示器来配置国内源 如果想设置固定ip可以追加配置，最终配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# This file is generated from information provided by the datasource. Changes# to it will not persist across an instance reboot. To disable cloud-init's# network configuration capabilities, write a file# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:# network: {config: disabled}network: ethernets: eth0: dhcp4: true optional: true version: 2 wifis: wlan0: access-points: &quot;Danke42168_1&quot;: password: &quot;wifi.danke.life&quot; dhcp4: true optional: true addresses: [192.168.124.18/24] gateway4: 192.168.124.1 nameservers: addresses: [192.168.124.1, 8.8.8.8]","link":"/2020/09/05/%E6%A0%91%E8%8E%93%E6%B4%BEubuntu%2020%20%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE/"},{"title":"树莓派ubuntu 20 安装k3s","text":"安装到 helm的Github仓库 找到解压后把这个目录加入环境变量就可以了","link":"/2021/02/11/%E6%A0%91%E8%8E%93%E6%B4%BEubuntu%2020%20%E5%AE%89%E8%A3%85k3s/"},{"title":"镜像发布","text":"发布 docker login 登录 docker hub docker push caesar123/hello-world:1.00 下载docker pull caesar123/hello-world:1.00","link":"/2019/12/20/%E9%95%9C%E5%83%8F%E5%8F%91%E5%B8%83/"},{"title":"树莓派固定ip设置","text":"前言由于没有多余的屏幕以及鼠标和键盘等外设（就是有也没空间放），所以树莓派只能通过 xshell 连接，先前我是可以连接上的，但是由于 ip 发生了变化所以又要重新连上屏幕查看 ip，但是以后难免还会发生这样的事情。一劳永逸的方法是设置一个固定 ip 这样下次登录就不会发生之前的问题了。 步骤操作也很简单树莓派中有个文件可以实现固定 ip 的设置，执行 vim /etc/dhcpcd.conf，修改配置文件 # 在最后加入下面几行 # 指定接口 wlan0 interface wlan0 # 指定静态IP，/24表示子网掩码为 255.255.255.0 static ip_address=192.168.124.18/24 # 路由器/网关IP地址 static routers=192.168.124.1 # 手动自定义DNS服务器 static domain_name_servers=114.114.114.114 然后执行 sudo reboot 即可，之后便可以通过 xshell 等工具进行连接这里有两点需要注意 我的路由器 ip 是 192.168.124.1 ，但是常见的一般是 192.168.1.1 和 192.168.0.1 static ip_address=192.168.124.18/24，这一项要保证 18端口没有被占用，简单的方法就是 ping 192.168.124.18 如果没有响应就可以了 其他至于树莓派怎么连接 wifi 参考 无屏幕和键盘配置树莓派WiFi和SSH。","link":"/2020/05/30/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%9B%BA%E5%AE%9Aip%E8%AE%BE%E7%BD%AE/"}],"tags":[{"name":"python","slug":"python","link":"/tags/python/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"邮件","slug":"邮件","link":"/tags/%E9%82%AE%E4%BB%B6/"},{"name":"django3","slug":"django3","link":"/tags/django3/"},{"name":"生活","slug":"生活","link":"/tags/%E7%94%9F%E6%B4%BB/"},{"name":"Typora","slug":"Typora","link":"/tags/Typora/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"FastAPI","slug":"FastAPI","link":"/tags/FastAPI/"},{"name":"Vue","slug":"Vue","link":"/tags/Vue/"},{"name":"自动化","slug":"自动化","link":"/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"uwsgi","slug":"uwsgi","link":"/tags/uwsgi/"},{"name":"WSL2","slug":"WSL2","link":"/tags/WSL2/"},{"name":"历史相关","slug":"历史相关","link":"/tags/%E5%8E%86%E5%8F%B2%E7%9B%B8%E5%85%B3/"},{"name":"树莓派","slug":"树莓派","link":"/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"}],"categories":[{"name":"生活","slug":"生活","link":"/categories/%E7%94%9F%E6%B4%BB/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"Django","slug":"Django","link":"/categories/Django/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"Git&#x2F;Github","slug":"Git-Github","link":"/categories/Git-Github/"},{"name":"其他","slug":"其他","link":"/categories/%E5%85%B6%E4%BB%96/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Markdown","slug":"Markdown","link":"/categories/Markdown/"},{"name":"充电","slug":"充电","link":"/categories/%E5%85%85%E7%94%B5/"},{"name":"阅读","slug":"阅读","link":"/categories/%E9%98%85%E8%AF%BB/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"树莓派","slug":"树莓派","link":"/categories/%E6%A0%91%E8%8E%93%E6%B4%BE/"}],"pages":[{"title":"404","text":"","link":"/404/index.html"},{"title":"","text":"什么样的存在极简主义，中二晚期. Key Value 所在 深圳 如何联系 775650117@qq.com 户外 爬山，滑雪 乐器 一把偶尔响一下的吉他 常用语言 Go,Python,Solidity 平时喜欢看 宇宙记录片，旅游Vlog，红警HBK08 一些清单 阅读清单 音乐清单 F我是一个偶尔会发疯的人呐。 Ricardo M. Lu《龙族》","link":"/about/index.html"},{"title":"202207W3","text":"生活周六申请了加班，一方面是优化一下系统，另外也是打算过段时间请假去西藏或者云南，当然也可能是四川走一走。有好长时间没有旅游了（一两天的就不说了），上次是什么时候已经不记得了。乌龟养了一个多月，这几天精神不是很好，把它放到的窗边了，希望每天有一段时间的光照能让它有有所好转。最近又开始刷宇宙记录片了，韦伯望远镜公布了几张深空照片，从中可以看到几处引力透镜效应，很好奇未来有一天我们通过引力透镜效应观测到的一百多亿年前接近 Bing Bang 时期的宇宙是什么样子。 技术入门了 solidity，虽然不从事区块链相关的工作，一直以来对这方面还是挺感兴趣的。博客从 Vercel 迁移到了 cloudflare，现在 Vercel 在国内访问速度有点感人。还有就是现在的主题有点太花哨了，计划切换成icarus。 读书在读Make Time。","link":"/weekly/202207W3.html"},{"title":"202208W1","text":"生活乌龟还是没能活过第二个月，如果早注意到它的状态就好了，本来想再尝试一下的，最后决定过段时间吧。最近朋友圈里有好多爬山的，回想一下上次爬山已经是几个月前的事了，周末爬一下塘朗山吧。 技术重读了一下DESIGN PATTERNS in GO，每次读设计模式问题能有不同的感觉，可能是因为平时不怎么写组件，所以更多的还是阅读开源代码来保持工程化的思维。 读书本周没怎么阅读，晚上睡的太晚了，地铁上都不想读书了，作息还是要调整一下的。","link":"/weekly/202208W1.html"},{"title":"","text":"Weekly report202208-W2202208-W1202207-W3","link":"/weekly/index.html"},{"title":"202208W2","text":"生活如上周周报所提到，周六下午去爬了塘朗山，今年的夏天相较往年热了不少，一趟下来全身都是汗。回后瑞随便吃了点，看了一下时间还早，想起也好久没有看电影了，查了一下最近《神探大战》正在上映，觉得题材和演员都还可以就直奔影院，剧情偏悬疑,刘青云演技依旧在线，就不剧透了，个人算是满意。回到家洗澡11点休息了，是几个月来最早的一次。玩了两局LOL，选了从来不选的船长，天坑，但是队友给力，所以还是赢了，这个游戏果然七分靠运气~ 技术速刷了 Solidity 的基本特性，下周会尝试开始写合约，也会学习一下公有链，私有链，联盟链，超级账本的概念和实现思路。博客主题换成了icarus，原因在7月第三周周报有提到（还是拖了大半个月。。。），顺带把周报单独分出了一个page。少加载了一堆资源访问速度提升是肉眼可见了，看板娘最后也没去掉。 读书 《读者》 《重构》虽然量不大，毕竟相比上周好多了。 还有本周就是这样了，不过在上传md之前习惯性地刷了一下推特","link":"/weekly/202208W2.html"}]}