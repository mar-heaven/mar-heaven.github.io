{"posts":[{"title":"2019和2020","text":"前言2019年总体来说还是有所收获的，除了技术上成长了许多，还开发了自己的博客；另外还参与了 Pycon China2019 成都 的志愿者活动，有机会和各位大佬近距离接触 ，阿里老哥、日本小姐姐以及 Flask 项目大神维护者的讲解让小生受益匪浅。 读书的话貌似杂志更多吧，受老爸影响没事的时候就会看看《特别关注》、还有初中以来一直看的《读者》、《意林》。小说的话也看了《嫌疑人x的献身》（开始以为是推理小说，最后还是爱情结尾……以前看《白夜行》感觉亮司也是个“好人”）、《巨人的陨落1》、《巨人的陨落2》目前看了一半吧。 工作方面之前一直在成都工作，最终也是内心斗争了好久还是决定来深圳了，2年前就一直想来了，毕业后又工作了几个月（从成都到北上广深的也许可以体会这需要多大的勇气~），来到深圳开始找新的工作吧，目前有一个offer不过岗位路线和自己的计划略微偏移，最终决定放弃这个offer。 旅行，去年把《港澳通行证》办了，打算的是今年来一趟香港之旅，不过成都距离还是太远了，现在来深圳方便多了，明年的话这个计划基本没问题。 对于2020年 学习，微服务无论是前景还是技术角度个人还是很看好的，然后之前抽空也大概看了看 docker，不过还没有项目部署经验，年前这段时间再巩固一下，年后打算把博客改成 docker 部署。由于用到了 elasticsearch 进行全文检索 和 supervisor 来进程管理，免不了再来一大波操作了~。 社交，感觉自己的运气还是蛮好的，来深圳之前帮助一个老哥解决了一些技术问题，来深圳以后老哥也帮了我不少。未来希望结交一些新朋友吧，不过这个随缘就好。 兴趣，周日的话想培养个兴趣，目前是想弹弹吉他，工作稳定后换个房子，养条狗，还是要有些仪式感的。 读书，《巨人的陨落》还有一本半没读完，《平凡的世界》，《基督山伯爵》（英文版）。 待补充…… 最后想给自己来一句 愿你在被打击时，记起你的珍贵，抵抗恶意；愿你在迷茫时，坚信你的珍贵。爱你所爱，行你所行，听从你心，无问西东。","link":"/2019/12/28/2019%E5%92%8C2020/"},{"title":"2022已过三分之一","text":"前言起早了，闲来无事刷一下 blog，看了看年初写的总结，决定复盘一下，近乎鞭尸的行为，先附上2021年总结。其实每过一段时间看看之前写的博客还蛮有意思的。 运动从年后到五月，只爬了一次山，更多的是出去吃个烧烤什么的，爬山的次数无法和2021年同期相比。目前可以做到80个仰卧起坐，40次哑铃（单手5KG）,30个俯卧撑，断断续续，并非每天，偶尔朋友吃饭回来11点了，就没有做了，之后的话尽量保证10.30之前回家。 读书年初的时候在 twitter 上看到一位老哥的总结，感触挺多的。当时看的时候还是挺感慨的，现在看也有同感。2021看完整读过的书不到10本，当然是除去了读者和特别关注等杂志，杂志也不是每篇都看。对比了一下自己： 单身和朋友合租，但基本也无人打扰 有一定社交，2021年还是参与一些群聊的 偶尔玩玩游戏 节假日会出去转转吧，爬山什么的 那天看了看书架上吃灰已久的书，做出了一些调整，周末玩游戏少了，退出了 N 个群，少花点时间水群。这在2021年总结 中有提到。空出来的时间以期读更多的书。从一月到五月，也就是写这篇文章的时候，读书情况如下： 《幻夜》100% 《新参者》 100% 《东方快车谋杀案》100% 《大秦帝国一（上）》100% 《大秦帝国一（下）》100% 《大秦帝国二（上）》100% 《秘密》100% 《三体一》100% 《三体二》100% 《三体三》100% 《大秦帝国二（下）》40% 《刀锋》35% 技术《kubernetes权威指南》时不时翻一下。 音乐🎸偶尔在弹，乐理没有在看。。。 最后阶段性的复盘还是很有必要的，之后每周写一下周报吧。","link":"/2022/05/08/2022%E5%B7%B2%E8%BF%87%E4%B8%89%E5%88%86%E4%B9%8B%E4%B8%80/"},{"title":"Class-based views","text":"前言Django 中 函数视图 中有个 request 对象，封装了一些请求的数据，比如 post 请求上传来的参数或者当前用户数据： def index(request, *args, **kwargs): print(args) return HttpResponse(&quot;hello&quot;) 在给博客新增第三方登录的时候后端要进行一些用户数据的处理，比如头像链接拼接，而项目的视图函数采用的是 类视图。 解决一开始没有找到 User 对象，然后看了看 View 类的封装，发现有这么一段： def setup(self, request, *args, **kwargs): &quot;&quot;&quot;Initialize attributes shared by all view methods.&quot;&quot;&quot; self.request = request self.args = args self.kwargs = kwargs 显然在 类视图 中 request 对象被封装成一个属性了，那调用的时候就用 self.request 来代替原来的 request，比如获取当前用户就用 self.request.user 即可。 结语遇到问题直接看源码有时候比百度要来得快一些。","link":"/2019/11/23/Class-based%20views/"},{"title":"Django ORM 机制","text":"ORM是什么目前大多数互联网项目都涉及到数据库，不同的数据库有着自己的优势，用的时候就需要查询它们的 sql 语句，学习成本高；另外一段很长的 sql 语句很容易存在被注入的风险。 对象关系映射（Object Relational Mapping，简称ORM）模式是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。 该技术让我们可以使用面向对象的方法来进行数据库的操作，从而不必理会不同数据库之间 sql 语句的差异。 如上图所示，类对应的就是数据库中的表，类中的属性对应数据表中的字段，类的实例对象就是数据库中的一条条数据了。 from django.db import models class Person(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) 这里的 Person 在数据库中就是一张表，表名可以自定义。first_name 和 last_name 就是其中的两个字段，max_length 就是长度约束，比如 MySQL 数据库中对于字符字段可以设置其最大长度。如果我们想新建一条数据，可以通过以下方法： from .models import Person person = Person(first_name=&quot;泷谷&quot;, last_name=&quot;源治&quot;) person.save() 总结ORM 让开发人员大大减少了工作量，使得代码更加清晰，方便维护。当然每个技术有优点就有缺陷，ORM 虽然使开发效率提高了，但是缺牺牲了一些性能；另外一些复杂的 sql 语句并不能通过 ORM 来实现。不过对于大多开发者来说还是利大于弊。","link":"/2020/02/18/Django%20ORM%20%E6%9C%BA%E5%88%B6/"},{"title":"Django 使用 logging 模块的一次记录","text":"起因偶尔浏览 Stack overflow 看到有人提出的关于日志记录的问题，比较感兴趣就尝试了一下，问题截图如下:意思是他想把不同的日志等级分别记录在不同的文件中，比如 INFO 和 ERROR 分别记录到 info.log 以及 error.log 文件中，然而经过上图的尝试发现只有 ERROR 级别的错误记录到 error.log 的文件中了，而 INFO 级别的却没有记录，有一条解答算是比较清晰的 In your settings you have two entries for django, and django is writing logs based on the last entry. 意思是： **当你设置两个 django 的 loggers，那么默认会执行最后一个，也就是倒数第二章图的这部分有效 'django': { 'handlers': ['file.ERROR'], 'level': 'ERROR', 'propagate': True, }, 解决办法也同样给出了： 'loggers': { 'django.request': { 'handlers': ['file.DEBUG'], 'level': 'DEBUG', 'propagate': True, }, 'django': { 'handlers': ['file.INFO', 'file.ERROR'], # &lt;-- Here 'level': 'INFO', 'propagate': True, } } 本着 实践是检验真理的唯一标准 ，忍不住写了个小的demo试了一下： # views.py class IndexView(View): def get(self, request): log.info('info log file') log.error('error log file') return HttpResponse('return') # settings.py 'handlers': { 'info.file': { 'level': 'INFO', 'class': 'logging.handlers.RotatingFileHandler', # 日志位置,日志文件名,日志保存目录必须手动创建 'filename': os.path.join(os.path.dirname(BASE_DIR), &quot;logs/info.log&quot;), # 日志格式:详细格式 'formatter': 'verbose' }, 'error.file': { 'level': 'ERROR', 'class': 'logging.handlers.RotatingFileHandler', # 日志位置,日志文件名,日志保存目录必须手动创建 'filename': os.path.join(os.path.dirname(BASE_DIR), &quot;logs/error.log&quot;), # 日志格式:详细格式 'formatter': 'verbose', }, }, # 日志对象，第一次 'loggers': { 'django': { 'handlers': ['info.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'INFO', }, 'django': { 'handlers': ['error.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'ERROR', }, } 第一次的结果就是，level 为 INFO 的 loggers 没有记录，也就是只记录了 error 的日志 # 日志对象，第二次 'loggers': { 'django': { 'handlers': ['error.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'ERROR', }, 'django': { 'handlers': ['info.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'INFO', }, } 第二次结果相反，只有 info.log 文件中保存有记录。说明回答问题的这位还是很负责的！最后测试了一下正确的方式： 'loggers': { 'django': { 'handlers': ['info.file', 'error.file'], 'propagate': False, # 是否让日志信息继续冒泡给其他的日志处理系统 'level': 'INFO', }, } 最终结果是 INFO 级别以及比它更低级别的日志都记录到了 info.log 中，就是说 error 等级别也一块进去了，而 error 以及比他更低级别的日志会记录到 error.log 文件中，也就是说 error 以及比它低级别的日志会保存两份。这符合 logging 库的说明。 后记虽然找到了问题所在，不过提问者貌似想把不同级别的分别存储到一个文件中，就是 info.log 只保存 INFO 级别的日志，而不会保留 error 的日志。虽然这种需求不是很常见，毕竟 ERROR 以下级别的日志同样重要，也许有的公司人员比较充足，可以分2个人来分别解决 ERROR 以及 CRITICAL(严重错误，比如项目根本无法启动)也说不定~","link":"/2019/11/26/Django%20%E4%BD%BF%E7%94%A8%20logging%20%E6%A8%A1%E5%9D%97%E7%9A%84%E4%B8%80%E6%AC%A1%E8%AE%B0%E5%BD%95/"},{"title":"Django2.0 重写用户模型","text":"前言现有的 django 自带的用户模型已经不满足我们的需求了，比如用户有头像以及性别等字段，于是乎我们需要自定义一个新的用户模型，但是有一部分字段还是可以用以前的，比如邮箱什么的，所以采用继承关系就好。 步骤重写用户模型，继承 django.contrib.auth.models.AbstractUser 类 # users.py from django.db import models from django.contrib.auth.models import AbstractUser # Create your models here. class User(AbstractUser): mobiles = models.CharField(verbose_name=&quot;手机号码&quot;, max_length=15, unique=True) avatar = models.ImageField(upload_to='avatar', verbose_name='头像', null=True, blank=True, help_text=&quot;头像图片的大小规格：256*256，或者对应的比例的图片&quot;) class Meta: db_table = 'blog_users' verbose_name = '用户' verbose_name_plural = verbose_name 在 settings.py 中更改用户认证模型的指向 # settings.py # ...其他代码 # 配置让Django的Auth模块调用users子应用下的User模型 AUTH_USER_MODEL = &quot;users.User&quot; # ...其他代码 最后迁移一下数据即可！","link":"/2019/11/26/Django2.0%20%E9%87%8D%E5%86%99%E7%94%A8%E6%88%B7%E6%A8%A1%E5%9E%8B/"},{"title":"Docker 指令","text":"docker images 显示所有镜像 docker build -t image_name . (点就是从当前路径查找Dockerfile) docker container ls 列举当前运行的容器 docker run -it image_name 交互式运行image docker rm/docker container rm container_id 删除container docker rmi/docker image rm image_id 删除image docker container -aq 列出所有container_id (-q代表只列出id) docker rm $(docker container -aq) ($，删除所有列表中的元素) docker rm $(docker container ls -f “status=exited” -q) 删除退出的容器 docker commit container_name new_container_name docker commit frozty_jeew caesar123/centos-vim Dockerfile 用来build一个一模一样的image Dokerfile FROM strach # 制作base image FROM centos # 使用base image FROM ubuntu:14.04 LABEL maintainer = “775650117@qq.com“ (METADATA:注释) LABEL version = “1.0” RUN yum update &amp;&amp; yun install -y vim python-dev 每次运行RUN都会生成新的image，所以尽量合并成一行 WORKDIR /root # 设定工作目录 WORKDIR /test # 如果没有会自动创建test目录 WORKDIR demo RUN pwd # 输出结果应该是/test/demo 用WORKDIR, 不要使用 RUN cd,尽量使用绝对目录 ADD(COPY) ADD hello / ADD test.tar.gz / # 添加到根目录并解压 WORKDIR /root ADD hello test/ # /root/test/hello WORKDIR /root COPY hello test/ # /root/test/hello 大部分情况，COPY优于ADD，ADD除了COPY还有解压功能 添加远程文件/目录请使用curl或者wget ENV MYSQL_VERSION 5.6 # 设置常量 ENV MYSQL_VERSION 5.6 # 设置常量 RUN apt-get install -y mysql-server= &quot;${MYSQL_VERSION}&quot; \\ &amp;&amp; rm -rf /var/lib/apt/lists/* 引用常量 尽量使用ENV增加可维护性","link":"/2019/12/19/Docker%20%E6%8C%87%E4%BB%A4/"},{"title":"Docker 指令2","text":"RUN 执行命令并创建新的Image layer CMD 设置容器启动后默认执行的命令和参数 ENTRYPOINT 设置容器启动时执行的命令 shell 格式 RUN apt-get install -y vim CMD echo &quot;hello docker&quot; ENTRYPOINT echo &quot;hello docker&quot; Exec格式 RUN [&quot;apt-get&quot;, &quot;install&quot;, &quot;-y&quot;, &quot;vim&quot;] CMD [&quot;/bin/echo&quot;, &quot;hello docker&quot;] ENTRYPOINT [&quot;/bin/echo&quot;, &quot;hello docker&quot;]","link":"/2019/12/19/Docker%20%E6%8C%87%E4%BB%A42/"},{"title":"Elasticsearch基本查询","text":"准备数据# 添加映射 PUT lagou { &quot;mappings&quot;: { &quot;job&quot;:{ &quot;properties&quot;: { &quot;title&quot;:{ &quot;store&quot;: true, &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; }, &quot;company_name&quot;:{ &quot;store&quot;: true, &quot;type&quot;: &quot;keyword&quot; }, &quot;desc&quot;:{ &quot;type&quot;: &quot;text&quot; }, &quot;comments&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;add_time&quot;:{ &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd&quot; } } } } } POST lagou/job/ { &quot;title&quot;:&quot;python django 开发工程师&quot;, &quot;company_name&quot;:&quot;美团科技有限公司&quot;, &quot;desc&quot;:&quot;对django的概念熟悉，熟悉python基础知识&quot;, &quot;comments&quot;:20, &quot;add_time&quot;:&quot;2019-5-30&quot; } POST lagou/job/ { &quot;title&quot;:&quot;python scrapy redis分布式爬虫基本&quot;, &quot;company_name&quot;:&quot;百度科技有限公司&quot;, &quot;desc&quot;:&quot;scrapy的概念熟悉，熟悉redis基础知识&quot;, &quot;comments&quot;:5, &quot;add_time&quot;:&quot;2019-5-1&quot; } POST lagou/job/ { &quot;title&quot;:&quot;elasticsearch打造搜索引擎&quot;, &quot;company_name&quot;:&quot;阿里巴巴科技有限公司&quot;, &quot;desc&quot;:&quot;熟悉数据结构算法，熟悉python基础开发&quot;, &quot;comments&quot;:60, &quot;add_time&quot;:&quot;2019-4-15&quot; } POST lagou/job/ { &quot;title&quot;:&quot;python打造推荐引擎系统&quot;, &quot;company_name&quot;:&quot;阿里巴巴科技有限公司&quot;, &quot;desc&quot;:&quot;熟悉推荐引擎的原理以及算法，掌握C语言&quot;, &quot;comments&quot;:60, &quot;add_time&quot;:&quot;2019-1-22&quot; } 查询基本查询 match(会对输入进行分词) GET lagou/_search { &quot;query&quot;: { &quot;match&quot;: { &quot;title&quot;: &quot;爬取&quot; } } } GET lagou/_search { &quot;query&quot;: { &quot;match&quot;: { &quot;title&quot;: &quot;爬取&quot; } } } term(不会分词) GET lagou/_search { &quot;query&quot;: { &quot;term&quot;: { &quot;title&quot;: &quot;python爬虫&quot; } } } terms(满足任何一个) # terms查询 GET lagou/_search { &quot;query&quot;: { &quot;terms&quot;: { &quot;title&quot;: [&quot;工程师&quot;, &quot;django&quot;, &quot;系统&quot;] } } } query查询(控制查询的返回数量) GET lagou/_search { &quot;query&quot;: { &quot;match&quot;: { &quot;title&quot;: &quot;python&quot; } }, &quot;from&quot;:1, &quot;size&quot;:2 } match_all查询 GET lagou/_search { &quot;query&quot;: { &quot;match_all&quot;: {} } } multi_match查询 # 比如可以指定多个字段 # 比如查询title和desc这两个字段里面包含python的关键词文档 # 可以设置权重 GET lagou/_search { &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;python&quot;, &quot;fields&quot;: [&quot;title^3&quot;, &quot;desc&quot;] } } } stored_fields指定返回的字段(mappings设置了store的) GET lagou/_search { &quot;stored_fields&quot;: [&quot;title&quot;], &quot;query&quot;: { &quot;match&quot;: { &quot;title&quot;: &quot;python&quot; } } } sort(排序返回 asc,desc) GET lagou/_search { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;comments&quot;: { &quot;order&quot;: &quot;desc&quot; } } ] } range(范围查询)boost: 权重 GET lagou/_search { &quot;query&quot;: { &quot;range&quot;: { &quot;comments&quot;: { &quot;gte&quot;: 10, &quot;lte&quot;: 20, &quot;boost&quot;: 2.0 } } } } GET lagou/_search { &quot;query&quot;: { &quot;range&quot;: { &quot;add_time&quot;: { &quot;gt&quot;: &quot;2019-4-1&quot; } } } } match_phrase(短语查询，自动分词，满足所有则返回)slop: 两个词之前的距离 GET lagou/_search { &quot;query&quot;: { &quot;match_phrase&quot;: { &quot;title&quot;: { &quot;query&quot;: &quot;python系统&quot;, &quot;slop&quot;: 6 } } } }","link":"/2019/12/28/Elasticsearch%E5%9F%BA%E6%9C%AC%E6%9F%A5%E8%AF%A2/"},{"title":"Elasticsearch操作","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273# es的文档，索引的 CRUD 操作# 索引初始化操作# 指定分片和副本的数量# shards一旦设置不能修改（副本数量）# 设置索引 PUT lagou{ &quot;settings&quot;: { &quot;index&quot;:{ &quot;number_of_shards&quot;: 5, &quot;number_of_replicas&quot;: 2 } } }GET lagou/_settingsGET _all/_settingsGET .kibana,lagou/_settingsGET lagou/job/1/_source# 修改settingsPUT lagou/_settings{ &quot;number_of_shards&quot;: 2}# 保存文档 PUT lagou/job/2{ &quot;title&quot;: &quot;python分布式爬虫开发&quot;, &quot;salary_min&quot;: 15000, &quot;city&quot;: &quot;北京&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;百度&quot;, &quot;company_addr&quot;: &quot;北京市软件园&quot; }, &quot;publish_data&quot;: &quot;2019-5-30&quot;, &quot;comments&quot;: 15}POST lagou/job/1{ &quot;title&quot;: &quot;python django 开发工程师&quot;, &quot;salary_min&quot;: 3000, &quot;city&quot;: &quot;天猫&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;美团科技&quot;, &quot;company_addr&quot;: &quot;北京市软件园A区&quot; }, &quot;publish_data&quot;: &quot;2019-5-30&quot;, &quot;comments&quot;: 2}GET lagou/job/2?_source=city,company.name# 修改文章PUT lagou/job/2{ &quot;title&quot;: &quot;python分布式爬虫开发&quot;, &quot;salary_min&quot;: 15000, &quot;city&quot;: &quot;北京&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;百度&quot;, &quot;company_addr&quot;: &quot;北京市软件园&quot; }, &quot;publish_data&quot;: &quot;2019-5-30&quot;, &quot;comments&quot;: 23}# 修改文章2POST lagou/job/2/_update{ &quot;doc&quot;:{ &quot;comments&quot;: 21 }}DELETE lagou/job/1DELETE lagou# 批量获取GET _mget{ &quot;docs&quot;:[ { &quot;_index&quot;:&quot;lagou&quot;, &quot;_type&quot;: &quot;job2&quot;, &quot;_id&quot;: 2 }, { &quot;_index&quot;:&quot;lagou&quot;, &quot;_type&quot;: &quot;job&quot;, &quot;_id&quot;: 1 } ]}# index一样GET lagou/_mget{ &quot;docs&quot;:[ { &quot;_type&quot;: &quot;job2&quot;, &quot;_id&quot;: 2 }, { &quot;_type&quot;: &quot;job&quot;, &quot;_id&quot;: 1 } ]}# index,type一样GET lagou/job2/_mget{ &quot;docs&quot;:[ { &quot;_id&quot;: 2 }, { &quot;_id&quot;: 1 } ]}GET lagou/job2/_mget{ &quot;ids&quot;: [1,2]} bulk批量操作bulk操作不能分行，json必需一行写完 123456789{&quot;index&quot;: {&quot;_index&quot;: &quot;zhilian&quot;, &quot;_type&quot;: &quot;job&quot;, &quot;_id&quot;: &quot;1&quot;}}{&quot;title&quot;: &quot;python分布式爬虫开发&quot;,&quot;salary_min&quot;: 15000,&quot;city&quot;: &quot;北京&quot;,&quot;company&quot;: {&quot;name&quot;: &quot;百度&quot;,&quot;company_addr&quot;: &quot;北京市软件园&quot;},&quot;publish_data&quot;: &quot;2019-5-30&quot;,&quot;comments&quot;: 23}{&quot;index&quot;: {&quot;_index&quot;: &quot;zhilian&quot;, &quot;_type&quot;: &quot;job&quot;, &quot;_id&quot;: &quot;2&quot;}}{&quot;title&quot;: &quot;爬虫开发&quot;,&quot;salary_min&quot;: 1500,&quot;city&quot;: &quot;太原&quot;,&quot;company&quot;: {&quot;name&quot;: &quot;阿里&quot;,&quot;company_addr&quot;: &quot;太原市软件园&quot;},&quot;publish_data&quot;: &quot;2019-5-30&quot;,&quot;comments&quot;: 23} bulk其他操作123456789101112131415{&quot;index&quot;: {&quot;_index&quot;: &quot;test&quot;, &quot;_type&quot;: &quot;type1&quot;, &quot;_id&quot;: &quot;1&quot;}}{&quot;field1&quot; : &quot;value1&quot;}{&quot;delete&quot;: {&quot;_index&quot;: &quot;test&quot;, &quot;_type&quot;: &quot;type1&quot;, &quot;_id&quot;: &quot;2&quot;}}{&quot;create&quot;: {&quot;_index&quot;: &quot;test&quot;, &quot;_type&quot;: &quot;type1&quot;, &quot;_id&quot;: &quot;3&quot;}}{&quot;field1&quot; : &quot;value3&quot;}{&quot;update&quot;: {&quot;_index&quot;: &quot;index1&quot;, &quot;_type&quot;: &quot;type1&quot;, &quot;_id&quot;: &quot;1&quot;}}{&quot;doc&quot;:{&quot;field2&quot;: &quot;value2&quot;} elasticsearch映射123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115# 创建索引PUT lagou{ &quot;mappings&quot;: { &quot;job&quot;:{ &quot;properties&quot;: { &quot;title&quot;:{ &quot;type&quot;: &quot;text&quot; }, &quot;salary_min&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;city&quot;:{ &quot;type&quot;:&quot;keyword&quot; }, &quot;company&quot;:{ &quot;properties&quot;: { &quot;name&quot;:{ &quot;type&quot;:&quot;text&quot; }, &quot;company_addr&quot;:{ &quot;type&quot;:&quot;text&quot; }, &quot;employee_count&quot;:{ &quot;type&quot;:&quot;integer&quot; } } }, &quot;publish_date&quot;:{ &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd&quot; }, &quot;comments&quot;:{ &quot;type&quot;: &quot;integer&quot; } } } }}PUT lagou/job/3{ &quot;title&quot;: &quot;python分布式爬虫开发&quot;, &quot;salary_min&quot;: &quot;abc&quot;, &quot;city&quot;: &quot;北京&quot;, &quot;company&quot;: { &quot;name&quot;: &quot;百度&quot;, &quot;company_addr&quot;: &quot;北京市软件园&quot;, &quot;employee_count&quot;:50 }, &quot;publish_data&quot;: &quot;2019-5-30&quot;, &quot;comments&quot;: 15}GET lagou/_mapping/jobGET _all/_mapping/job","link":"/2019/12/28/Elasticsearch%E6%93%8D%E4%BD%9C/"},{"title":"Elasticsearch组合查询","text":"准备数据POST lagou/testjob/_bulk {&quot;index&quot;:{&quot;_id&quot;:1}} {&quot;salary&quot;:10, &quot;title&quot;: &quot;Python&quot;} {&quot;index&quot;:{&quot;_id&quot;:2}} {&quot;salary&quot;:20, &quot;title&quot;: &quot;Scrapy&quot;} {&quot;index&quot;:{&quot;_id&quot;:3}} {&quot;salary&quot;:30, &quot;title&quot;: &quot;Django&quot;} {&quot;index&quot;:{&quot;_id&quot;:4}} {&quot;salary&quot;:40, &quot;title&quot;: &quot;Elasticsearch&quot;} 组合查询bool查询 用 bool 包括 must should must_not filter 来完成，格式如下 filter 过渡字段 must 所有都要有 should 满足一个或多个 must_not 一个都不能满足 bool: { &quot;filter&quot;: [], &quot;must&quot;: [], &quot;should&quot;: [], &quot;must_not&quot; } filter查询 select * from testjob where salary=20 薪资为20k的工作 GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match_all&quot;:{} }, &quot;filter&quot;: { &quot;term&quot;: { &quot;salary&quot;: &quot;20&quot; } } } } } # 多个 GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;terms&quot;: { &quot;salary&quot;: [&quot;10&quot;, &quot;20&quot;] } } } } } # select * from testjob where title=&quot;Python&quot; # text字段会先分词，再全部转为小写入库 # term不会预处理，直接大写查询，但是倒排索引已经全部小写了 # 所以查不到，要不就用小写，要不就用match GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;term&quot;: { &quot;title&quot;:&quot;Python&quot; } } } } } bool组合过滤查询# 查询薪资等于20k或者工作为Python的工作，排除价格为30k的 # select * from testjob where (salary=20 OR title=&quot;Python&quot;) AND (salary !=30) GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;:[ {&quot;term&quot;: {&quot;salary&quot;:20}}, {&quot;term&quot;:{&quot;title&quot;:&quot;python&quot;}} ], &quot;must_not&quot;: [ {&quot;term&quot;:{&quot;salary&quot;:30}}, {&quot;term&quot;:{&quot;salary&quot;:10}} ] } } } # 嵌套查询 # select * from testjob where title=&quot;python&quot; or (title=&quot;django&quot; AND salary=40) GET lagou/testjob/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;:[ {&quot;term&quot;: {&quot;title&quot;:&quot;python&quot;}}, {&quot;bool&quot;:{ &quot;must&quot;: [ {&quot;term&quot;: {&quot;title&quot;:&quot;elasticsearch&quot;}}, {&quot;term&quot;: {&quot;salary&quot;: 40}} ]} } ] } } } 过滤空和非空 # 建立测试数据 POST lagou/testjob2/_bulk {&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}} {&quot;tags&quot;:[&quot;search&quot;]} {&quot;index&quot;:{&quot;_id&quot;:&quot;2&quot;}} {&quot;tags&quot;:[&quot;search&quot;, &quot;python&quot;]} {&quot;index&quot;:{&quot;_id&quot;:&quot;3&quot;}} {&quot;orther_field&quot;:[&quot;some data&quot;]} {&quot;index&quot;:{&quot;_id&quot;:&quot;4&quot;}} {&quot;tags&quot;:null} {&quot;index&quot;:{&quot;_id&quot;:&quot;5&quot;}} {&quot;tags&quot;:[&quot;search&quot;, null]} # 处理非空值的方法 # select tags from testjob2 where tags is not NULL GET lagou/testjob2/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;exists&quot;: { &quot;field&quot;: &quot;tags&quot; } } } } }","link":"/2019/12/28/Elasticsearch%E7%BB%84%E5%90%88%E6%9F%A5%E8%AF%A2/"},{"title":"Elasticsearch配置","text":"安装 Java环境 Git 下载 elasticsearch-rtf 压缩包，解压 进入bin 运行 elasticsearch.bat Git clone elasticsearch-head 进入，npm install,npm run start 配置elasticsearch.yml http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; http.cors.allow-methods: OPTIONS, HEAD, GET, PUT, DELETE http.cors.allow-headers: &quot;X-Requested_With, Content-Type, Content_Length, X-User&quot; 安装 kibana ,版本与 elasticsearch相对应 elasticsearch概念 集群 节点 分片 副本 Elasticsearch Mysql index 数据库 type 表 documents 行(一条数据) fields 列","link":"/2019/12/28/Elasticsearch%E9%85%8D%E7%BD%AE/"},{"title":"Github搜索开源项目方式","text":"前言作为全球最大的同性交友网站，Github 上有很多优秀的开源项目，使用正确的方式搜索可以很方便地找到自己需要的资源。 使用筛选的语法非常简单 # 按照项目名/仓库名搜索（大小写不敏感） in:name xxx # 按照README搜索（大小写不敏感） in:readme xxx # 按照description搜索（大小写不敏感） in:description xxx # stars数大于xxx stars:&gt;xxx # forks数大于xxx forks:&gt;xxx # 编程语言为xxx language:xxx # 最新更新时间晚于YYYY-MM-DD pushed:&gt;YYYY-MM-DD 举个例子，如果需要搜索一个基于 Django 的后台管理项目，可以通过以下方式，搜索仓库名包含 django 关键字并且项目描述中包含 后台 关键字。就是这么方便，当然可以通过更新时间来过滤一些不维护的项目。","link":"/2020/05/02/Github%E6%90%9C%E7%B4%A2%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%96%B9%E5%BC%8F/"},{"title":"Git设置代理","text":"Git代理开了VPN以后发现执行 git clone 还是不够快，经大佬指点发现还需要配置 git 的代理。 https://gist.github.com/evantoli/f8c23a37eb3558ab8765 git config –global http.proxy http://127.0.0.1:1087","link":"/2020/03/31/Git%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"title":"Linux 文件隐藏属性","text":"前言我们都知道 Linux 系统文件都有 r(read)/w(write)/x(execute) 三个属性，但是文件系统还提供了隐藏属性，这些隐藏属性非常实用，可以进一步起到对文件的保护作用。 chattr(配置文件隐藏属性)配置文件隐藏属性的指令是 chattr [+- - =][ASacdistu] 文件或目录名其中选项和参数如下: 选项与参数： + ：增加某一个特殊参数，其他原本存在参数则不动。 - ：移除某一个特殊参数，其他原本存在参数则不动。 = ：设定一定，且仅有后面接的参数 A ：当设定了 A 这个属性时，若你有存取此文件(或目录)时，他的访问时间 atime 将不会被修改，可避免 I/O 较慢的机器过度的存取磁盘。(目前建议使用文件系统挂载参数处理这个项目) S ：一般文件是异步写入磁盘的(原理请参考前一章 sync 的说明)，如果加上 S 这个属性时，当你进行任何文件的修改，该更动会『同步』写入磁盘中。 a ：当设定 a 之后，这个文件将只能增加数据，而不能删除也不能修改数据，只有 root 才能设定这属性 c ：这个属性设定之后，将会自动的将此文件『压缩』，在读取的时候将会自动解压缩，但是在储存的时候，将会先进行压缩后再储存(看来对于大文件似乎蛮有用的！) d ：当 dump 程序被执行的时候，设定 d 属性将可使该文件(或目录)不会被 dump 备份 i ：这个 i 可就很厉害了！他可以让一个文件『不能被删除、改名、设定连结也无法写入或新增数据！』对于系统安全性有相当大的帮助！只有 root 能设定此属性 s ：当文件设定了 s 属性时，如果这个文件被删除，他将会被完全的移除出这个硬盘空间，所以如果误删了，完全无法救回来了喔！ u ：与 s 相反的，当使用 u 来配置文件案时，如果该文件被删除了，则数据内容其实还存在磁盘中，可以使用来救援该文件喔！ 注意 1：属性设定常见的是 a 与 i 的设定值，而且很多设定值必须要身为 root 才能设定 注意 2：xfs 文件系统仅支援 AadiS 而已 admin@iZwz93u7y9mplneahfm5doZ:~$ cd /tmp/ admin@iZwz93u7y9mplneahfm5doZ:/tmp$ touch attrtest admin@iZwz93u7y9mplneahfm5doZ:/tmp$ chattr +i attrtest chattr: Operation not permitted while setting flags on attrtest admin@iZwz93u7y9mplneahfm5doZ:/tmp$ sudo chattr +i attrtest admin@iZwz93u7y9mplneahfm5doZ:/tmp$ sudo rm attrtest &lt;=此时sudo也就是root都无法删除了 rm: cannot remove 'attrtest': Operation not permitted admin@iZwz93u7y9mplneahfm5doZ:/tmp$ chattr -i attrtest chattr: Operation not permitted while setting flags on attrtest admin@iZwz93u7y9mplneahfm5doZ:/tmp$ sudo chattr -i attrtest &lt;=把i属性取消掉就可以删除了 admin@iZwz93u7y9mplneahfm5doZ:/tmp$ rm attrtest 其中最常用的就是 i 和 a 属性了，i 让一个文件无法修改，无法被删除，也不能被软链接，对系统安全性有很重要的意义。a 让一个文件只能增加数据，无法修改和删除数据。 lsattr(显示文件隐藏属性)显示隐藏属性的指令如下： lsattr [- adR] 文件 或者 目录选项与参数: -a ：将隐藏文件的属性也秀出来 -d ：如果接的是目录，仅列出目录本身的属性而非目录内的文件名 -R ：连同子目录的数据也一并列出来","link":"/2020/02/20/Linux%20%E6%96%87%E4%BB%B6%E9%9A%90%E8%97%8F%E5%B1%9E%E6%80%A7/"},{"title":"Linux文件属性","text":"前言以前一直只知道 chmod + 777 文件或者目录 就是把文件或者文件夹的权限提升到所有人都可以使用，至于为什么是 777 一直没有了解过，最近在看 《鸟叔的Linux私房菜-基础篇》，记录下这部分。 查看文件属性执行 ls -al 来查看一个目录下的文件和文件夹（包含隐藏的）属性。 分为七部分，以最后一行说明 -rw-r–r– 文件的类型权限，一共十个字母。第一个字母是文件类型， - 表示是个文件，d 表示是个目录。后面九个每三个分为一组，表示执行权限,[rwx]分别表示可读，可写，可执行：第一组是文件所有者的权限，第二组是此所有者所在的组权限，第三组是非本人且没有加入本人所在组的权限。 第二个为连接到此节点的链接数，包括硬链接和软链接 第三个是文件（目录）所属用户 第四个是文件所在的群组 第五个是文件大小 第六个是文件创建日期 第七个是文件名 改变文件属性和权限 chgrp: 改变文件所属群组 chown: 改变文件拥有者 chmod: 改变文件权限，SUID, SGID, SBIT 等等的特性 改变文件所属组chgrp users myblog.ini把 myblog.ini 文件所在组改为 uses，如果组不存在则会报错 改变文件的拥有者chown ginta myblog.ini把 myblog.ini 文件拥有者改为 ginta 改变文件的权限Linux文件一共有9个基本权限，分别是owner/group/others三个身份以及read/write/execute三个权限，三个三个为一组可以排列出9种权限。 r:4 w:2 e:1其中身份(owner/group/others)和权限(r/w/x)是累加的， 比如我们上边的 [-rw-r–r–] 就代表 owner = -rw = 0 + 4+2 =6 group = r– = 4 +0 + 0 = 4 others = r– = 4 + 0 + 0 = 4那么此文件的权限就是 644修改文件权限的命令是chmod 777 myblog.ini这条命令就是我之前无脑操作的，权限全开。 总结以前的文件操作方式相当于把文件整个暴漏给了其他人，可读可写！！无知是多么可怕~","link":"/2020/02/17/Linux%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7/"},{"title":"Ubuntu系统安装redis","text":"前言一般爬虫是在 Ubuntu 系统下进行配置的，这次的任务就是在 Ubuntu 系统下安装 redis。 步骤 sudo apt-get install redis-server，遇到依赖包输入 Y 回车即可 启动，安装以后自动启动，可以查看 ps aux|grep redis 手动启动， sudo service redis-server start 停止， sudo service redis-server stop 卸载sudo apt-get purge --auto-remove redis-server Ubuntu连接Windows redis我这里 Windows 用的是本机 redis 服务，ubuntu 使用的虚拟机，也就是说是在同一个局域网下的，不同网络其实也差不多，连接其他服务器 redis 的命令是 redis-cli -h host -p port，比如我的 Windows 局域网 ip 是 192.168.199.168redis端口是 6379 ，那命令就是 redis-cli -h 192.168.199.168 -p 6379：ubunu 下：我们用 ubuntu 系统连接 Windows 系统 redis ，这里显示失败了，我们开 windows 的 redis 配置文件 redis.windows.conf 有这么一行意思是其他人访问 redis 的时候地址是这个，我们都知道 127.0.0.1 永远指向本机，当然不能访问成功了，我们改成本机地址就可以，一定是当前局域网的 ip，也就是 bind 一定是服务器的 ip 地址，而不是客户端的 ip，如果是 0.0.0.0 表示其他机器可以通过本机的所有网卡（一台电脑可能有多个网卡） ip 地址连接本机 redis:保存之后重启 windows 的 redis 服务，再用 ubuntu 连接一下：我们可以看到，成功了，并且访问 username 键，获得了它的值。","link":"/2019/11/26/Ubuntu%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85redis/"},{"title":"Windows10 docker desktop k8s","text":"##前言家里的台式机换了主板，cpu和内存之后流畅很多，图形化界面是 Windows 系统天然的优势，所以装了个 docker desktop，装完后发现可以一键安装k8s，果断开干。 虽说是一键，但还是有个小问题。一起在启动中，等了很久都没反应，猜测是因为依赖都是外网，需要开代理。我的本机代理端口是1080。最终成功安装！可能有细心的发现 k8s 版本变了，是因为我已经成功安装，看不到 starting 了，于是在网上找了一张，不过这不重要~ 2021.3.12docker pull 用的是https之前imac上的k8s一直无法启动，配置了 https 代理就好了。","link":"/2020/11/14/Windows10%20docker%20desktop%20k8s/"},{"title":"django Signals","text":"前言在平时应用中我们经常遇到比如新增加一个用户就发送短信，新增加一条留言就给我们 发送邮箱 这种需求，一般来说都可以在视图函数中完成这些操作。但是如果有多个地方都需要类似的操作，比如用户在N个应用中都可以留言，如果在每个视图函数中都写一遍 发送邮箱 这种操作无疑是不明智的，好在 django 框架中内置了 signals(信号) 机制，可以辅助我们监听某些行为，比如 model 新增，或者请求前和请求后。 信号官方的信号主要分为以下几种，具体介绍详见 Django信号。 Model signals pre_init post_init pre_save post_save pre_delete post_delete class_prepared Management signals post_syncdb Request/response signals request_started request_finished got_request_exception Test signals template_rendered 举例这里举一个例子，官方推荐在应用目录下新增一个 signals.py文件 新建并注册app，我这里app名字是 signalapp 在app下方新建signals.py文件 修改 app下面的 apps.py # 原来 from django.apps import AppConfig class SignalappConfig(AppConfig): name = 'signalapp' # 现在 from django.apps import AppConfig class SignalappConfig(AppConfig): name = 'signalapp' def ready(self): # signals are imported, so that they are defined and can be used import signalapp.signals 编写 signals.py # signalapp/signals.py from django.dispatch import receiver from django.db.models.signals import post_save from signalapp.models import Post def send(): print(&quot;发送邮件&quot;) @receiver(post_save, sender=Post, dispatch_uid='Post_post_save') def send_email(instance, **kwargs): send() 然后重启服务，接下来在任意地方只要新建了 Post 实例并保存了，该函数都将在保存之后执行。与之相对应的是函数是 pre_save，显然，这是在保存前执行的。 receiver 装饰器有三个参数： 第一个是要监听的信号，我这里是 post_save 第二个是所要监听的模型，我这里是 Post 是文章模型，所以这个函数会在每次有文章保存（新建或者更新）的时候触发 post_save 在某个Model保存之后调用, 对于每个唯一的dispatch_uid,接收器都只被信号调用一次 这个信号的功能就是每次新建或者更改文章的时候发送一个邮件（邮件函数没写。。） 补充其他的可以参考文档，django 的文档写得确实很好，另外想说的就是 sender 不一定是模型，也可以是函数： import datetime import os import django from django.dispatch import receiver, Signal from django.http import HttpResponse # 发送信号 def signal_sender(request): hostname = request.get_host() msg = 'Django Signal Test' time = datetime.date.today() signal_obj.send(sender=signal_sender, hostname=hostname, msg=msg, time=time) # 关键一行 return HttpResponse('200 OK') # 接收和处理信号 @receiver(signal_obj, sender=signal_sender) # 装饰器把处理函数注册成接收器 def signal_handler(sender, **kwargs): # 接收到信号后，在此处理。kwargs字典用来传递Signal信号参数 print('接收到信号内容：{hostname}|&quot;{msg}&quot;|{time}'.format(hostname=kwargs['hostname'], msg=kwargs['msg'], time=kwargs['time']))","link":"/2019/11/26/django%20Signals/"},{"title":"django 图片储存七牛云","text":"前言每次给博客添加一篇文章的时候，上传图片的时候总要心痛一下，因为服务器的空间很有限，最主要的还是感觉把博客的图片和代码放到一个地方总有种污染代码的感觉，以前就听说了七牛云很方便，于是就用一下了。 开始首先我们要新建一个七牛云的储存空间，具体操作如下。进入这里，点击 对象存储新建存储空间 ，存储空间的名称随意就好，配置可以仿照这里图片这个样子，然后就OK了，对于新用户首先要实名认证，不过挺快的，我申请了2个小时不到就通过了。 使用 首先安装依赖包pip install django-qiniu-storage 然后 settings.py 配置新增如下 # 七牛云配置 QINIU_ACCESS_KEY = 'ACCESS_KEY' # 七牛给开发者分配的AccessKey QINIU_SECRET_KEY = 'SECRET_KEY' # 七牛给开发者分配的Secret QINIU_BUCKET_NAME = 'myblog' # 就是刚才新建的存储空间名称 # 用来存放文件的七牛空间(bucket)的名字 QINIU_BUCKET_DOMAIN = '*****.bkt.clouddn.com/' # 七牛空间(bucket)的域名，别遗漏了后面的/ DEFAULT_FILE_STORAGE = 'qiniustorage.backends.QiniuStorage' # 只用七牛托管动态生成的文件（例如用户上传的文件） QINIU_SECURE_URL = False # 使用http PREFIX_URL = 'http://' # 文件系统更改 MEDIA_URL = PREFIX_URL + QINIU_BUCKET_DOMAIN MEDIA_ROOT = 'media/' QINIU_BUCKET_DOMAIN 的位置如下 我的轮播图 model 如下 class Banner(BaseModel): STATUS_NORMAL = 1 STATUS_DELETE = 0 STATUS_ITEMS = ( (STATUS_NORMAL, '正常'), (STATUS_DELETE, '删除'), ) &quot;&quot;&quot; 轮播图 &quot;&quot;&quot; # upload_to 存储子目录，真实存放地址会使用配置中的MADIE_ROOT+upload_to image = models.ImageField(upload_to='banner', verbose_name='轮播图', null=True, blank=True, help_text=&quot;轮播图片的大小规格：1920x720，或者对应的比例的图片&quot;) name = models.CharField(max_length=150, verbose_name='轮播图名称') desc = models.CharField(max_length=250, verbose_name='描述信息', help_text=&quot;请填写描述信息&quot;) status = models.PositiveIntegerField(default=STATUS_NORMAL, choices=STATUS_ITEMS, verbose_name='状态') link = models.CharField(max_length=150, verbose_name='轮播图广告地址') class Meta: db_table = 'home_banner' verbose_name = '轮播图' verbose_name_plural = verbose_name def __str__(self): return self.name 注意 image 这个字段，我设置了 upload_to='banner' ，他就会保存到 MADIE_ROOT+’banner’ 这个路径下，而 MADIE_ROOT 在配置中是 MEDIA_URL = PREFIX_URL + QINIU_BUCKET_DOMAIN ,也就是 'http://*****.bkt.clouddn.com/'于是我们的轮播图图片就会保存到类似这样的url下：http://*****.bkt.clouddn.com/banner/20160923084104779_jAQ76Kw.jpg 总结基本操作就是这样了，因为网上有很多大佬已经踩过坑了，所以避免了不少麻烦。七牛云不止可以存储图片，也可以存储其他文件，CDN加速等等，以后有需要会补充上的。","link":"/2019/11/26/django%20%E5%9B%BE%E7%89%87%E5%82%A8%E5%AD%98%E4%B8%83%E7%89%9B%E4%BA%91/"},{"title":"django-allauth 阿里云发送邮件出现nginx 504解决方法","text":"前言在博客的认证中使用到了 django-allauth 模块进行用户注册登录，但是在注册环节配置邮箱系统的时候出了问题，搞了好几个小时终于解决了原来我的配置如下首先是github配置： Homepage URL: http://ginta.top/ Authorization callback URL: http://ginta.top/accounts/github/login/callback/ 这是settings.py django-allauth 配置 # django-allauth配置 ACCOUNT_EMAIL_VERIFICATION = 'mandatory' # 强制注册邮箱验证(注册成功后，会发送一封验证邮件，用户必须验证邮箱后，才能登陆) ACCOUNT_AUTHENTICATION_METHOD = &quot;username_email&quot; # 登录方式(选择用户名或者邮箱都能登录) ACCOUNT_EMAIL_REQUIRED = True # 设置用户注册的时候必须填写邮箱地址 ACCOUNT_LOGOUT_ON_GET = False # 用户登出(需要确认) # smtp 服务器地址 EMAIL_HOST = &quot;smtp.qq.com&quot; # 默认端口25，若请求超时可尝试465 EMAIL_PORT = 25 # 用户名 EMAIL_HOST_USER = &quot;.....@qq.com&quot; # 邮箱代理授权码（不是邮箱密码） EMAIL_HOST_PASSWORD = &quot;******&quot; # 发送人 EMAIL_FROM = &quot;.....@qq.com&quot; # # 默认显示的发送人，（邮箱地址必须与发送人一致），不设置的话django默认使用的webmaster@localhost DEFAULT_FROM_EMAIL = &quot;.....@qq.com&quot; 线下测试的时候没有问题，邮件也能发送，但是发布到阿里云上就是不行，一直出现邮件超时，也就是 nginx 504 的情况，网上有说把 nginx 超时时间改一下，我没尝试，一方面是因为默认已经是一分钟了，用户哪能等那么久，另一个是看到有说 25端口 在阿里云默认是关闭的，总之要进行一系列操作什么的，好在还可以用465端口，但是只把25端口改成465端口还是出现超时状态！！ ，后来有看到有加上一句 EMAIL_USE_SSL = True，于是试了一下，解决了。最后附上完整配置, github 配置不变，只改 settings.py 就好 ： # django-allauth配置 ACCOUNT_EMAIL_VERIFICATION = 'mandatory' # 强制注册邮箱验证(注册成功后，会发送一封验证邮件，用户必须验证邮箱后，才能登陆) ACCOUNT_AUTHENTICATION_METHOD = &quot;username_email&quot; # 登录方式(选择用户名或者邮箱都能登录) ACCOUNT_EMAIL_REQUIRED = True # 设置用户注册的时候必须填写邮箱地址 ACCOUNT_LOGOUT_ON_GET = False # 用户登出(需要确认) SOCIALACCOUNT_EMAIL_VERIFICATION = 'mandatory' # smtp 服务器地址 EMAIL_HOST = &quot;smtp.qq.com&quot; # 默认端口25，若请求超时可尝试465 EMAIL_PORT = 465 EMAIL_USE_SSL = True # 用户名 EMAIL_HOST_USER = &quot;***@qq.com&quot; # 邮箱代理授权码（不是邮箱密码） EMAIL_HOST_PASSWORD = &quot;****&quot; # 发送人 EMAIL_FROM = &quot;***@qq.com&quot; # # 默认显示的发送人，（邮箱地址必须与发送人一致），不设置的话django默认使用的webmaster@localhost DEFAULT_FROM_EMAIL = &quot;***@qq.com&quot;","link":"/2019/11/27/django-allauth%20%E9%98%BF%E9%87%8C%E4%BA%91%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E5%87%BA%E7%8E%B0nginx%20504%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"title":"django3 choices 新特性","text":"前言等了好久的 Django3 正式版本终于发布了！在看官方文档的时候看到有这么一句 Custom enumeration types TextChoices, IntegerChoices, and Choices are now available as a way to define Field.choices. TextChoices and IntegerChoices types are provided for text and integer fields 具体是什么意思呢，解释起来比较麻烦，还是上代码比较清晰： from django.db import models # Create your models here. class Student(models.Model): class Gender(models.IntegerChoices): MALE = 1 FEMALE = 2 gender = models.IntegerField(choices=Gender.choices) 这里新建了一个学生模型，里面只有一个性别字段。如果是以前的写法应该是这样： from django.db import models # Create your models here. class Student(models.Model): gender_choices = ( (1, '男'), (2, '女'), ) gender = models.IntegerField(choices=gender_choices) 直接看起来好像并没有方便多少，只是在内部新建了一个类而已，确实如此，不过还是有区别的，比如这里我们要求字段的值是 整数 ，新的写法会自动进行类型检查： class Student(models.Model): class Gender(models.IntegerChoices): MALE = &quot;ga&quot;, gettext_lazy('男') FEMALE = 2, gettext_lazy('女') gender = models.IntegerField(choices=Gender.choices) 如果我们这样写，MALE 的值改为 “ga”，在执行 python manage.py makemigrations 的时候会抛出以下错误： ValueError: invalid literal for int() with base 10: ‘ga’ 如果是以前的代码则不会报错。 这是后台显示，如果想显示中文也是可以的，把代码改成如下 from django.db import models from django.utils.translation import gettext_lazy # Create your models here. class Student(models.Model): class Gender(models.IntegerChoices): MALE = 1, gettext_lazy('男') FEMALE = 2, gettext_lazy('女') gender = models.IntegerField(choices=Gender.choices) 这就是效果了。如果是要求值是字符串，同理，只不过继承的类就不是 models.IntegerChoices ， 而是 models.TextChoices 。","link":"/2019/12/03/django3%20choices%20%E6%96%B0%E7%89%B9%E6%80%A7/"},{"title":"docker pull更换源","text":"前言每次使用docker pull的时候总是要等待很久，在不翻墙的情况下建议使用国内的源 步骤 在 /etc/docker/daemon.json 文件中添加以下参数（没有该文件则新建）： { &quot;registry-mirrors&quot;: [&quot;https://9cpn8tt6.mirror.aliyuncs.com&quot;] } 服务重启 systemctl daemon-reload systemctl restart docker","link":"/2020/08/30/docker%20pull%E6%9B%B4%E6%8D%A2%E6%BA%90/"},{"title":"do things matters","text":"最近在网上看到这么一句话，“do things matters”，后面的解释触发了共鸣： 这不仅意味着努力去核心岗位做重要的事情，还意味着每一件事都会因为是我做的，而 ‘matters’. 英雄联盟很多年前玩这个游戏的目的只有一个，上分。随着这款风靡全球的游戏流行，更多的玩家会选择在周末去网吧和朋友放飞自我，即使家用电脑已经普及，去网吧只是为了体验一种氛围。游戏机制导致天梯最多可以双人一起，因而大部分玩家更倾向于可以5人一起的匹配模式。同学几个人一起开黑的时候，我选择了单人Rank，而且选择相对较难的位置。室友曾经调侃：“你看我们大家一起玩多有意思，这游戏对于你来说简直就是孤儿游戏！” 每个人对游戏都有自己的理解，诚然游戏于大部分人来说只是一种释放压力的途径，我也一样，只是挑战更高难度对我来说也是十分重要的。 个体经济周末偶尔和朋友出门约饭，酒过三巡之后总要讨论一些时髦话题，比如哪个明星又怎样了，哪个国家政府被赶下去了，比特币最近又在作妖了……，不过此类话题基本都是几句带过，因为明星太过遥远，而币价也非我等韭菜可以操控的。最终个体经济这类话题占了上风，也往往会讨论很长时间，比如周边哪位同学的家里又帮忙购置不动产了，哪个亲戚又出国了。 对于家庭对个人的经济影响我始终保留自己的意见，天下家庭何其多，富甲终是少数，纵使家里没有条件给予更多的支持，亦或是可以包揽一切，由于着更多是上一辈人的结果，也就不会有更多的感触了。 do things matters维护一个开源项目，需要经常回答群里的问题，有人问过我：“为什么喜欢做开源”。 开源的话可以和很多用户沟通，他们会给出很多有趣的想法，有些建议是很有价值的，即使代码没有优化，修改之后产品本身对于用户也会更加友好。 不只是开源，即使是内部项目自己也是更希望能选择更有挑战性，反馈更多的项目去尝试，如果简单的事情太多了，也会和leader申请更具挑战的项目。 又回到开头的那句话了，“do things matters”。","link":"/2021/10/05/do%20things%20matters/"},{"title":"drf 一次错误排查","text":"前言在使用最新版本的 DRF 框架时，注册路由阶段报了一个错 “django.core.exceptions.ImproperlyConfigured: The included URLconf ‘bingo.urls’ does not appear to have any patterns in it. If you see valid patterns in the file then the issue is probably caused by a circular import.” 找了半天错误，期间反复查看官方文档都没有什么问题，最后使用删减排除了错误,原本用户的路由是这个 user_router.register(&quot;user&quot;, UserViewSet, base_name=&quot;user&quot;) 结果报错了，我改成以下代码： user_router.register(&quot;user&quot;, UserViewSet) 问题得到了解决，然而还是睡不着，这个参数在使用中还是很方便的，就这么删掉了肯定不好，于是上 github 查看了该项目的 issues，最后发现新版本的 base_name 已经被替换了： 于是把 base_name 改成了 basename，问题解决！","link":"/2020/02/12/drf%20%E4%B8%80%E6%AC%A1%E9%94%99%E8%AF%AF%E6%8E%92%E6%9F%A5/"},{"title":"路明非","text":"衰小孩12345678910111、所谓弃族的命运，就是要穿越荒原，再次竖起战旗，返回故乡。死不可怕，只是一场长眠。在我可以吞噬这个世界之前，与其孤独跋涉，不如安然沉睡。我们仍会醒来。2、同一条路，和某些人一起走，就长得离谱，和另外一些人走，就短得让人舍不得迈开脚步。3、可人不是断气的时候才真的死了。有人说人会死三次，第一次是他断气的时候，从生物学上他死了；第二次是他下葬的时候，人们来参加他的葬礼，怀念他的一生，然后在社会上他死了，不再会有他的位置；第三次是最后一个记得他的人把他忘记的时候，那时候他才真正的死了。4、这个世界其实从不曾有一个人能取代另一个人的位置，所谓的取代，只是以前的那个人被遗忘了。5、比孤独更可悲的事情，就是根本不知道自己很孤独，或者分明很孤独，却把自己都骗得相信自己不孤独。6、不需要计划，在我们的战场上是没有计划的。用绝对的力量，抹掉它。","link":"/2021/07/06/first/"},{"title":"supervisor + pipenv + uwsgi","text":"前言目前我部署 django 项目的方式是 uwsgi + nginx ，uwsgi 重启也很方便，只需要写一句 uwsgi –reload xxx.pid 即可，但是即使是一句我也不想输入了，就是比较懒，于是乎就有了 supervisor 管理 uwsgi 进程，配置好以后通过 web 网页点一下即可。 开始至于怎么配置 uwsgi 网上教程有很多，这里只讲一下怎么用 supervisor 启动。通过网上的教程可以先安装好 supervisor ，我这里有一篇 ubuntu python3 配置 supervisor 可供参考。我的 supervisor 配置目录结构如下： supervisor/ ├── conf.d │ ├── myblog.ini # 自己配的 ├── supervisord.conf # 初始化生成的配置文件（一开始就有，网上可以找到如何生成） └── var ├── log │ ├── myblog-stderr.log # 后续生成的 │ ├── myblog-stdout.log # 后续生成的 │ └── supervisord.log # 后续生成的 ├── supervisord.pid # 后续生成的 └── supervisor.sock # 后续生成的 supervisor 文件夹是在 /etc 下面。首先配置 supervisor/supervisord.conf 文件，有几个地方改了一下： 让 socket 文件生成在 ~/etc/supervisor/var/ 目录下。注意 supervisor 不支持将 ~ 展开为用户 home 目录，所以要用绝对路径指定。我这里是 root 用户，这样直接写就可以，其他用户的路径类似于 /home/username/etc/supervisor…** [unix_http_server] file=/etc/supervisor/var/supervisor.sock ; the path to the socket file 修改 [inet_http_server] ，这一步主要是可以通过外部浏览器来进行控制 supervisor 进程，其中 端口号像我这样配置成 port=*:9001 ，就可以在外网通过服务器的域名下的 9001 端口来控制，默认是没有密码的，但是最好配置一下 [inet_http_server] ; inet (TCP) server disabled by default port=*:9001 ; ip_address:port specifier, *:port for all iface ;username=user ; default is no username (open server) ;password=123 ; default is no password (open server) 类似的修改 [supervisord] 板块下的 logfile 和 pidfile 文件的路径，还有 user 改为系统用户，这样 supervisor 启动的进程将以系统用户运行，避免可能的权限问题,**注意 supervisor 不支持将 ~ 展开为用户 home 目录，所以要用绝对路径指定。我这里是 root 用户，这样直接写就可以，其他用户的路径类似于 /home/username/etc/supervisor…**： [supervisord] logfile=/etc/supervisor/var/log/supervisord.log ; main log file; default $CWD/supervisord.log pidfile=/etc/supervisor/var/supervisord.pid ; supervisord pidfile; default supervisord.pid user=root ; setuid to this UNIX account at startup; recommended if root [supervisorctl]板块下： [supervisorctl] serverurl=unix:///etc/supervisor/var/supervisor.sock ; use a unix:// URL for a unix socket [include] 版块,将 /etc/supervisor/conf.d/ 目录下所有以 .ini 结尾的文件内容包含到配置中来，这样便于配置的模块化管理。 [include] files = /etc/supervisor/conf.d/*.ini 配置 管理uwsgi进程 的配置文件在 /etc/supervisor/conf.d/ 目录下新建一个配置文件，名字以 .ini 结尾就好，是因为我们在 supervisor.conf 文件中修改了配置 [include] ，所以 supervisor 会搜索 /etc/supervisor/conf.d/ 目录下所有以 .ini 结尾的文件。这是我的配置文件 [program:myblog] command=pipenv run uwsgi --ini /root/mysite_uwsgi/myblog.ini directory=/root/code/Workspace/ginta.top autostart=true autorestart=unexpected user=root stdout_logfile=/etc/supervisor/var/log/myblog-stdout.log stderr_logfile=/etc/supervisor/var/log/myblog-stderr.log program:hellodjango-blog-tutorial] 指明运行应用的进程，名为 hellodjango-blog-tutorial。 command 为进程启动时执行的命令， 我的环境是用 pipenv 来进行包管理的所以要这样执行，如果没有用包管理直接执行 uwsgi --ini /root/mysite_uwsgi/myblog.ini 即可，也就是 uwsgi 的启动命令。 directory 指定执行命令时所在的目录。 autostart 随 Supervisor 启动自动启动进程。 autorestart 进程意外退出时重启。 user 进程运行的用户，防止权限问题。 stdout_logfile，stderr_logfile 日志输出文件。6. 启动 Supervisor supervisord -c ~/etc/supervisord.conf 进入 supervisorctl 进程管理控制台： supervisorctl -c ~/etc/supervisord.conf 执行 update 命令更新配置文件并启动应用。 浏览器输入域名，可以看到服务已经正常启动了。 注意 由于我们 supervisor 有配置项目的日志，所以如果在 uwsgi.ini 中配置有日志，请把它注释掉 # myblog.ini （项目的uwsgi配置） # daemonize = /root/mysite_uwsgi/myblog.log # 日志管理 如果之前就已经运行了 uwsgi，请一定要先退出再重启 supervisor supervisor/supervisord.conf 文件的注释符号是 **;**，比如 *;[eventlistener:theeventlistenername]*，所以我们所有的配置前面如果有 ; ，请删掉，比如把 ;[eventlistener:theeventlistenername] 改成 [eventlistener:theeventlistenername] ，不然会视作没有配置。 本文配置参考了追梦人物的博客。","link":"/2019/11/19/supervisor%20+%20pipenv%20+%20uwsgi/"},{"title":"ubuntu python3.7 安装uwsgi 常见错误","text":"前言由于需要在 ubuntu18.04 系统部署 django 项目，用到了 uWSGI 库，在安装的时候遇到了几个问题在这里记录一下原因，并附上解决方法。 Retrying (Retry(total=4, connect=None….这是比较常见的问题，原因是安装超时，因为我们下载的库的源一般都是在国外，涉及到翻墙问题，解决方法是更换国内的源，注明的有阿里，豆瓣等，这里我用到的是豆瓣源:pip install -i https://pypi.doubanio.com/simple uwsgi前面 -i 是指明更换源路径，最后的 uwsgi 就是本次我要安装的 uWSGI 库 error: invalid command ‘bdist_wheel’这个问题一般是 pip 版本比较老了，更新一下即可尝试用以下命令升级以下pip版本后再试一下:python -m pip install –upgrade pip如果装着python3.X ，那么就用:python3 -m pip install –upgrade pip fatal error: Python.h网上说的是因为环境不完整，安装如下这个包：python2：sudo apt-get install python-devpython3:sudo apt-get install python3-dev确实是这个问题，不过可能是我的 python 版本比较新吧，是 python3.7.2 ，也可能是其他原因总之最后安装 uWSGI 还是失败了，网上还有一个库是真的比较新版本的 python3.7+ ：sudo apt install python3.7-dev安装成功~","link":"/2019/11/26/ubuntu%20python3.7%20%E5%AE%89%E8%A3%85uwsgi%20%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"},{"title":"ubuntu 部署 django2.0 + uwsgi + nginx","text":"django 默认的服务是单进程的，而且处理静态文件也比较慢，我们采用 django + uwsgi + nginx 来提高并发数的同时减少静态文件的访问时间。 nginx 安装nginxapt-get install nginx 进入 /etc/nginx 路径下可以看到两个文件夹，sites-available 和 sites-enabled，前者是网站的可用配置文件夹，后者是启用的配置，一般都是把配置文件放到 sites-available 再通过软链接的方式在 sites-enabled 中启用配置。 进入 sites-available 文件夹中，新建配置文件arrange.conf，内容如下 server { listen 80; # 网站对外的端口为80 server_name ginta.top; # 服务名字（一般是用域名方便理解） charset utf-8; # 字符编码 client_max_body_size 75M; # 上传文件的最大尺寸 location /static { alias /home/admin/code/Workspace/arrange/static; # 静态文件的访问路径 } location /media{ alias /home/admin/code/Workspace/arrange/media; # 媒体资源的访问路径 } location / { # 发送请求给django，nginx处理不了，我们要转发给uwsgi，除了 static 和 media 其他的转发给uwsgi uwsgi_pass 127.0.0.1:8001; include /etc/nginx/uwsgi_params; # uwsgi协议配置文件，类似于nginx.conf，django没有，但是nginx下有个这样的文件 } } 删除 sites-enabled 文件夹下的default文件，否则服务可能无法启动，卡在nginx欢迎界面 uWSGI 安装uWSGI，可能出现的错误在这里有 解决方式. pip install uwsgi2. 测试，创建一个 foobar.py 的文件，内容如下 : def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return [b&quot;Hello World&quot;] 然后通过服务器的 9090 端口进行测试uwsgi --http :9090 --wsgi-file foobar.py访问成功即可。3. 编写项目uwsgi配置文件然后选择一个目录新建个文件作为项目的 uwsgi 配置文件,我这里是 arrange.ini [uwsgi] chdir = /home/admin/code/Workspace/arrange # 项目的绝对路径 virtualenv = /home/admin/code/Envs/blog # 我这里用的是虚拟环境 module = arrange.wsgi:application # 项目的wsgi，我的项目名是 **arrange** master = True # 启动主程序 processes = 4 # 使用的进程数 harakiri = 60 # 请求60s超时关闭 max-requests = 5000 # 请求超过5000进程重启防止内存泄漏 socket = 127.0.0.1:8001 # 监听的端口 uid = nginx # 使用nginx代替root用户 （安全一些） gid = nginx # 使用nginx代替root用户 pidfile = /home/admin/mysite_uwsgi/master.pid # 通过 pidfile 对主进程进行关闭，启动或者重启操作 daemonize = /home/admin/mysite_uwsgi/arrange.log # 指定日志存放路径 vacuum = True # 当服务器关闭会自动把pidfile和daemonize进程回收 启动项目uwsgiuwsgi --ini arrange.ini 进入 /etc/nginx/ 路径，简历配置文件软链接sudo ln -s /etc/nginx/sites-available/arrange.conf /etc/nginx/sites-enabled/arrange.conf 测试一下nginx有没有问题sudo nginx -t出现 successful 表示没有问题 重启nginxsudo service nginx restart 补充uwsgi 重启服务,由于我们配置了pidfile路径，所以可以很快捷地重启uwsgi --reload /home/admin/mysite_uwsgi/master.pid想看看启动没有可以通过 ps 指令ps -aux | grep uwsgi","link":"/2019/11/26/ubuntu%20%E9%83%A8%E7%BD%B2%20django2.0%20+%20uwsgi%20+%20nginx/"},{"title":"win10 osg.js 使用","text":"引言有位朋友希望可以在win10上部署一个 osg.js 服务，虽然在这之前我也没用过 osg.js ，不过看了下官方基本的 doc，由于是涉及到美术行业内容不是很懂，不过部署貌似也不复杂。 安装依赖该工程一共需要2个依赖，一个是 Git ，另外就是 npm。首先安装 Git ，点击此处的下载链接下载安装包，一直下一步就好。其次安装 npm，这里参考廖雪峰教程就可以。 下一步这是官方链接，部署非常简单，首先在电脑上安装一个 git 把代码 clone 下来，找一个存放工程的目录，右键，点击 Git Bash Here： 然后执行 $ git clone git://github.com/cedricpinson/osgjs.git，接下来就可以在目录下看到一个 osgjs 文件夹。接下来进入这个文件夹 $ cd osgjs/，依次执行四条命令： npm install -g grunt-cli npm install grunt build grunt serve不出意外可以看到这个界面 打开浏览器访问 http://localhost:9000/ ，然后就可以体验了 虽然不是这个方向，但感觉还是挺不错的。 小结整个过程还是挺简单的，最费时间的是执行 grunt serve 这一步，因为要从其他仓库下载模型，而且还是外网，所以非常耗时，建议采用 科学上网 的方式执行。我当时执行这一步的时候真的是失败了N次，但是想着答应要尽力的，最终还是耐心多尝试，最后成功了，挺高兴的。","link":"/2019/12/03/win10%20osg.js%20%E4%BD%BF%E7%94%A8/"},{"title":"windows 安装 helm","text":"安装到 helm的Github仓库 找到解压后把这个目录加入环境变量就可以了","link":"/2021/07/01/windows%20%E5%AE%89%E8%A3%85%20helm/"},{"title":"windows终端命令行下使用网络代理","text":"右键打开 ShadowsocksR 的 选项设置 设置你的HTTP和HTTPS的代理端口 打开cmd窗口，设置代理变量 set HTTP_PROXY=http://127.0.0.1:1080 set HTTPS_PROXY=http://127.0.0.1:1080 如果设置了用户名和密码 set HTTP_PROXY=http://proxy.com:port set HTTP_PROXY_USER=username set HTTP_PROXY_PASS=password set HTTPS_PROXY=http://proxy.com:port set HTTPS_PROXY_USER=username set HTTPS_PROXY_PASS=password 上面命令的作用是设置环境变量，不用担心，这种环境变量只会持续到cmd窗口关闭，不是系统环境变量。 如何取消代理呢: netsh winhttp reset proxy","link":"/2020/05/04/windows%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E4%BD%BF%E7%94%A8%E7%BD%91%E7%BB%9C%E4%BB%A3%E7%90%86/"},{"title":"wsl2 安装 Centos8","text":"前言由于开发需要安装 centos 版本的 wsl， 但 Windows Store 里只有 Ubuntu、Debian 等 kernel，好消息是 Github 上可以找到对应版本的安装包。 安装 ChocolateyNuGet（读作New Get）是用于微软.NET开发平台的软件包管理器，是一个Visual Studio的扩展。Chocolatey 是基于 NuGet 的一个软件包管理器，就像 Linux 中的 yum 或 apt 一样，在 Windows10 中也可以用命令行安装程序了。 右键单击开始菜单，选择 Windows PowerShell(管理员)，打开一个具有管理员权限的 PowerShell 窗口，输入命令并回车： 1Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) 完成后，输入命令：choco ，如果能正确显示版本号，说明安装成功。 详情请查看官网文档安装说明 LxRunOffline 是非常实用的 WSL 管理软件，可以备份、创建、恢复、导出WSL子系统，也可以安装适配 WSL 的任何 Linux 发行版，可以将 WSL 子系统安装到任意目录中。在 PowerShell 窗口中输入命令安装LxRunOffline，安装完成后重启 PowerShell。 1choco install lxrunoffline -y 安装 Centos8 wsl打开链接，这里直接下载 CentOS8-stream.zip ，解压后会发现有一个 rootfs.tar.gz 文件，使用 lxrunoffline install -n CentOS -d F:/centos -f E:\\CentOS8-stream\\rootfs.tar.gz 命令来安装，其中 -d 后面是 kernel 想要安装到的位置，**-f** 的参数是 rootfs.tar.gz 的所有路径。然后将这个发行版设置为 WSL2：wsl --set-version CentOS 2 换源由于默认源都用的国外安装路径，下载东西很慢，需要换成阿里源 备份原文件123456cd /etc/yum.repos.dmv CentOS-Base.repo CentOS-Base.repo.bakmv CentOS-extras.repo CentOS-extras.repo.bakmv CentOS-centosplus.repo CentOS-centosplus.repo.bakmv CentOS-PowerTools.repo CentOS-PowerTools.repo.bakmv CentOS-AppStream.repo CentOS-AppStream.repo.bak 下载12# wget -O CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repovi CentOS-Stream-BaseOS.repo 这里有两点需要解释一下，目前安装的 centos8 没有内置 wget 和 vim ，不过上边只是一个文件，可以用 windows 下载完之后将里面的内容复制一下，然后粘贴到 CentOS-Stream-BaseOS.repo 保存就好。 删除缓存并生成新的缓存12dnf clean alldnf makecache wsl2配置使用windows网络代理我想要在 wsl2 上安装 helm ，脚本中有需要访问外网，这就需要一个代理。不过我的 windows 已经有代理了，只需要让它使用 windows 的代理就好。 wsl2获取win10 ip cat /etc/resolv.conf|grep nameserver|awk ‘{print $2}’ =&gt; 例如：172.20.192.1注：由于windows防火墙的存在，此时可能出现ping 172.20.192.1失败 新建防火墙入站规则 打开控制面板\\系统和安全\\Windows Defender 防火墙 点击入站规则-&gt;新建规则 规则类型：自定义 程序：所有程序 协议和端口：默认即可 作用域： 本地ip处选择“任何IP地址” 远程ip处选择“下列IP地址”，并将wsl2的IP添加进去。（请根据自己wsl2的ip进行计算，我这里添加了172.20.192.1/20）（掩码一般是20位） 操作：允许连接 配置文件：三个全选 名称描述：请自定义 注意：这一步完成后，从wsl2 ping主机的ip应该可以ping通了。 防火墙配置 打开控制面板\\系统和安全\\Windows Defender 防火墙\\允许的应用。 将与代理相关的应用程序均设置为：允许其进行专用、公用网络通信。 特别注意的是：将Privoxy也配置为允许 windows端代理软件配置 启用“允许来自局域网的连接” 测试 在wsl2中配置http代理，如export http_proxy=”http://172.20.192.1:1080&quot;。注意：端口号请结合自己的代理设置进行修改 执行命令curl cip.cc查看ip地址 部分资料参数文章 arp命令 centos 安装_WSL2子系统安装CentOS8及源码编译Nginx1.18+PHP7.4+MySql8.0开发环境… wsl2配置使用windows网络代理","link":"/2021/07/04/wsl2%20%E5%AE%89%E8%A3%85%20Centos8/"},{"title":"《大秦帝国》终于到了","text":"NNQI前天下单的书终于到了！！！ 一度上次看《大秦帝国》 还是在四川。那时周末会在成都图书馆做志愿者，一般休息的时候都会看看杂志，读者、格言、意林、青年文摘，有时也会看看达芬奇和梵高的作品，虽然始终无法领会他们的境界。偶尔到借阅区转了一圈，就在书架最上层看到了一本《大秦帝国》，当时第一部已经外借出去了，只留下一本第二部的“国命纵横”，大致翻了一下感觉还行，讲的是纵横家苏秦和张仪各自选择不同的国家实现自己的抱负，书中用词没有让我感到浮夸的地方，整体印象就是行文恰到好处。回家的时候顺便也就借走了，不过那一个月也比较忙，没看完就还回去了。 二重平时在公司午休的时候也基本都是看看杂志，周末的话会多睡几个小时。一段时间没有认真地阅读一部小说总是会感到有些不安，前两天考虑了一下还是决定把之前没有读完的《大秦帝国》通读一遍，至于读完以后再买什么书就是之后的事情了。 当我还是个孩子的时候，我吃过很多食物，现在已经记不起来吃过什么了。但可以肯定的是，它们中的一部分已经成长为我的骨头和肉。 –三毛","link":"/2020/04/02/%E3%80%8A%E5%A4%A7%E7%A7%A6%E5%B8%9D%E5%9B%BD%E3%80%8B%E7%BB%88%E4%BA%8E%E5%88%B0%E4%BA%86/"},{"title":"删除排序数组中的重复项","text":"给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。 不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。 给定数组 nums = [1,1,2],函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。你不需要考虑数组中超出新长度后面的元素。 思路使用双游标方法 flag 来记录当前数组不重复的位置，而变量 j 控制整个数组的遍历；当 flag 位置的数据和 j 位置的数据不同时则说明有新的，也就是有效变量进入，此时 flag 加 1，同时也要把 j 位置的值给 flag 位置。 class Solution: def removeDuplicates(self, nums: List[int]) -&gt; int: flag = 0 for j in range(1, len(nums)): if nums[j] != nums[flag]: flag += 1 nums[flag] = nums[j] return flag+1","link":"/2019/12/21/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"title":"围棋第一次胜局","text":"心血来潮前几天弟弟说考试比上次进步了，想让得到茫茫多的零食大礼包作为鼓励。考虑到现在的学生也是蛮辛苦的，于是果断奖励了三本课外书，除了《活着》是应付老妈的，《禁区法则》和《天局》一如既往地中二。其中《天局》讲的就是凡人与天人下围棋最终以半子取胜的故事。 入门给他普及了《天局》故事后顺手就下了个围棋app，百度了一下教程就算入门了。开始是和玩家对弈，想了想不恶心别人了，就人机互啄，难度从入门级降到了儿童级。几天之内下了10几局吧，无一例外全输了，直到今天晚上，终于赢了一局，万分感动。附上图以作记录 其他想说的事实证明围棋入门并不难，只是想要精通还是不容易的。比较考验大局观，一子的得失有时候并不重要，总之能赢第一局还是挺高兴的。","link":"/2021/07/08/%E5%9B%B4%E6%A3%8B%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%83%9C%E5%B1%80/"},{"title":"数据库定时备份任务","text":"前言最近因为一次误操作不小心把博客的数据库文件删除了，当时感觉自然是难受的。不过幸运的是之前移动博客文件的时候曾把数据和项目打包了，所以文件又找回来了！！！虽然文件是找回来了，不过这种情况难免再次发生，而且下次就不一定能找回来了。于是决定写一个定时任务每天备份一下数据库文件。 使用的第三方库是 apscheduler，简单的介绍可以看 apscheduler，更具体的请参考 文档 代码如下： # backup_db.py import os import datetime from apscheduler.schedulers.blocking import BlockingScheduler file_path = &quot;/root/Workspace/ginta.top/myblog/myblog/db.sqlite3&quot; backup_dir = &quot;/root/data/backup_blog_db&quot; def backup_db(file_path, backup_dir): now = datetime.datetime.now() date = datetime.datetime.strftime(now, &quot;%Y-%m-%d&quot;) backup_dir = os.path.join(backup_dir, date) os.system(&quot;mkdir {}&quot;.format(backup_dir)) backup_file_dir = os.path.join(backup_dir) os.system(&quot;cp {} {}&quot;.format(file_path, backup_file_dir)) print(&quot;{} backup_finished&quot;.format(date)) if __name__ == &quot;__main__&quot;: print(&quot;backup_script start!&quot;) sched = BlockingScheduler() sched.add_job(backup_db, 'interval', [file_path, backup_dir], seconds=60 * 60 * 24) sched.start() 然后执行 nohup python -u backup_db.py &gt; /root/data/log/back_db/backup_db.log 2&gt;&amp;1 &amp; 就放到后台了 总结实现了每天定时备份一次数据库，但是也很不优雅。 在 python 脚本中执行 mkdir 和 cp 命令是很不好的. 以后脚本多了就很不好管理，问了一下公司我带的大佬推荐了两种管理方式，分别是 jenkins 和 crontab.","link":"/2020/03/28/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD%E4%BB%BB%E5%8A%A1/"},{"title":"来到深圳","text":"很早以前，还是上大二的时候就一直想到深圳发展，后来毕业了就在成都工作。想了很久最后还是来到了深圳，虽然没有亲戚和同学，幸运的是仍有朋友在我刚到深圳的时候招待了一天，还帮我一起去租房。虽然今后怎样还是个未知数，但想想曾经帮助过我的人，还是有了奋斗的动力！！","link":"/2019/12/15/%E6%9D%A5%E5%88%B0%E6%B7%B1%E5%9C%B3/"},{"title":"树莓派4b ubuntu 20 设置阿里源","text":"前言设置国内源其实很简单，但是由于我是下载的 64位 操作系统，并且树莓派是arm架构，所以有一点不同执行 lsb_release -a 查看发行版本 ubuntu@ubuntu:/etc/netplan$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.1 LTS Release: 20.04 Codename: focal 所以修改配置文件 sudo vim /etc/apt/sources.list: ## Note, this file is written by cloud-init on first boot of an instance ## modifications made here will not survive a re-bundle. ## if you wish to make changes you can: ## a.) add 'apt_preserve_sources_list: true' to /etc/cloud/cloud.cfg ## or do the same in user-data ## b.) add sources in /etc/apt/sources.list.d ## c.) make changes to template file /etc/cloud/templates/sources.list.tmpl # See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to # newer versions of the distribution. deb http://mirrors.aliyun.com/ubuntu-ports focal main restricted # deb-src http://mirrors.aliyun.com/ubuntu-ports focal main restricted ## Major bug fix updates produced after the final release of the ## distribution. deb http://mirrors.aliyun.com/ubuntu-ports focal-updates main restricted # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-updates main restricted ## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu ## team. Also, please note that software in universe WILL NOT receive any ## review or updates from the Ubuntu security team. deb http://mirrors.aliyun.com/ubuntu-ports focal universe # deb-src http://mirrors.aliyun.com/ubuntu-ports focal universe deb http://mirrors.aliyun.com/ubuntu-ports focal-updates universe # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-updates universe ## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu ## team, and may not be under a free licence. Please satisfy yourself as to ## your rights to use the software. Also, please note that software in ## multiverse WILL NOT receive any review or updates from the Ubuntu ## security team. deb http://mirrors.aliyun.com/ubuntu-ports focal multiverse # deb-src http://mirrors.aliyun.com/ubuntu-ports focal multiverse deb http://mirrors.aliyun.com/ubuntu-ports focal-updates multiverse # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-updates multiverse ## N.B. software from this repository may not have been tested as ## extensively as that contained in the main release, although it includes ## newer versions of some applications which may provide useful features. ## Also, please note that software in backports WILL NOT receive any review ## or updates from the Ubuntu security team. deb http://mirrors.aliyun.com/ubuntu-ports focal-backports main restricted universe multiverse # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-backports main restricted universe multiverse ## Uncomment the following two lines to add software from Canonical's ## 'partner' repository. ## This software is not part of Ubuntu, but is offered by Canonical and the ## respective vendors as a service to Ubuntu users. # deb http://archive.canonical.com/ubuntu focal partner # deb-src http://archive.canonical.com/ubuntu focal partner deb http://mirrors.aliyun.com/ubuntu-ports focal-security main restricted # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-security main restricted deb http://mirrors.aliyun.com/ubuntu-ports focal-security universe # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-security universe deb http://mirrors.aliyun.com/ubuntu-ports focal-security multiverse # deb-src http://mirrors.aliyun.com/ubuntu-ports focal-security multiverse 注意由于是 arm架构，一定要改成 http://mirrors.aliyun.com/ubuntu-ports 而不是 http://mirrors.aliyun.com/ubuntu，否则无法正常更新下载！！！。","link":"/2020/09/05/%E6%A0%91%E8%8E%93%E6%B4%BE4b%20ubuntu%2020%20%E8%AE%BE%E7%BD%AE%E9%98%BF%E9%87%8C%E6%BA%90/"},{"title":"树莓派frp内网穿透","text":"前言目的是实现外网连接树莓派 步骤# 客户端（树莓派）frpc.ini [common] server_addr = 120.79.215.235 server_port = 7000 [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 然后执行 ./frps -c ./frps.ini # 服务端（阿里云服务器） [common] [common] # 本机公网ip 120.79.215.235 bind_port = 7000 然后执行 ./frpc -c ./frpc.ini 最后通过 xshell 连接 或者命令行 ssh -oPort=6000 pi@120.79.215.235但是不知道为什么命令行的方式在 xshell 老提示密码错误。","link":"/2020/05/30/%E6%A0%91%E8%8E%93%E6%B4%BEfrp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"title":"树莓派ubuntu 20 网络设置","text":"前言在树莓派4B上配置一个 ubuntu 20 LTS 网络环境折腾了挺久的，在此记录一下以免下次再次采坑。 1234567891011121314151617181920212223242526272829# 编辑 /etc/netplan/50-cloud-init.yaml 改成如下network: ethernets: eth0: dhcp4: true optional: true version: 2 wifis: wlan0: access-points: &quot;Danke42168_1&quot;: # 这个是wifi名字 password: &quot;wifi.danke.life&quot; # 这是wifi密码 dhcp4: true optional: true 最后如果没有显示器可以先修改 root文件夹下的 network-config 文件， 一定要在第一次开机前设置，否则无法生效。不过由于安装包用的是国外的源，所以一般还是要接上显示器来配置国内源 如果想设置固定ip可以追加配置，最终配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# This file is generated from information provided by the datasource. Changes# to it will not persist across an instance reboot. To disable cloud-init's# network configuration capabilities, write a file# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:# network: {config: disabled}network: ethernets: eth0: dhcp4: true optional: true version: 2 wifis: wlan0: access-points: &quot;Danke42168_1&quot;: password: &quot;wifi.danke.life&quot; dhcp4: true optional: true addresses: [192.168.124.18/24] gateway4: 192.168.124.1 nameservers: addresses: [192.168.124.1, 8.8.8.8]","link":"/2020/09/05/%E6%A0%91%E8%8E%93%E6%B4%BEubuntu%2020%20%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE/"},{"title":"树莓派ubuntu 20 安装k3s","text":"安装到 helm的Github仓库 找到解压后把这个目录加入环境变量就可以了","link":"/2021/02/11/%E6%A0%91%E8%8E%93%E6%B4%BEubuntu%2020%20%E5%AE%89%E8%A3%85k3s/"},{"title":"树莓派固定ip设置","text":"前言由于没有多余的屏幕以及鼠标和键盘等外设（就是有也没空间放），所以树莓派只能通过 xshell 连接，先前我是可以连接上的，但是由于 ip 发生了变化所以又要重新连上屏幕查看 ip，但是以后难免还会发生这样的事情。一劳永逸的方法是设置一个固定 ip 这样下次登录就不会发生之前的问题了。 步骤操作也很简单树莓派中有个文件可以实现固定 ip 的设置，执行 vim /etc/dhcpcd.conf，修改配置文件 # 在最后加入下面几行 # 指定接口 wlan0 interface wlan0 # 指定静态IP，/24表示子网掩码为 255.255.255.0 static ip_address=192.168.124.18/24 # 路由器/网关IP地址 static routers=192.168.124.1 # 手动自定义DNS服务器 static domain_name_servers=114.114.114.114 然后执行 sudo reboot 即可，之后便可以通过 xshell 等工具进行连接这里有两点需要注意 我的路由器 ip 是 192.168.124.1 ，但是常见的一般是 192.168.1.1 和 192.168.0.1 static ip_address=192.168.124.18/24，这一项要保证 18端口没有被占用，简单的方法就是 ping 192.168.124.18 如果没有响应就可以了 其他至于树莓派怎么连接 wifi 参考 无屏幕和键盘配置树莓派WiFi和SSH。","link":"/2020/05/30/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%9B%BA%E5%AE%9Aip%E8%AE%BE%E7%BD%AE/"},{"title":"时生","text":"《时生》看完了，区别于之前看过的东野圭吾的小说，没有涉及到凶杀，这本小说讲的是时生从未来回到过去找寻自己的父亲（拓实）。内容没有留下很深的印象，大概就是时生让父亲直面自己弃婴这一身世，原谅奶奶当初把他送人这一无奈举动，小说最后时生告别父亲后就消失了。 读完后还是想了很多，比如自己像时生一样在生命快要终结的时候意外回到了十几年前，有机会重写这一段过去，又会做什么不一样的选择？时间究竟是什么，时生竭力去改变父亲，做了很多事，结局和历史依旧是重合的。是不是意味时间就是那么神奇，即使有机会回到过去，以为改变了很多，实际上什么都没有改变，过去即是未来，未来即是过去。 如果历史真的可以改变，改变后的历史还是历史吗？会不会像龙珠所讲的每次穿越时间，只是凭空多出一个平行的时间线？","link":"/2022/08/23/%E6%97%B6%E7%94%9F/"},{"title":"Fabric实践","text":"安装参考Install Fabric and Fabric Samples Fabric Samples第一步快速起一个Fabric测试网络，官方给了一个非常方便的项目用来学习 123456789101112131415161718# clone fabric-samplesgit clone git@github.com:hyperledger/fabric-samples.git # 初始化数据仓库（用来放后续的peer、ca等数据）mkdir ~/data/fabric-datacd ~/data/fabric-data# 脚本要启动一个fabric测试网络需要下载相关镜像，还有一些工具放到了[fabric-samples](https://github.com/hyperledger/fabric-samples) 这个仓库，官方给了一个一键执行的脚本curl -sSLO https://raw.githubusercontent.com/hyperledger/fabric/main/scripts/install-fabric.sh &amp;&amp; chmod +x install-fabric.sh./install-fabric.sh -h 可以看一下有什么操作# clone fabric-samples仓库，下载相关镜像./install-fabric.sh docker samples## 下载Fabric二进制执行文件./install-fabric.sh --fabric-version 2.2.1 binary 运行网络12345678910cd fabric-samples/test-network# 先干掉之前运行的容器（如果是第一次运行就不用了）./network.sh down# 启动网络./network.sh up# 创建一个通道，第二个参数是名字，没写的话默认是mychannel./network.sh createChannel./network.sh createChannel -c channel1./network.sh createChannel -c channel2 链码部署12# 把链码安装到peer0.org1.example.com和peer0.org2.example.com两个peer./network.sh deployCC -ccn basic -ccp ../asset-transfer-basic/chaincode-go -ccl go 交互1234567891011121314151617181920212223242526272829303132333435# 如果按照上边的步骤走下来会发现fabric-samples目录下有个bin文件夹，我们把它加到环境变量export PATH=${PWD}/../bin:$PATH# 设置环境变量FABRIC_CFG_PATH来指定core.yamlexport FABRIC_CFG_PATH=$PWD/../config/# 现在来设置环境变量方便操作Org1# Environment variables for Org1export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=localhost:7051# 初始化账本peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile &quot;${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem&quot; -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles &quot;${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt&quot; --peerAddresses localhost:9051 --tlsRootCertFiles &quot;${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt&quot; -c '{&quot;function&quot;:&quot;InitLedger&quot;,&quot;Args&quot;:[]}'# 查询账本资产peer chaincode query -C mychannel -n basic -c '{&quot;Args&quot;:[&quot;GetAllAssets&quot;]}'# 转移资产peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile &quot;${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem&quot; -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles &quot;${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt&quot; --peerAddresses localhost:9051 --tlsRootCertFiles &quot;${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt&quot; -c '{&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset6&quot;,&quot;Christopher&quot;]}'# 同理我们设置Org2的环境变量# Environment variables for Org2export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=localhost:9051# 使用Org2 peer来查询（注意上方的环境变量已经用Org2覆盖了之前的Org1的peer chaincode query -C mychannel -n basic -c '{&quot;Args&quot;:[&quot;ReadAsset&quot;,&quot;asset6&quot;]}' 删除测试数据12这条命令会把我们的peer，order节点，volume(持久化文件)，还有CA证书，Org相关文件全部删掉./network.sh down 至此我们已经简单走了一下Fabric的搭建流程！ 部署智能合约安装，背书123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 启动测试网络cd fabric-samples/test-network./network.sh down # 先清掉历史数据./network.sh up createChannel./monitordocker.sh fabric_test # 创建一个日志收集器# 我们这里安装go版本的合约cd fabric-samples/asset-transfer-basic/chaincode-goGO111MODULE=on go mod vendorcd ../../test-networkexport PATH=${PWD}/../bin:$PATHexport FABRIC_CFG_PATH=$PWD/../config/# 打包合约代码peer lifecycle chaincode package basic.tar.gz --path ../asset-transfer-basic/chaincode-go/ --lang golang --label basic_1.0# 指定Org1环境变量export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=localhost:7051# peer1节点安装链码peer lifecycle chaincode install basic.tar.gz# 指定Org2环境变量export CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=localhost:9051# peer2节点安装链码peer lifecycle chaincode install basic.tar.gz# 查看链码安装peer lifecycle chaincode queryinstalled# 把链码id设置到环境变量export CC_PACKAGE_ID=basic_1.0:69de748301770f6ef64b42aa6bb6cb291df20aa39542c3ef94008615704007f3# Org2赞同链码（由于上边我们切到了Org2的环境变量）peer lifecycle chaincode approveformyorg -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --channelID mychannel --name basic --version 1.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile &quot;${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem&quot;# 切回Org1，赞同链码export CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_ADDRESS=localhost:7051peer lifecycle chaincode approveformyorg -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --channelID mychannel --name basic --version 1.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile &quot;${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem&quot; 使链码在channel(通道)上生效12345678# 先查看一下链码的背书情况（两个peer都签名了)peer lifecycle chaincode checkcommitreadiness --channelID mychannel --name basic --version 1.0 --sequence 1 --tls --cafile &quot;${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem&quot; --output json# commit链码到channel(通道)peer lifecycle chaincode commit -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --channelID mychannel --name basic --version 1.0 --sequence 1 --tls --cafile &quot;${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem&quot; --peerAddresses localhost:7051 --tlsRootCertFiles &quot;${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt&quot; --peerAddresses localhost:9051 --tlsRootCertFiles &quot;${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt&quot;# 查看通道上的链码peer lifecycle chaincode querycommitted --channelID mychannel --name basic --cafile &quot;${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem&quot; 调用链码12345peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile &quot;${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem&quot; -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles &quot;${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt&quot; --peerAddresses localhost:9051 --tlsRootCertFiles &quot;${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt&quot; -c '{&quot;function&quot;:&quot;InitLedger&quot;,&quot;Args&quot;:[]}'# 查看账本peer chaincode query -C mychannel -n basic -c '{&quot;Args&quot;:[&quot;GetAllAssets&quot;]}'","link":"/2022/11/15/Fabric%E5%AE%9E%E8%B7%B5/"},{"title":"一起聊聊团队协同","text":"有段时间没跑步了，running Page 上的记录还停留在上个月的11号。今天心血来潮想把荒废40多天的跑步再拯救一下。 开始跑的时候是听纯音乐的，中间突然想到 yihong 大佬会跑步的时候听一些播客，就打开小宇宙听了最近的一期 科技双眼啤 ，主题是 一起聊聊团队协同(ft.陈皓 - MegaEase 创始人)，跑完播客大约还有一个小时左右才结束，就绕着小区一直走，期间看到有个人在不起眼的角落里练萧，想上去聊两句又怕打扰他，想等他练完再去搭讪的，可惜又绕了两圈之后他已经回家了，不过同住一个小区之后大概率还是可以遇到的，因为不止一次听他练习了。 slack和飞书最大的不同回顾飞书是先把人拉完了再建群，slack倾向于建立一个channel，再去拉人。更普遍的现象是群为了临时的某件事情而生成，当事情完成以后更多的是水一些无关话题，而很多群里的成员是一样的。而Channel的话题性更强，更加聚焦于一个话题在接下来也能保持一直有意义下去，而不是一闪即逝。 组织文化驱动了产品功能良好的协作工具应该是为了促进团队的工作效率而被推广的，国内的IM产品诸如飞书、企业微信的一些功能体现了企业于工作者之间的隔阂，比如撤回功能，很多产品是可以看到谁在什么时候撤回了一句话，并且撤回是有时效的，比如过了两天的信息就无法撤回了。另外一些产品是无痕撤回，并且可以直接编辑原文。两种产品体现了使用者之间的信任问题，前者表现出互相不信任，聊天记录在未来被用于追溯当时说过什么，呈堂证供，而不是纯粹地作为记录供查阅。 开会的目的会议应当是高效共识某个议题(Proposal)，而回忆主持者应当在文档中把方案准备详尽，会议简短而高效。Google的会议时长为30分钟左右，前10分钟大家看资料（议题），有问题直接提问。只有一个话题而不给方案的会议很多时间都浪费在讨论上了，这是十分低效的。 分享同 组织文化驱动了产品功能，是组织文化最终选择了产品，也是组织文化最终缔造了产品。一个原本内向不善表达的人融入了一个乐于分享的团队，他的性格会在潜移默化之间收到影响，而更有可能变成一个分享者，长期处于一个极度内耗的团队不利于个人发展，引用无间道里的“环境改变个人，个人是很难改变环境的“；Google的周五是不工作的，大家会share自己的工作成果，以及自己觉得满意的作品。 好的协同工具异步协作是个比较理想的状态，部分团队会使用email进行交流。GitHub可以多人同时编写同一份代码，PR，Review流程使得协同效率非常高，并且可以看到每个人都做了什么，过程是如何的。Figma可以实时看到设计者的操作。 知识摄取类似于地图知识获取并非是顺序的，选择自己感兴趣的一点然后去扩展它。","link":"/2022/11/22/%E4%B8%80%E8%B5%B7%E8%81%8A%E8%81%8A%E5%9B%A2%E9%98%9F%E5%8D%8F%E5%90%8C/"},{"title":"个人工具","text":"记录一些常用工具 媒体 音乐：网易云 影视：爱奇艺、优酷、腾讯视频 播客：小宇宙 RSS：Inoreader 学习 英语：Ted英语演讲 教程：Youbube 资源 音乐下载：melody 记录 读书，观影：Notion 跑步： running_page 科学上网 Shadowrocket Clash 开源 协作：飞书（开源社） 仓库：kaiyuanshe 运动记录 跑步：keep 爬山：两步路户外助手 乐器 楚门 Creeper S 爬山虎 全影纹相思木TF型缺角 硬件 移动设备：macbook Air,airpods pro2,iphone 14pro,华为手环7 台式：5600X, GTX1060 6G, 32G memory","link":"/2022/11/23/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/"},{"title":"2022年总结","text":"元旦和室友去惠州玩了两天，爬山有点过头了到上班这一天腿还是很酸，请假再家多休息一天，也抽出时间把年终总结搞定。 在写这篇之前回顾了去年的年终总结，顺便看了看其他博主的年终总结。 即使想用天花乱坠的描述去点缀这一年的经历，想来想去还是找不出可以炫耀的支点。期望的年终总结应该是充满奇异，实际上2022年什么大事也没发生，或许可以罪恶地把一切都推给疫情，亦或是承认这一年的平淡无奇。 相比2021年也还是有一点可以罗列的。阅读量的提升最为显著，2021年完整的读书（除去杂质）只有3本，2022年读了23本，其中《大秦帝国》系列算是最为推崇的，文字表达非常大气，乱世中的大国纷争，小国苟且生存，名士纵横捭阖，小人唯利是图，在整个阅读的过程中有种灵魂经过洗礼的感觉，时常能感觉到自己的狭隘，或者说是局限更为恰当。截止到目前读了一半有余，另外一半不出意外是在2023年可以读完的。2022 年读书：运动方面在Q4段段续续开始跑步了，大概最后一个季度有跑了150KM左右，不是很耀眼的数字，比起2021年同期依然是好很多。 遗憾也是有的，计划是2022年深度参与开源社区，虽然相比2021年已是参与更深了，不过个人期望的深度是一个活跃项目的reviewer当然最好是committer。吉他也只是前半年有少许的练习，后半年就可以忽略不计了，说实话很欣赏那些可以沉浸在演奏里的人，可以借助音乐去平复躁动的内心。 2022年的变化还是有的，只是和自己理想的还是有一些距离，一如往年，2023年也还是定一下目标吧（虽然不知道能完成多少） 技术： leetcode每周5道 保持每天的开源项目源码阅读，作出文字的输出 运动： 每个月80KM（一周5天每天4KM，太高容易坚持不下来） 每个月爬1次山，完成广东剩下的几座高山挑战 读书： 重构精读 程序员修炼之道精读 大秦帝国刷完 社交：结识一些比较古怪的人 音乐：吉他达到即兴表演的程度 开源社区： 成为一个活跃项目的reviewer 语言：尝试和English native 的土著交流 Manjusaka的总结里的一句话很是认同，也希望未来的自己少一些躁动，多一些热情，保持足够简单的生活： Stay Simple, Stay Naive.","link":"/2023/01/03/2022%E5%B9%B4%E6%80%BB%E7%BB%93/"},{"title":"gRPC","text":"引言随着应用的日益复杂，单一服务已经不能很好地承载日益庞大的用户请求，当唯一一个服务由于各种原因不能正常运行（数据库满载，机房故障）导致系统整体挂掉显然是不能接受的。解决上述问题思路就是风险均摊，比如机房故障我们可以把服务部署在多个地区，然后把服务从大的服务拆分成若干个小的服务，这样当一个服务出现问题的时候也可以保证其他服务正常运行，至少不是所有服务全部炸掉，比如直播的时候弹幕服务不可用，但是用户依然可以正常观看直播，只是不能和主播实时互动而已。以上粗略描述了微服务的基本思想和要解决的痛点。 gRPC？要了解 grpc 首先我们要说说 rpc，Remote procedure call，远程过程调用。通常我们在本地调用一个方法的时候是用类似这样的方式： 1234567func SayHello(name string) { return &quot;hello&quot; + name}func main() { res := SayHello(&quot;Ginta&quot;)} 那如果我们想调用的函数是远程的一台机器，并且也想使用 SayHello(argument) 这种方式直接调用，就需要约定好怎么传参，返回参数是什么，以及怎么去连接。这种约定就是所谓的协议。rpc 主要包含通信协议和序列化协议：通信协议：如http，tcp序列化协议：如protobuf,json 我们常用的说的 restful 就是使用的 json 去实现的序列化，这种序列化方式的优势是直观可读，但是压缩率低，传输就会很慢。 protobuf是一款用C++开发的跨语言、跨平台、二进制编码的数据序列化协议，以超高的压缩率著称，极大地提高了传输效率。缺点就是需要专门的库去解析。 gRPC的官网主页只有一句简单的说明：”A high performance, open source universal RPC framework“。一个开源的高性能RPC框架。使用 HTTP2 为传输协议，HTTP1 中也可以多个请求利用一个连接，但是服务端返回的时候是根据pipeline中发送的顺序返回的，如果有一个阻塞了其他都不能返回，HTTP2 很好地解决了这一点。gRPC 使用 protobuf 来序列化数据。 protocol buffersgo的grpc实现proto声明123456789101112131415161718syntax = &quot;proto3&quot;;package grpc;option go_package = &quot;grpc/pb;proto&quot;;service HelloService { rpc SayHello (SayHelloRequest) returns (SayHelloResponse);}message SayHelloRequest { string Name = 1;}message SayHelloResponse { string Message = 1;} server123456789101112131415161718192021222324252627282930313233package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;net&quot; &quot;google.golang.org/grpc&quot; pb &quot;grpc-study/pb&quot;)type Server struct { pb.UnimplementedHelloServiceServer}func (s *Server) SayHello(ctx context.Context, request *pb.SayHelloRequest) (*pb.SayHelloResponse, error) { return &amp;pb.SayHelloResponse{ Message: fmt.Sprintf(&quot;hello %s&quot;, request.Name), }, nil}func main() { // open a port listen, _ := net.Listen(&quot;tcp&quot;, &quot;:9090&quot;) // create a grpc server server := grpc.NewServer() // register service pb.RegisterHelloServiceServer(server, &amp;Server{}) server.Serve(listen)} client1234567891011121314151617181920212223242526package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/credentials/insecure&quot; pb &quot;grpc-study/pb&quot;)func main() { conn, err := grpc.Dial(&quot;localhost:9090&quot;, grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { return } defer conn.Close() // start a client client := pb.NewHelloServiceClient(conn) response, err := client.SayHello(context.Background(), &amp;pb.SayHelloRequest{Name: &quot;Ginta&quot;}) if err != nil { return } fmt.Println(response.GetMessage())} grpcurlgrpcurl 工具可以查询 grpc 服务的 API, 用来调试 grpc 服务很方便安装：go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest。要使用 grpcurl 我们要在代码里先启动 reflection 反射服务 1234567891011121314151617package mainimport ( ... &quot;&quot;google.golang.org/grpc/reflection&quot;&quot;)func main() { ... server := grpc.NewServer() // register service pb.RegisterHelloServiceServer(server, &amp;Server{}) // register reflection reflection.Register(server) ....} 然后就可以使用 grpcurl 来调试了，先看看服务有哪些接口, grpcurl localhost:9000 list，报了一个异常 Failed to dial target host “localhost:9000”: tls: first record does not look like a TLS handshake，grpc 是用的 http2 协议, 虽然不强求但是一般传输也都是要加密的，这里提示我们少了 TLS 加密，我们可以先使用明文。grpcurl -plaintext localhost:9000 list。可以看到已经返回了我们服务的列表： 12grpc.HelloServicegrpc.reflection.v1alpha.ServerReflection ,第二个是我们开启的反射服务，可以用 grpcurl -plaintext localhost:9000 list grpc.HelloService 命令看看 grpc.HelloService 服务有哪些方法名，或者用grpcurl -plaintext localhost:9000 describe grpc.HelloService会返回更多的信息，包括方法的出入请求。 1234grpc.HelloService is a service:service HelloService { rpc SayHello ( .grpc.SayHelloRequest ) returns ( .grpc.SayHelloResponse );} 我们来请求一下这个 SayHello 方法，grpcurl -plaintext -d '{&quot;Name&quot;: &quot;Ginta&quot;}' localhost:9000 grpc.HelloService/SayHello: 123{ &quot;Message&quot;: &quot;hello Ginta&quot;} 补充grpc通信加密服务发现","link":"/2023/01/26/grpc/"},{"title":"202208W1","text":"生活乌龟还是没能活过第二个月，如果早注意到它的状态就好了，本来想再尝试一下的，最后决定过段时间吧。最近朋友圈里有好多爬山的，回想一下上次爬山已经是几个月前的事了，周末爬一下塘朗山吧。 技术重读了一下DESIGN PATTERNS in GO，每次读设计模式问题能有不同的感觉，可能是因为平时不怎么写组件，所以更多的还是阅读开源代码来保持工程化的思维。 读书本周没怎么阅读，晚上睡的太晚了，地铁上都不想读书了，作息还是要调整一下的。","link":"/2022/08/08/202208W1/"},{"title":"202208W2","text":"生活如上周周报所提到，周六下午去爬了塘朗山，今年的夏天相较往年热了不少，一趟下来全身都是汗。回后瑞随便吃了点，看了一下时间还早，想起也好久没有看电影了，查了一下最近《神探大战》正在上映，觉得题材和演员都还可以就直奔影院，剧情偏悬疑,刘青云演技依旧在线，就不剧透了，个人算是满意。回到家洗澡11点休息了，是几个月来最早的一次。玩了两局LOL，选了从来不选的船长，天坑，但是队友给力，所以还是赢了，这个游戏果然七分靠运气~ 技术速刷了 Solidity 的基本特性，下周会尝试开始写合约，也会学习一下公有链，私有链，联盟链，超级账本的概念和实现思路。博客主题换成了icarus，原因在7月第三周周报有提到（还是拖了大半个月。。。），顺带把周报单独分出了一个page。少加载了一堆资源访问速度提升是肉眼可见了，看板娘最后也没去掉。 读书 《读者》 《重构》虽然量不大，毕竟相比上周好多了。 还有本周就是这样了，不过在上传md之前习惯性地刷了一下推特，发现了一枚有趣的学生。","link":"/2022/08/14/202208W2/"},{"title":"202207W3","text":"生活周六申请了加班，一方面是优化一下系统，另外也是打算过段时间请假去西藏或者云南，当然也可能是四川走一走。有好长时间没有旅游了（一两天的就不说了），上次是什么时候已经不记得了。乌龟养了一个多月，这几天精神不是很好，把它放到的窗边了，希望每天有一段时间的光照能让它有有所好转。最近又开始刷宇宙记录片了，韦伯望远镜公布了几张深空照片，从中可以看到几处引力透镜效应，很好奇未来有一天我们通过引力透镜效应观测到的一百多亿年前接近 Bing Bang 时期的宇宙是什么样子。 技术入门了 solidity，虽然不从事区块链相关的工作，一直以来对这方面还是挺感兴趣的。博客从 Vercel 迁移到了 cloudflare，现在 Vercel 在国内访问速度有点感人。还有就是现在的主题有点太花哨了，计划切换成icarus。 读书在读Make Time。","link":"/2022/07/24/202207W3/"},{"title":"202208W3","text":"生活周六刷了梧桐山，上次去梧桐山已经是半年前了，天气正好，有一段土路没有下雨，顺利走到蝴蝶谷。只是不巧当天山顶多云，往下什么都看不到，还挺冷的。吉他放到角落吃灰有段时间了，试了试《城南花已开》，已经有点生硬了，平时还是要不时练习一下。公司新来一个老哥可以负载部分我的任务，leader说前期可以把不太重要的交给他熟悉项目，不过第一周感觉还是算了吧，快乐就好，所以我告诉他本周只用熟悉一下模块是做什么的，然后就是强调了一下没什么事就准时下班。 技术这周还挺忙的，技术方面基本没有输入和输出，本来想写一下合约的，这周工作任务比较满。下周会好一点，可以把一些任务交付给新人了。 读书东野圭吾的《时生》读了一半，《重构》小翻了一下，个人感觉比起上周只读杂志算是好一点。","link":"/2022/08/22/202208W3/"},{"title":"202209W1","text":"生活本来计划周六去惠州爬罗浮山的，正好深圳实行“静默管理”也没去成，目前来看中秋节也是出不了深圳了。高中时期看的《龙族》出动漫了！很喜欢小恶魔的形象，话说记得诺诺是御姐，中二是保留了一点点，不过御姐完全是看不出来，继续期待青铜与火之王登场，衰小孩使用第一个1/4生命换来的战斗场面会以什么样的方式呈现给观众呢？老妈打电话问国庆什么时候回，舅舅家的姐姐要出嫁了，半年多没回老家是想回去看看，不过参加婚宴难免要被灵魂拷问，自毕业以来就像断线的风筝在南方浪，家里还是希望能早点定居，只是自由惯了，总觉得定居就会被束缚，还不够成熟吧。 技术学习了超级账本 hyperledger的理念，了解了联盟链，公共链和私有链的区别，周末把电脑重装了一下，本地试跑了 fabric，感觉找到了新玩具！ 读书《乌合之众》读完，感触挺大的，就是不知道怎么表达，作者的一些观点冲击了以往的认知，作者认为群众的认知未必高于个体，而个体的一些特点在融入集体之后会慢慢消失，这让我想到了一个词：同化。","link":"/2022/09/05/202209W1/"},{"title":"202209W3","text":"生活周六和朋友爬了南山，只看海拔可以说是一座小山，然而盘山的路也是挺长的，总体下来和塘朗山用时差不多。用商品门口的电子称测了体重，比起年初的144斤已经下降到了132.8斤，一方面是过年穿的多，也可能是跑步两周的意外变化吧，意外是因为跑步只是不想太肥宅而每天保持一定的运动量。国庆的机票订好了，希望这段时间疫情不要再反复了，一年也就回去两次。 技术在家里的电脑搭了一个 istio，实操一下，公司的 istio 都是运维去处理的，虽然不用开发改配置，终究是想自己体验一下。 读书《被拒绝的勇气》 100%书名里是拒绝，读完感觉和拒绝关系不大吧，主要是给读者一点点建议或者说是方法，简单化生活也是可以轻易做到的。拿弗洛伊德的作为对立的观点也是有点东西了。","link":"/2022/09/19/202209W3/"},{"title":"202208W4","text":"生活周五和两位朋友吃饭，之前是他们请的，这次正好轮到我了，选了大仟里的《美奈小馆》，越南料理，几个月前尝过一次，口感还行。期间闲聊了很多，代码、链、定居。其中一位离职一个多月，最近在研究 react ，有提到曾经做过一段前端，算是重拾旧业，打算再休息一段时间。另一位是有考虑之后在惠州定居，可能是因为已经有小孩了，所以会想得全面一点。 技术这周抽空整理了一下负责业务模块代码，九月份计划重构部分接口，所以又看了DESIGN PATTERNS in GO，希望重构后可以做到任何一位新人都可以快速上手。 读书 《时生》100% 《人间失格》100%积压的东野圭吾的书全部看完了，把《时生》放回书架的时候纠结下一本看什么好，《大秦帝国》系列还是阿加莎系列，但是最近看的都是历史和悬疑类型小说，想换个风格。正好看到角落里的《人间失格》，之前和发小互相推荐小说的时候有对她提到过，她说这本书看了可能会抑郁，没有很推荐我看。然而当初《活着》也没有造成很大的心理负担，片刻迟疑最终还是拆开了包装。《人间失格》一共花了两天半，确实是不错的作品，也确实有点心情沉重，刚看完的那天不想工作，也不想和任何人沟通。一两天后就好多了，多看看不同题材的书就好像经历了不同人的部分人生一样，感觉生命充实许多。","link":"/2022/08/28/202208W4/"},{"title":"202209W4","text":"生活换了个灵动岛，只有很小一部分应用支持，不过苹果的联通信号是真的有点抱歉了，上地铁基本等于没有，电量暂时能坚持一天。周六爬了铁仔山，海拔不高，个别地方风景不错。忘记上次刷油管是什么时候了。抽空听一些播客，了解一下不同人的异样人生，挺有意思的，有位分享者兜兜转转出国回国、换了职业方向，最终选择了一个小城定居，也有的出国了就没再回来。想到了在成都和一位做开源的老哥沟通过，老哥彼时在业界也算小有名气，放弃了一些机会选择自由职业，在几期博客里也分享了自己的开源生涯，前一阵子看他在博客里提到入职了戴尔。偶尔也会感到生活的单调，对于大多数人来说也许单调才是常态，罗曼·罗兰有句话描述了这种生活方式： 有些人二十岁就死了，等到八十岁才被埋葬 诚然每个人对于生活都有自己诠释，但总奢望平静的生活不时有一些波澜，无论好坏，就好像有一种疯狂是渴望燃尽生命去追求的，是一种只有在不断变化的场景中才能突然达到的状态。 技术Github 看到一个 issue 被link到了自己提的一个 *PR*，当时是为了下油管的视频补全了代理的功能，然后又不想白嫖项目就顺手提交了这个小的feature。没想到国外的机器访问国内也要代理，好奇这是哪个国家。作者希望这个 PR 把配置功能一并完善了，后来一直没时间（其实就是懒），立个FLAG：国庆一定。 读书原以为现在已经可以接受各种风格的书了，其实想多了，《沙之书》最终是读不下去了，说不定未来哪天实在无聊把它捡起来一口气解决了。《大秦帝国3下》读了10%，这周读书有点少了。","link":"/2022/09/27/202209W4/"},{"title":"202209W2","text":"生活中秋在家宅了三天没有出门，现在每天会跑几公里，一周下来感觉还行，用了一个开源项目收集每天的跑步信息，还可以自动生成轨迹线，但是GPS需要带手机，不过记录距离即可所以手机放家了。好久没看 doinb 直播，还是一如既往地有意思，4个职业选手放飞自我，辅助的妹子也是为难。 技术内网起了一个 go-ethereum的 本地环境，尝试用 go-ethereum 去实现创建账号，实现与公链的交互，由于相对离底层更进一步，所以比起直接用 solidity 无脑写合约来得更清楚。 读书《大秦帝国三上》100%战国秦的几代君主都是挺有才能的，赢渠梁、赢驷、赢稷，再加有商君、司马错、白起等臣子，虽说赢荡自负举鼎而亡，也没有多大成就，不过在位时也算能听进臣下的意见，所以总体来说秦的强大是必然的，从战国最弱的几个国家一直到最强。人物刻画的相当有特色，整部小说看起来也有一种开阔的感觉。","link":"/2022/09/13/202209W2/"},{"title":"202210W1","text":"生活回一次老家真是挺不容易的，早上六点起床下午四点才到家；回来那天短袖尚可，现在已是外套加身。和家人一起把前院的土豆收了一下，很多年没有做农活了，手法已然生疏。本来二舅家的姐姐是要回来举办婚礼的，突然县里管控升级就作罢了，想凑个热闹都不行。 技术国庆优先，其他滞后～ 读书《大秦帝国三下》 100%看到白起被秦昭王赐死很是惋惜，一生从未打过败仗的军神最终落得如此下场。关于赵括，以前只知道这是个纸上谈兵的将军，现在看来是以点概面了，如果他能随军征战几年，经历几场大战再与白起决战长平，胜负真不一定，没想到他在断粮的时候能把自己一半的粮食分给战士，陷全军于危局能承认自己全盘的错误，人格魅力相当可以，可惜。","link":"/2022/10/05/202210W1/"},{"title":"202210W4","text":"生活上周没写周报，是因为也没什么可以写的，本周的话没有大事发现，参加了第七届开源年会，这次是第一次采用元宇宙的形式给大家做分享，有幸作为志愿者组长和区块链会场的主持人参与其中，组长需要培训志愿者，任务虽然简单但是大家时间都不统一，所以有一部分是元宇宙内部培训的，也有一部分是看我的录屏学习，每天晚上基本都是11点以后才回答完所有的问题。会议开始前一天晚上才把主持稿写完，有一位讲师的视频超过时长了，下了剪辑软件剪了10分钟的内容，最后导出发现音频和视频不同步…….主持当天麦克风声音还很小。 技术因为在准备开源年会，所以基本什么都没做 读书《大秦帝国四上》 100%终于读完了 其他之前也有参与过Pycon China 2019,Pychon China 2022。一次是在成都，一次是在深圳，这次是在元宇宙。其实参与社区最主要的一个目的还是因为社区的氛围比较好，因为自己崇尚自由，喜欢不受约束，外加极简的社交，开源社区刚好满足所有的情况，期间的各种工作也给了参与者自由发挥的空间。比如作为主持人我不需要用太官方的话客串全场，主持过程中加点个人的想法这都是可以的。","link":"/2022/10/31/202210W4/"},{"title":"202210W2","text":"国庆结束说短不短的假期没什么感觉就过去了，看了一个国庆的动物世界，并非所有的动物都畏惧人类，像虎鲸这样的海洋霸主偶尔也会挑逗一下两足生物。上班第二天开始跑步，小半个月没跑第一天就把膝盖摔伤了。S12开始了，lpl的几只队伍表现都不错，小明的辅助硬是打出了C位的感觉，看到有弹幕笑称“4保1辅助”，反而是TES的战绩在lpl中垫底，不管怎么说轻敌也要反思一下。回到深圳和朋友吃了顿饭，离职几个月感觉精神状态好多了，而且还能保持一定的hard刷题量倒是挺意外的。 技术看了一下helm自定义配置功能的源码，打算借鉴到另一个项目中去 读书《大秦帝国四上》 40%吕不韦终于登场了，有一段对话挺精彩的 吕不韦思忖道：“商家以牟利为本。敢问父亲，耕田之利几何？”“劳作立身，其利十倍。”“珠玉之利几何？”吕不韦问。“珠玉无价，其利百倍。”“若得谋国，其利几何？”“谋国？”父亲大是愣怔，“邦国焉得买卖？何谋之有？”吕不韦字斟句酌道：“譬如，拥一新君，掌邦国大全。”“……”父亲默然，良久，竹杖笃笃顿地，“如此谋国，其利万世不竭！” 吕不韦认定秦异人“奇货可居”，于是押上自己全部身家帮秦异人还国，无论是眼光还是魄力都注定了他未来曲折精彩的道路。","link":"/2022/10/11/202210W2/"},{"title":"202211W1","text":"生活计划周六去梅林穿越的，天气不稳定小伙伴们最终一致“下次一定”。周日晚上和朋友出去吃饭，说起来有段时间没见他了，在家快乐当宝爸了吧。Pycon China下个月就要还是老地方举办，收到少飞的突然联系还是挺有意思的，今年还是去折腾直播设备吧，去年真的调试了好久。 技术学习了一下go的template用法。了解了一下 consensys 公司的产品设计思路，重复看了上周区块链论坛的分享内容。目前对于区块链的了解算是小有入门吧，不过还没有看到比较成熟的商品模式。 其他国庆后的作息很不规律，工作日一两点睡，周末有时候四五点还没睡，希望能慢慢调整到在家时的状态。","link":"/2022/11/07/202211W1/"},{"title":"逝去的生命","text":"整理书架的时候发现没有空间放置新书了，有一层是放满了读者，还有几杯比较厚的 python 技术书，有的是还没毕业买的，有的是刚毕业那会买的，一起处理了。 逝去的生命网上看到一位币圈的大佬自杀了，他曾炒币收入500万，后来进行一些投资，最近市场不景气差不多归零了，然后就是和女友分手，留下了一段视频之后选择告别人世。惊讶，可惜，惊讶是因为年纪轻轻家里情况又比较特殊的情况下也曾有过那样的折腾。可惜22岁大有重新来过的可能却终结了生命。有时也会把一些场景类比到自己身上，思考在同样的情景中自己的意志是否能平静处理，答案往往是不能。 放慢节奏周末在家宅了一天，看了一天书，还旁观了社区几位大叔下象棋。前一段时间的周末过得很忙，或者说排得有点满，突然有一周不玩游戏不约饭不水群感觉真的不错。 技术正在重拾 Hyperledger Fabric，一个月前在 wsl 上成功跑起来了测试网络就没管了，这次打算系统地学习一下这个框架，感谢pseudoyu 推荐的《区块链原理、设计与应用》和《区块链技术进阶与实战》这两本书。 读书《区块链原理、设计与应用》10%接下来一段时间小说先停下来，小说今年的输入已经远超往年了 其他忍不住又开始看《魔兵传奇》了，说起来银太的名字作为网名已经好多年了，连 Github 当初注册的 id 都是 Mar-heaven。","link":"/2022/11/14/202211W2/"},{"title":"万能的ChatGPT","text":"这周听的播客依然以开源为主，几位嘉宾讲述了各自参与到开源的经历，以及一些想法。不得不说每次听到有谁说自己高中啊甚至初中就接触到编程还是有点佩服的，对比自己，初中的时候电脑基本都是用来看剧，或者玩反恐精英，高中就更纯粹了，单调英雄联盟。 深度参与社区其中有一个观点还是很有感触的，就是尝试去深度参与社区。刚毕业的那会自己只负责拍照，还老担心拍的不好（事实上确实很业余），后来借鉴了其他人的照片，现在至少角度不会显得突兀。 后来负责了一个直播的摄影机机位，虽说是固定不用移动，但第一次调试直播设备也经历了一点波折。最噩梦的是切屏器被我玩的对不上了，那天我们调试到了很晚才整好。 再后来线上培训志愿者、主持分会场，观众不多也挺紧张的。幕后也要简单地剪辑视频，偶尔摸出一个脚本去处理一些事情。 以现在的角度回看，在比起更加直接的“**开发工程师”， 在开源社区更多的是有机会尝试不同的角色，也不用去焦虑做不好会怎样。 翻出2021年总结的时候有这么一段：后续会更深度参与社区，期待有新的发现。 ChatGPT微博的热搜前十我不知道是什么，但 ChatGPT 毫无争议是朋友圈的关键词第一，它可以写代码，搞怪，天文地理无所不知个人体验是非常满意的，自己的代码可以交给它 review，有考虑过作为搜索引擎，只是未来它一定是收费的，目前可以白嫖。或许以前没有注意过 AI 的发展，像这种可以有上下文的提问，并且可以把话题一直延伸下去的还是头一次见，目前一些简单的代码实现完全可以用 ChatGPT 去生成初代简易算法，所以未来计算机相关的初级任务完全可以交给人工智能自行解决。 运动连续跑步十天了，打破历史记录中间断了一个月，12月坚持下来200公里应该问题不大。 读书二刷《重构》","link":"/2022/12/07/202212W1/"},{"title":"颓废的两周","text":"最近发烧的人好多，周四喉咙有点疼，不过当时也没有抗原，也不知道是不是中招了，打了声招呼远程办公。周日一起合租的同学烧到40度+，原本打算元旦前的一周也远程算了，鉴于在家这几天少了固定的运动量精神似乎变差了很多，想想还是去公司吧。周一早上看了一下镜子里的人，不到一周的熬夜和荒废了两周的跑步从黑眼圈和憔悴的面容就可以看出来有多糟糕了。 Pycon 2022和听听卡一起主办了今年的 PyCon China 深圳场，有了往年的惨痛教训流程上顺利了很多，没有因为切屏器再搞到晚上十一点，会前还调侃说今年这个疫情到时候来听的人只有一两个会不会很尴尬，最终还是到场了几十个，似乎比去年还多一点。晚上一起吃饭的时候发现有不少讲师其实也是从听众过来的。第一年是听众，第二年是志愿者，第三年就上台分享。虽然工作上一直在 GO 了，不过在社区的项目还是优先开发效率比较高的 Python。如果明年的 Pycon 自己还在深圳的话，那上去分享一下吧。 花里胡哨开源社的小伙伴大多是 Node.js + * TypeScript*，为了方便后续的合作，计划元旦入坑 Node.js。最近在搞开源社的公众号后台，不需要备案所以内网穿透一个开发也挺方便的，就是支持很不好，自动回复的功能网页端可以支持多条图文，但是开发者的接口只能返回一个，在公众号支持之前看样子是不能直接交付了。 读书这段时间也没读什么书，今年的最后一周就以东野圭吾结束吧。 元旦元旦暂时没有出省的计划，大概率在广东内部游荡了，更大概率就在深圳不出去了，最近两个月都没爬山了，去东莞或者惠州选一座山爬。 其他2022年的最后几天不要感染病毒就好～","link":"/2022/12/26/202212W4/"},{"title":"好像没那么能吃辣了","text":"下次不点辣了周六和同学吃了个火锅，锅底选的鸳鸯，微辣。突然发现我们都下意识地把菜加到了番茄的那边。”如今感觉微辣都受不了了“，我感慨道，同学点头表示同意。当初刚从成都来到深圳的时候是不会考虑鸳鸯锅的，至少中辣起步，也算是入乡随俗了。 新人？老人？ hello 各位 我是邢立涛 目前在做go，做过 pycon 2019 pycon 2021 第七届开源年会志愿者 分别负责拍照摄影和主持很高兴认识大家！ 以往每年都会参加 pycon china 的活动，2019年在成都是10月举办的，2021年是11月，今年是12月中旬。不出意外今年还是负责深圳会场的直播摄像。成都那年还是很拘谨的，刚毕业的自己总是不知道怎么融入其中，后来发现社区中不乏奇葩，特立独行的比比皆是，只不过是再多一个而已。 技术Fabric 测试网络调试了链码，对 Fabric 的业务流程熟悉多了，包括从发起一个 proposal 到 install 链码，再到 approval,invoke,deploy an application。下周阅读 Fabric 的源码，有空会开发一个应用。 读书《区块链原理、设计与应用》20%","link":"/2022/11/20/202211W3/"},{"title":"202302W1 重拾的生活","text":"最近朋友圈被 Damus 和 apitable 刷爆了。apitable 是个不错的开源项目，不过方向不是很感兴趣就没有跟进了。本着好奇的原则注册了一个 Damus 账号，目前上边的广告泛滥，绝对的去中心化没有任何的审查也是需要一些靠谱的方案保障，比如智能合约，发帖需要消耗gas费用，但是这样会极大打击社区活跃度。看了下 nostr 的思想，对其未来的自制能力还是很有信心的我们的信息是公布在所有 Relay 的，活跃在各个社区的 名人 总是有共通的那一波，然后就像 POS 协议那样由 名人 来筛选黑名单，当然这只是目前的一个想法，可能还不完善。 恢复的运动过年的那段时间运动量急剧下降，生物钟也是惨不忍睹，每天4-5点睡觉，下午1点起床。用了将近一周的时间恢复正常了，前两天还是很晚才睡，最后决定用跑步挣扎一下看看效果，终于可以在1点之前睡觉了，虽然也不怎么早。周末也是保持了每天至少1W步的运动量，会去欢乐港湾听唱歌，然后从后瑞地铁站一直走回小区。 其他再度学习了 solidity，以及 nostr 协议，还有打算自己实现一个 Relay。博客周报本来是单独开了一个 Tag，总感觉有点怪异，点过去还挺麻烦的，索性就不拆出去了，和其他博文放一起吧～","link":"/2023/02/05/202302W1/"},{"title":"去听欢乐港湾的弹唱","text":"下周结束就快过年了，和家里说了今年在深圳过年，第一次在外地过年是两年前，也是在深圳，大部分人来深圳都只是为了赚钱，这边的外来人占比相当大，所以一到过年会发现这座城市很空，特别是除夕会有种一个人拥有整个城市的感觉。至于为什么在深圳过年，是因为毕业之后就一直在工作，节奏很快，每隔一段时间就想留出几天什么都不做，出去户外，或者关掉电子设备一直躺着。 春节假期有两周左右，是想做一些平时没时间去做的事情，比如看看周围有没有地方钓鱼，前几天看到 Grey Li 的年终总结，有提到十多年前的吉他，后来就基本没弹了，有遗憾的也不止我一个，还是可以继续学习的。 周末晚上去欢乐港湾吃了麦当劳，那边每周末都有人唱歌，曲子是随机的，也可以点歌，中间休息的时候去找他们聊了一会，我说平时最喜欢听小刚的《青花》，但是歌单上只看到了《黄昏》，能不能唱《青花》呢，“你是哪一年的？”，弹唱的小哥问到，我说25，不过周传雄的歌不是很多人都听过吗，他笑着说现在听的人少了，最终还是请他唱了《黄昏》。比起近几年火爆抖音的《红昭愿》、《叹》去考古十多年前的歌是有点奢侈了。 技术看了一下 k8s 的 ingress，服务暴漏这部分还一直停留在 nodeport 阶段，ingress-nginx 确实优雅，虽然也支持 istio 实现，公司里也是这么做的，但 istio 的部署和熟悉成本会高很多，一般的中小型项目也用不上。其实中小型项目直接 nginx + docker-compose 也是足够了。 书《How to》30%， 这本书的作者用各种不切实际的问题去请教专业人士，比如飞机怎么停到潜艇上，如何过河（用上亿个热水壶把河水蒸干，坐汽车加速完成抛物线运动，把河水冻成冰），还挺有意思的，推荐阅读。","link":"/2023/01/09/202301W1/"},{"title":"开始听跑步电台","text":"周二晚上跑步的时候收到社区的电话说经过风险地区，后续几天不能去公司上班。虽说不让去公司上班，倒也没有强制把整个楼封掉，或者不让下楼扔垃圾，只是避免和太多人接触吧。在家的几天也挺规律的，每晚都下楼跑步，12点就睡觉。 听了一周播客从周二开始又想跑步了，之前也提到自国庆以来基本是没有跑了，以往跑步手机直接放家里，只带个手环下楼用于买水和记录跑步的里程和心率等，跑完就上楼了，现在每天会把手机打开播客听一期开源相关的内容，实在没什么可听的就选择一些生活相关的播客，比如设计，旅游，语言……听了一周的体验是相当不错的，平时自己也会关注自己感兴趣的博客。相比之下播客有几个好处：1. 是听的而不是看了，因为跑步的时候只能听而不能拿着手机看博客，除去安全问题眼睛是受不了的。2. 互动，播客的目的就是大家交流想法，比如开发软件可能他觉得有更好的工具或者包，而博客只靠表达效果是远远没有这么好的，比如主持人中间的开玩笑啊，其他人的语气这些从文字中是体会不到的。3. 博客相比线下的Meeting Up灵活很多，在线即可，疫情原因很多线下活动举办起来没那么方便，可能一年也没几场，博客只需开个channel就可以了。4. 其实很多主播也不一定有博客，或者有些主题自己写没什么意思，而在播客里可以了解到更多样的主播。 Github新发现之前一直没注意到 Github 的 Explore 功能，它是通过你关注的项目去推荐可能感兴趣的同类项目，类似抖音的视频推荐，比如最近比较关注区块链相关的项目，它就会推荐 Hyperledger 组织的仓库，挺实用的功能。 其他有趣的发现xlog是一个dapp博客，它的数据都在链上，评论也已经有了，支持用户自定义功能： You can follow, comment, like, and mint your blog and posts, all on the blockchain of course. Domain name, navigation bar, custom styles, all as you wish, and stored on the blockchain. 行尸走肉完结了很多年前追过的一部美剧，也是唯一看过的一部丧尸相关电视剧，前两天在B站看到说它大结局了，从高中到毕业三年，不过真的剧情太长了，看看以后会不会想起来追完它。 Ted英语演讲免费的英语学习app，有讲解视频和中英对应，还有长按翻译，目前使用很好。 Hyperledger视频他们每周都会更新一些区块链相关应用的视频，这周看了一下在慈善基金会的应用。 鬼泣背后的剧情在B站上看到一位Up主分析了鬼泣5背后的剧情，对鬼泣有了新的认识，比如为什么最后总需要V补刀，因为梦魇是无法杀人的。说起来鬼泣还是小学时候在电视上一个游戏频道看到的，打斗感和过场动画震撼到了当时只会玩红警和4399的我，后来去网吧也是会打开玩一下的，也是从那个时候开始粉丁叔的，桀骜不逊的性格，表面上玩世不恭又异常可靠，最喜欢的游戏角色，没有之一了吧。","link":"/2022/11/29/202211W4/"},{"title":"除夕的深圳","text":"小区附近的店铺都关门回家过年了，使得本就比较偏僻的街道显得格外冷清，连平时后瑞地铁站周边密集的小吃摊也仅剩了三两个在维持着最后的烟火味。 除夕提前放假的几天在家疯狂玩游戏，玩到作息昼夜颠倒，每天凌晨4-5点睡觉，11点之后起床，基本没怎么下楼。直到除夕那天中午应邀去同事家吃午饭，本来约好的吃完早饭就过去的，结果刷了一下B站睡着了，要不是老爸的一个视频电话打过来可能就一直睡到中午了。同事家里做了蛮多的菜，期间她们问我做的如何，我笑了笑，打趣道比昨晚吃的泡面好多了。后来去荷兰小镇转了转，看到有卖乌龟的，想起了之前养的没有活过一个季度的乌龟，同事说可以再买一只，有比较便宜的品种，最终还是没买，家里那只之前生病的时候我觉得症状比较轻微，而且乌龟的生命力比较顽强，就没有带着去看兽医，直到最后结果无法挽回，那段时间极度消沉，不专业的喂养是在亵渎生命，就决定暂时不养宠物了。晚点的时候感谢了同事的招待，坐地铁去深圳湾转了转，坐到了另一个站，又低估了深圳湾的长度，绕了很久都没有走到经常出站的那个地铁口，错过了落日。 看书沉迷游戏也没怎么看书，过年的前三天刷一下曹春辉大大写的《Go语言高级编程》。 其他初一的欢乐港湾人比想象中的多。","link":"/2023/01/22/202301W3/"},{"title":"202301W3 头文字D","text":"小区楼下有几个小朋友在下象棋，仿佛看到了20年前的自己，那时候小区也是有几位一起玩的朋友，如今也都各奔东西了，只有一个还保持联系。好久没有和表哥联系了，周末抽了一个多小时闲聊，他说北京疫情比起几个月前好多了，说我一个人在深圳没什么意思，要不要在北京工作，或者天津，可能是过年那几天家里有和他提了一下。我说政治中心太过严肃了，闲散惯了融入不了那边的生活，天津还相对靠谱点，不过还是惦记着成都。 换了一台电脑终于忍受不了编译一个小工程也要半分钟了，找老妈朋友买了台 M1 PRO 的，本来是选的 M2 ，阿姨说刚好她店里下架了一台14寸的，配置比我选的会好不少，如果不介意电池损耗可以一试。考虑到电脑大部分时间通电，所以电池容量下降一点没关系，但是性能的提升还是能降低不少血压的，事实也是如此，内存和芯片的提升节省了一半以上的编译时间。 头文字D这周把《头文字D》动漫前3部刷完了，还顺便把周董拍的真人版也刷了一遍，最近几天脑子里全是 AE86。相比之下还是动漫人物刻画得更鲜明，无论是主角还是配角，尤其是文太总是表现得漫不经心，却能给人一种“你爹还是你爹”的感觉，比如给 86 换了怪物一样的引擎，还有秋名山碾压拓海的车技。 小说好久没看的《大秦帝国》又续上了。","link":"/2023/02/19/202302W3/"},{"title":"202301W4 Hello eBPF","text":"From this report, i just start writing in English as much as possible.I had a short but insightful conversation with a fellow open-source enthusiast over the phone. As mentioned in my year-end review, I felt that my involvement in open-source projects had decreased in 2022 compared to 2021 (partly due to maintaining my company’s open-source projects). This year, I plan to sacrifice some of my social time to invest my energy in more active open-source projects, and try to shift discussions about PRs and issues from WeChat to email for better asynchronicity. 6kmOn Wednesday, I listened to an episode of GGTalk podcast and decided to run 2km more than my usual 4km, but stopped because I had to work the next day. I hope to achieve the goal of running a half-marathon distance at one time this year. reading《大秦帝国》 have read 80% percent. just talkIt has been a month since I last communicated with my friend.Although we live very close, we rarely talk to each other.We talked some topics about military and tourism.","link":"/2023/02/25/202302W4/"},{"title":"202303W2 ski and tennis","text":"I went skiing with friend on Saturday, now i can control the speed easily.The last time we went skiing in Guangzhou was in 2021.After skiing, we had barbecue. After a night’s rest, we went to play tennis with friends the next day. This week i spent some time learning about Golang’s concurrency features.By the way, I learned about the nft implementation of blockchain. Reading book 《坏蛋是怎样炼成的》，it has pass 15 years since i read it first time.Once i feel be lack of power, i will reread this novel.","link":"/2023/03/12/202303W2/"},{"title":"202303W3 GPT-4 and an interesting meeting","text":"In the past week,GPT-4 has gone viral on the internet, and every one around me is disscussing topics related to it.As an old movie “The Matrix” shows, AI will become increasingly powerful,i believe it will eventually take over all aspects of our lives. I took part in an interesting meeting on Friday night,and it was my first time participating in a meeting in English.Although my English level is average,my forign friend could still understand what i was trying to say. When it comes to speaking English, most people worry that they can’s express themselves correctly due to their poor English.However,the foreigners can still understand what they say means even if they speak poorly. Recently, i have been trying to use Github actions to automate my project workflow.When the code is pushed to the develop branch,it will automatically build the image and deploy the service on EC2.In the future, i still need to address issues related to service load balancing and discovery. I took the time to migrate the project from sudo nohup ... to k3s.Previously, i had to kill the process manually every time i updated, and there were several minutes where the service could not be provided externally.","link":"/2023/03/18/202303W3/"},{"title":"2021年总结","text":"本来是打算在年末的最后一天总结一下的，结果跨年玩到了3点多才回后瑞，那就元旦的上午抽点时间回顾2021年的经历，顺便规划一下2022年。 按理来说总结应该是简单的，不过多写点其实也挺好的，很久之后再看回过头再看自己写的东西其实挺有意思的。 2021年的春节是在朋友家过的，在过年的前一个月疫情突然又严重了，老妈说太原那边看样子回不去了，票可以退掉。想到从来没有一个人在外地过年，还是有点新鲜的，所以后来虽然确定可以回去了，也果断选择留在深圳过年。 那天上午在家玩了几局游戏，下午就出门了，目的地没有想好，先去宝安图书馆转了一下，本以为十分冷清的大厅竟坐满了人，大部分是准备考试的，考研、考证、可能考公也不一定。在书架上挑了本讲宇宙天体的书看了两个小时，不得不说有插画的书，特别是这种讲太空星体的更能让人耐心看下去。四点多到了深圳湾公园，海边也有不少人的，也不奇怪，毕竟图书馆都能有那么多人。有不少人在拍照,找了自认为风景还可以的角度拍了几张，选了一张贴上。七点回去吃年夜饭，朋友准备的还是很不错的，菜式比较丰富，名字叫不上来，十分好吃。期间聊了一下工作，还有以前的经历，每个人都有自己的过去，以前一直认为朋友身在一个互联网大厂，在深圳定居已经让不少人羡慕了，但北京的几年辛酸加上个人的性格，就不在 Tencent 想必也差不到哪去。朋友说很多年前他也曾沉迷游戏，为了充钱过年也没有回家，家里还一度以为他在好好读书。那天聊了很久，年夜饭就这么结束了。过年的两个星期把《无心法师》追完了。 三月和同事去玩了恐怖密室，《鬼打墙》。之前是没有玩过恐怖主题密室的，表面平静，实际感觉还是有点吓人的，有个女生主动 solo 最后一关，我们还是佩服她的勇气，后来又去了个恐怖主题的，但都没有第一家那种感觉了。 六月组织了梅林-塘朗山穿越，一行七人，都是入门级玩家，有四位竟然只带了一瓶水就来爬山了，只能说想法比较年经，不过能让他们体会到了躺平是多么美好的一件事，后来这种强度的运动他们再也不参加了。还有一位行进比较慢就到终点等我们了。同事体力相当好，我被丢到了后面，后来带着我的所有补给和唯一的通信工具上了山顶，以至于我后来没有体力走下去了，也联系不上同事，还遇到了分叉口，被迫下山了。下山后找了家小商店，八宝粥火腿什么的各种吃，顺便加了根老冰棍,然后给家里打电话说没钱结账了，家里多转了100块打车回家，用电脑上的微信联系到了同事。“你太能折腾了，自己都这样还叫同事，下次一个人就好了，自己丢了不要紧，别把其他人捎带了。”依稀记得后来老妈是说么说的。再后来就把阳台山，梧桐山也爬完了，之后考虑挑战更高难度的山。 七月份入门了围棋，围棋以前总觉得很高深，不好上手。其实围棋对新人来说还是很友好的，成为国手就是另一回事了。 十一月底换了工作，转了 go 的开发。比较感谢 leader 一年多的关照，还有公司的其他同事也比较好沟通，离职一个多月了有时做梦还能梦到公司的猫。 十二月初捡起了闲置几个月的吉他，自买回来就没弹过几次，不过整个十二月还是连续下来了。 读书清单如下： 《幻夜》30% 《程序员修炼之道》40% 《我曾走在崩溃的边缘》100% 《明朝那些事儿》100% 《活着》100% 《读者》、《特别关注》若干 2021年总体来说相对2020年还是丰富了很多，2020年的周末基本都是在家里宅的。Pycon China 的Meeting up 也结识了不少新朋友，听了他们不同人生经历感触还是挺深的。读书的话这么一看似乎是有点少了，大部分都是杂志，技术方面对 k8s 架构了解了一下，也不再只局限于架构。小说只完成了两本，其实小说应该至少15+的。 退掉好多微信群年度的某个周末，我做了一个重大决定：退掉大部分群，简化社交。截止到2021年末微信加了很多很多的群，大部分都是同事群。因为都是和工作无关，所以离职后也没有退，还有一些在其他场合加入的。也许是自己无法做到让内心足够的平静，查看多个群的内容每天占据了相当可观的时间，虽然确实有一些内容比较有用，但这样的状态也不是自己所理想的。有考虑过退掉这么多群带来的弊端，比如技术领域的滞后，以及社交能力的下滑。然而最后还是这么做了。一直以来理想的状态是每周可以静心读一到两本小说，或者半月通读一本技术书籍；每天弹半个小时到一个小时吉他，然后做一定量的运动。如果每隔几分钟就想看一下群消息，担心错过什么重要信息，那我可能一直达不到理想的状态了。基于以上考虑，目前还是选择放弃一部分社交，多出来的时间调节一下自己，哪怕只是在躺着什么也不做，什么也不想。 2022年读书前置清单： 《幻夜》（一周） 《重构》（一个月） 《放学后》（一周） 《大秦帝国》（三个月） 《why we sleep》（两个月）先规划半年的吧，读书量按周末时间来估的 技术 SRE - Google 运维解密 深入了解 Proxyless Service Mesh 相关技术 一周两道算法练习 读gin源码 深度学习mysql 开源 参与到kratos rqalpha 户外运动（玩） 排牙山 广州蹦极 七娘山 音乐 学习乐理 健身目前每天晚上是固定2组简单的运动：每组40次哑铃（单手1.75KG），80个仰卧起坐以及30个俯卧撑。二月结束的时候希望达到每组50次哑铃（单手2.5KG），100个仰卧起坐以及40个俯卧撑。目前先这么定，哑铃的目标感觉有点高了，先挂着吧。 尝试尝试做一些自己从来没做过的方向，年前听了100天计划，你可以完成什么？播客，觉得很有意思，几位主播都用100天尝试自己从未涉及的领域，100天后的效果还是挺好的。能把一件自己觉得有意思的事连续100天不间断做下来，第二个100天就容易很多了。从来没有期望自己做什么惊天动地的大事，只是不想每天过着重复的生活，很多冲动的决定，只是希望生活可以丰富一点。 end最近看到一句很不错的话: 一个人最好的状态莫过于,眼里写满了故事,脸上却不见风霜。","link":"/2022/01/01/1024/"},{"title":"GMP","text":"IntroductionWe all know that Golang has high concurrency performance, thanks to its excellent GMP model design. This article discusses the cleverness of the GMP model. HistorySingle processIn the early days of operating systems, there was only one core, and computers executed tasks in the order they were arranged, with task A executed before task B, and task B executed before task C. When task B (actually a process) was blocked, it had to wait indefinitely. Multiple processesImagine that we now need to write a web crawler to retrieve 100 pages, and each page takes 1 second to respond. The entire process takes more than 100 seconds (processing data, writing to a database, etc.), so multi-process/multi-threading technology was introduced. When a task is blocked by I/O, the CPU switches to execute other tasks, and then returns to execute the original task when the other tasks are completed. Compared to the initial performance, this approach greatly improves performance, and the CPU is no longer idle, achieving so-called “concurrency,” but not “parallelism.” Multiple processes on multiple coresWith the development of hardware technology, computers have entered the era of multiple cores, and multiple CPUs can work simultaneously. At this point, we can say that it is parallelism. However, processes consume a lot of resources, and the cost of switching processes is high: Save context: CPU registers, program counters, process status, etc. Load new context: Load new context into CPU registers and program counters. Switch memory space: The memory space between processes is independent, so when switching processes, the operating system needs to switch the memory space of the process. Switch hardware context: such as IO cache, interrupt vectors, etc. The most common approach is to use multi-threading technology. Since all threads in the same process share the same memory space, file descriptors, and global variables of the process, when switching threads, only the context information of the thread itself needs to be switched, and the memory space and other resources of other processes do not need to be switched.However, multi-threading also brings new problems: in order to ensure data safety when multiple threads compete, mutexes and other synchronization mechanisms need to be introduced, which significantly increases the cost of mutual exclusion behavior. GoroutineSince thread and process scheduling are relatively resource-intensive, engineers later discovered that a thread is actually divided into kernel mode and user mode, and named this user mode thread a “goroutine,” meaning a lightweight thread. When encountering I/O blocking, we can implement scheduling processing in user mode ourselves, without having to trouble the lower-level operating system to switch threads to schedule. This significantly improves performance because a process occupies approximately 4 GB of virtual memory (32-bit operating system), and a thread also requires approximately 4 MB. However, a goroutine is much smaller, requiring only a few kilobytes in Go. Binding relationshipN:1N goroutines are bound to one thread, avoiding the hassle of thread switching, but multiple cores cannot be used to process programs. 1:1One goroutine is bound to one thread, returning to the kernel to switch threads. M:NM goroutines are bound to N threads, which can fully utilize multiple cores to efficiently process programs, but the difficulty is to implement the binding and scheduling of goroutines and threads in user mode. Go language uses this strategy. GMP模型G：Represents goroutineM：System threadP: Scheduler Each P has its own queue for storing goroutines to be executed, and there is also a global queue. When there are no goroutines to be executed in P’s own queue, it first steals some from other queues using the method mentioned above. If other queues are also empty, it will take goroutines from the global P queue. When taking G (referring to goroutine) from the global queue, it will not take many at once, otherwise, other P will come here to take them, increasing unnecessary overhead. The GMP scheduling method is as follows: A system thread (M) that wants to execute a goroutine must first bind to P M takes G from P to execute it, and then takes the next G according to the aforementioned method If M encounters a system call (such as file read and write) while executing G, P will unbind from M, but M will remember which P it was bound to. When G and M exit the system call, they will find the P that was just bound to this M. If it cannot be found, they will find other P. If it cannot be found, the G will be marked as runnable and placed in the global queue. In addition： If a running G1 creates a new G2, G2 will be bound to P1, where G1 was originally located. Rule: When creating G2, running G1 will wake up other P and M (assuming P2 and M2) to execute tasks in the system. If there are no Gs in the queue of P2, it will try to steal some from other places using the aforementioned method. If it still cannot find any, it will keep searching. We call this state a “spin state.” Although it seems a bit silly, it is still acceptable compared to the overhead of creating and destroying threads.In summary, the GMP model uses lightweight goroutines to reduce resource consumption and increase concurrency, and uses a clever scheduling strategy to avoid the high overhead of thread and process switching.","link":"/2023/03/22/GMP/"},{"title":"正版软件","text":"这周把 Goland 和 Pycharm 都换成正版的了，结束了多年破解版的使用历程。虽说正版的功能也没有完全用到，不过以往用破解版的时候总是有很不顺的感觉，一方面是因为破解版往往落后好几个版本，另一方面是不稳定，要不时去更新一下。 关于盗版学生时代用的大部分软件都是盗版的，那时的自己根本不懂什么版权意识，无论是办公工具还是游戏一律用破解版，还沾沾自喜觉得找资源有一手。第一次支持正版是2019年出的《全战三国》，处于对三国的狂热，毫不犹豫300多买了价位不算便宜的新版大作。自那以后就慢慢开始支持正版了。作为开发者也会参与一些开源项目，偶尔也会其他参与开源的朋友聊天，大部分的作者仅靠开源是不足以支持自己生活开销，如果使用者都能尽自己的所能去支持这些作品，开发者就有更大的动力去把这件事做下去。比较好的一个现象是有一些大公司已经这么做了，但充其量也只是很小的一部分开发者得以纯靠开源的收入来生活。个人来说，希望能尽自己的力去让更多的开源作者获得一些收入，即使是帮忙宣传一些优秀的项目，也挺好的。","link":"/2022/11/20/%E6%AD%A3%E7%89%88%E8%BD%AF%E4%BB%B6/"},{"title":"Kubernetes 架构","text":"前言作为云原生时代的当红人物，一直想精读一下 k8s 的源码，本篇文章会从其架构，源码来深入剖析 k8s 的设计思路。 K8S组件与职责K8S组件 我们可以看到K8S主要是由，API server、Cloud controller manage（可选）、Controller manager、etcd、kubelet、kube-proxy、Scheduler。可以分为Control Plane组件、和Node组件两个大类，Control Plane组件一般在单独的机器上，也就是说生产环境不会把业务Pod和它们放一起，Node组件每台运行Pod的机器都要有的，一方面是维持Pod正常运行，还有就是提供K8S运行时环境。 Control Plane 组件 Kube-APIserver：k8S暴露出来给用户使用API的组件，其它各组件之间的交互都是要经过它的。所以考虑到高频地调用，它是可以部署多个来负载的 etcd：一个高性能的键值数据库，K8S的持久化数据都放在这里 kube-scheduler： 持续监听有没有未分配节点的Pod，并根据各种条件（节点情况、Pod配置亲和性）等给它分配一个节点 kube-controller-manager：正常来说每个控制器都是一个单独的进程，不过K8S为了降低复杂性就把它们把包成一个二进制文件并运行在一个进程中，其中比较常见的控制器有 Node controller： 负责监听Node是否正常 Job controller： 负责监听K8S的一次性运行的Job，并创建Pod去跑Job EndpointSlice controller：负责EndpointSlice的创建，EndpointSlice 可以理解是 Service和Endpoint之间的一个映射关系 ServiceAccount controller：为新的Namespace创建默认的 ServiceAccounts Node 组件上边有提到，Node组件是每个节点都会运行的 kubelet： 它负责确保Pod中的容器正常运行，并确保按照PodSpecs（比如ServiceAccount，Pod调试策略，标签）等条件运行的。 kube-proxy： 是Node中的网络代理，pod与pod间的通信要经由它，实现了k8s service 概念的部分功能 Container runtime： 容器器运行时就如它的名字一样，负责运行容器的。常见的容器运行时除了我们熟知的 docker还有containerd，CRI-O等。","link":"/2023/03/24/1025/"},{"title":"202303W4 go hiking","text":"It has passed a month since I go hiking last time. I took 6 hours across the “dong xi chong” and then back to the beginning place with my frend on Saturday. At several monthes ago, I ran 4 kilometers every day, however, after a 6-kilometer attempt, my body couldn’t adapt. And one day a person told me that i looked fat than before suddenly, although I never deliberately try to lose weight, I want to maintain a normal appearance. So I decided to resume running 5 kilometers every day as before.","link":"/2023/04/02/1026/"},{"title":"202304W4 playing and playing","text":"I have taken a guitar lesson for 2 weeks, from half a month ago, I started playing guitar as before. There are some interesting friends at the milk tea shop on Saturday, someone sings songs well, and someone plays musical instruments well, I’m glad to enjoy music. Labour Day is coming soon, and my roommate asked me if there are any places there are not to crowded and fun to go to. Last year we went to a small island, but I haven’t decided where to go this time yet. I was thinking of just relaxing in Beijing, but there isn’t much to do there. There’s a good chance we’ll just stay in Guangdong province this year.","link":"/2023/04/28/1027/"},{"title":"202305W3 offline for a week","text":"It has been three weeks since the last time I wrote a weekly report. Recently, I’ve been wanting to go back to the northern region to visit my family. A few days ago, I told my leader that I would be taking a week off. I will be flying to Beijing on the 27th of this month to meet my brother and sister, and then go to my hometown. Recently, I have been studying AWS platform and GitHub Actions for automation purposes. I plan to gradually accomplish project building, deployment, logging, tracing, and performance monitoring. If there are no other tasks, I intend to work on these during my vacation.","link":"/2023/05/23/1028/"},{"title":"202306W1 Healthy","text":"I got infected with the novel coronavirus at the beginning of this month. Last month, I informed my friends in the northern region that I would be returning there for a week’s vacation at the end of the month, and also planned to visit them. However, due to the virus, this plan had to be postponed until the end of June. As mentioned before, I have now achieved automated deployment of the project on AWS. The next step is to utilize caching to accelerate the build process. However, progress has been a bit slow recently due to some physical discomfort. I have been focusing on studying Linux system-related topics lately.","link":"/2023/06/11/1029/"}],"tags":[{"name":"python","slug":"python","link":"/tags/python/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"邮件","slug":"邮件","link":"/tags/%E9%82%AE%E4%BB%B6/"},{"name":"django3","slug":"django3","link":"/tags/django3/"},{"name":"生活","slug":"生活","link":"/tags/%E7%94%9F%E6%B4%BB/"},{"name":"Typora","slug":"Typora","link":"/tags/Typora/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"自动化","slug":"自动化","link":"/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"uwsgi","slug":"uwsgi","link":"/tags/uwsgi/"},{"name":"WSL2","slug":"WSL2","link":"/tags/WSL2/"},{"name":"历史相关","slug":"历史相关","link":"/tags/%E5%8E%86%E5%8F%B2%E7%9B%B8%E5%85%B3/"},{"name":"树莓派","slug":"树莓派","link":"/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"小说","slug":"小说","link":"/tags/%E5%B0%8F%E8%AF%B4/"},{"name":"东野圭吾","slug":"东野圭吾","link":"/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/"},{"name":"Hyperledger","slug":"Hyperledger","link":"/tags/Hyperledger/"},{"name":"Fabric","slug":"Fabric","link":"/tags/Fabric/"},{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"科技双眼啤","slug":"科技双眼啤","link":"/tags/%E7%A7%91%E6%8A%80%E5%8F%8C%E7%9C%BC%E5%95%A4/"},{"name":"年终总结","slug":"年终总结","link":"/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"},{"name":"go","slug":"go","link":"/tags/go/"},{"name":"gRPC","slug":"gRPC","link":"/tags/gRPC/"},{"name":"周报","slug":"周报","link":"/tags/%E5%91%A8%E6%8A%A5/"},{"name":"goroutine","slug":"goroutine","link":"/tags/goroutine/"},{"name":"云原生","slug":"云原生","link":"/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"categories":[{"name":"生活","slug":"生活","link":"/categories/%E7%94%9F%E6%B4%BB/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"Django","slug":"Django","link":"/categories/Django/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"Git&#x2F;Github","slug":"Git-Github","link":"/categories/Git-Github/"},{"name":"其他","slug":"其他","link":"/categories/%E5%85%B6%E4%BB%96/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Markdown","slug":"Markdown","link":"/categories/Markdown/"},{"name":"阅读","slug":"阅读","link":"/categories/%E9%98%85%E8%AF%BB/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"树莓派","slug":"树莓派","link":"/categories/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"区块链","slug":"区块链","link":"/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Fabric","slug":"区块链/Fabric","link":"/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Fabric/"},{"name":"博客","slug":"博客","link":"/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"协议","slug":"协议","link":"/categories/%E5%8D%8F%E8%AE%AE/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"kubernetes","slug":"kubernetes","link":"/categories/kubernetes/"}],"pages":[{"title":"404","text":"","link":"/404/index.html"},{"title":"","text":"什么样的存在极简主义，中二晚期. Key Value 所在 深圳 如何联系 email: Nzc1NjUwMTE3QHFxLmNvbQo= 媒体平台 twitter、Instagram 户外 爬山，滑雪 乐器 一把偶尔响一下的吉他 常用语言 Go,Python,Solidity 平时喜欢看 宇宙记录片，旅游Vlog，红警HBK08 一些清单 阅读清单 跑步清单 音乐清单 观影清单 乱七八糟平时用的工具什么的会 记录在这里 F我是一个偶尔会发疯的人呐。 Ricardo M. Lu《龙族》","link":"/about/index.html"},{"title":"202208W1","text":"生活乌龟还是没能活过第二个月，如果早注意到它的状态就好了，本来想再尝试一下的，最后决定过段时间吧。最近朋友圈里有好多爬山的，回想一下上次爬山已经是几个月前的事了，周末爬一下塘朗山吧。 技术重读了一下DESIGN PATTERNS in GO，每次读设计模式问题能有不同的感觉，可能是因为平时不怎么写组件，所以更多的还是阅读开源代码来保持工程化的思维。 读书本周没怎么阅读，晚上睡的太晚了，地铁上都不想读书了，作息还是要调整一下的。","link":"/weekly/2022/202208W1.html"},{"title":"202208W2","text":"生活如上周周报所提到，周六下午去爬了塘朗山，今年的夏天相较往年热了不少，一趟下来全身都是汗。回后瑞随便吃了点，看了一下时间还早，想起也好久没有看电影了，查了一下最近《神探大战》正在上映，觉得题材和演员都还可以就直奔影院，剧情偏悬疑,刘青云演技依旧在线，就不剧透了，个人算是满意。回到家洗澡11点休息了，是几个月来最早的一次。玩了两局LOL，选了从来不选的船长，天坑，但是队友给力，所以还是赢了，这个游戏果然七分靠运气~ 技术速刷了 Solidity 的基本特性，下周会尝试开始写合约，也会学习一下公有链，私有链，联盟链，超级账本的概念和实现思路。博客主题换成了icarus，原因在7月第三周周报有提到（还是拖了大半个月。。。），顺带把周报单独分出了一个page。少加载了一堆资源访问速度提升是肉眼可见了，看板娘最后也没去掉。 读书 《读者》 《重构》虽然量不大，毕竟相比上周好多了。 还有本周就是这样了，不过在上传md之前习惯性地刷了一下推特，发现了一枚有趣的学生。","link":"/weekly/2022/202208W2.html"},{"title":"202208W3","text":"生活周六刷了梧桐山，上次去梧桐山已经是半年前了，天气正好，有一段土路没有下雨，顺利走到蝴蝶谷。只是不巧当天山顶多云，往下什么都看不到，还挺冷的。吉他放到角落吃灰有段时间了，试了试《城南花已开》，已经有点生硬了，平时还是要不时练习一下。公司新来一个老哥可以负载部分我的任务，leader说前期可以把不太重要的交给他熟悉项目，不过第一周感觉还是算了吧，快乐就好，所以我告诉他本周只用熟悉一下模块是做什么的，然后就是强调了一下没什么事就准时下班。 技术这周还挺忙的，技术方面基本没有输入和输出，本来想写一下合约的，这周工作任务比较满。下周会好一点，可以把一些任务交付给新人了。 读书东野圭吾的《时生》读了一半，《重构》小翻了一下，个人感觉比起上周只读杂志算是好一点。","link":"/weekly/2022/202208W3.html"},{"title":"202209W1","text":"生活本来计划周六去惠州爬罗浮山的，正好深圳实行“静默管理”也没去成，目前来看中秋节也是出不了深圳了。高中时期看的《龙族》出动漫了！很喜欢小恶魔的形象，话说记得诺诺是御姐，中二是保留了一点点，不过御姐完全是看不出来，继续期待青铜与火之王登场，衰小孩使用第一个1/4生命换来的战斗场面会以什么样的方式呈现给观众呢？老妈打电话问国庆什么时候回，舅舅家的姐姐要出嫁了，半年多没回老家是想回去看看，不过参加婚宴难免要被灵魂拷问，自毕业以来就像断线的风筝在南方浪，家里还是希望能早点定居，只是自由惯了，总觉得定居就会被束缚，还不够成熟吧。 技术学习了超级账本 hyperledger的理念，了解了联盟链，公共链和私有链的区别，周末把电脑重装了一下，本地试跑了 fabric，感觉找到了新玩具！ 读书《乌合之众》读完，感触挺大的，就是不知道怎么表达，作者的一些观点冲击了以往的认知，作者认为群众的认知未必高于个体，而个体的一些特点在融入集体之后会慢慢消失，这让我想到了一个词：同化。","link":"/weekly/2022/202209W1.html"},{"title":"202209W2","text":"生活中秋在家宅了三天没有出门，现在每天会跑几公里，一周下来感觉还行，用了一个开源项目收集每天的跑步信息，还可以自动生成轨迹线，但是GPS需要带手机，不过记录距离即可所以手机放家了。好久没看 doinb 直播，还是一如既往地有意思，4个职业选手放飞自我，辅助的妹子也是为难。 技术内网起了一个 go-ethereum的 本地环境，尝试用 go-ethereum 去实现创建账号，实现与公链的交互，由于相对离底层更进一步，所以比起直接用 solidity 无脑写合约来得更清楚。 读书《大秦帝国三上》100%战国秦的几代君主都是挺有才能的，赢渠梁、赢驷、赢稷，再加有商君、司马错、白起等臣子，虽说赢荡自负举鼎而亡，也没有多大成就，不过在位时也算能听进臣下的意见，所以总体来说秦的强大是必然的，从战国最弱的几个国家一直到最强。人物刻画的相当有特色，整部小说看起来也有一种开阔的感觉。","link":"/weekly/2022/202209W2.html"},{"title":"202208W4","text":"生活周五和两位朋友吃饭，之前是他们请的，这次正好轮到我了，选了大仟里的《美奈小馆》，越南料理，几个月前尝过一次，口感还行。期间闲聊了很多，代码、链、定居。其中一位离职一个多月，最近在研究 react ，有提到曾经做过一段前端，算是重拾旧业，打算再休息一段时间。另一位是有考虑之后在惠州定居，可能是因为已经有小孩了，所以会想得全面一点。 技术这周抽空整理了一下负责业务模块代码，九月份计划重构部分接口，所以又看了DESIGN PATTERNS in GO，希望重构后可以做到任何一位新人都可以快速上手。 读书 《时生》100% 《人间失格》100%积压的东野圭吾的书全部看完了，把《时生》放回书架的时候纠结下一本看什么好，《大秦帝国》系列还是阿加莎系列，但是最近看的都是历史和悬疑类型小说，想换个风格。正好看到角落里的《人间失格》，之前和发小互相推荐小说的时候有对她提到过，她说这本书看了可能会抑郁，没有很推荐我看。然而当初《活着》也没有造成很大的心理负担，片刻迟疑最终还是拆开了包装。《人间失格》一共花了两天半，确实是不错的作品，也确实有点心情沉重，刚看完的那天不想工作，也不想和任何人沟通。一两天后就好多了，多看看不同题材的书就好像经历了不同人的部分人生一样，感觉生命充实许多。","link":"/weekly/2022/202208W4.html"},{"title":"202210W1","text":"生活回一次老家真是挺不容易的，早上六点起床下午四点才到家；回来那天短袖尚可，现在已是外套加身。和家人一起把前院的土豆收了一下，很多年没有做农活了，手法已然生疏。本来二舅家的姐姐是要回来举办婚礼的，突然县里管控升级就作罢了，想凑个热闹都不行。 技术国庆优先，其他滞后～ 读书《大秦帝国三下》 100%看到白起被秦昭王赐死很是惋惜，一生从未打过败仗的军神最终落得如此下场。关于赵括，以前只知道这是个纸上谈兵的将军，现在看来是以点概面了，如果他能随军征战几年，经历几场大战再与白起决战长平，胜负真不一定，没想到他在断粮的时候能把自己一半的粮食分给战士，陷全军于危局能承认自己全盘的错误，人格魅力相当可以，可惜。","link":"/weekly/2022/202210W1.html"},{"title":"202209W4","text":"生活换了个灵动岛，只有很小一部分应用支持，不过苹果的联通信号是真的有点抱歉了，上地铁基本等于没有，电量暂时能坚持一天。周六爬了铁仔山，海拔不高，个别地方风景不错。忘记上次刷油管是什么时候了。抽空听一些播客，了解一下不同人的异样人生，挺有意思的，有位分享者兜兜转转出国回国、换了职业方向，最终选择了一个小城定居，也有的出国了就没再回来。想到了在成都和一位做开源的老哥沟通过，老哥彼时在业界也算小有名气，放弃了一些机会选择自由职业，在几期博客里也分享了自己的开源生涯，前一阵子看他在博客里提到入职了戴尔。偶尔也会感到生活的单调，对于大多数人来说也许单调才是常态，罗曼·罗兰有句话描述了这种生活方式： 有些人二十岁就死了，等到八十岁才被埋葬 诚然每个人对于生活都有自己诠释，但总奢望平静的生活不时有一些波澜，无论好坏，就好像有一种疯狂是渴望燃尽生命去追求的，是一种只有在不断变化的场景中才能突然达到的状态。 技术Github 看到一个 issue 被link到了自己提的一个 *PR*，当时是为了下油管的视频补全了代理的功能，然后又不想白嫖项目就顺手提交了这个小的feature。没想到国外的机器访问国内也要代理，好奇这是哪个国家。作者希望这个 PR 把配置功能一并完善了，后来一直没时间（其实就是懒），立个FLAG：国庆一定。 读书原以为现在已经可以接受各种风格的书了，其实想多了，《沙之书》最终是读不下去了，说不定未来哪天实在无聊把它捡起来一口气解决了。《大秦帝国3下》读了10%，这周读书有点少了。","link":"/weekly/2022/202209W4.html"},{"title":"202209W3","text":"生活周六和朋友爬了南山，只看海拔可以说是一座小山，然而盘山的路也是挺长的，总体下来和塘朗山用时差不多。用商品门口的电子称测了体重，比起年初的144斤已经下降到了132.8斤，一方面是过年穿的多，也可能是跑步两周的意外变化吧，意外是因为跑步只是不想太肥宅而每天保持一定的运动量。国庆的机票订好了，希望这段时间疫情不要再反复了，一年也就回去两次。 技术在家里的电脑搭了一个 istio，实操一下，公司的 istio 都是运维去处理的，虽然不用开发改配置，终究是想自己体验一下。 读书《被拒绝的勇气》 100%书名里是拒绝，读完感觉和拒绝关系不大吧，主要是给读者一点点建议或者说是方法，简单化生活也是可以轻易做到的。拿弗洛伊德的作为对立的观点也是有点东西了。","link":"/weekly/2022/202209W3.html"},{"title":"202210W4","text":"生活上周没写周报，是因为也没什么可以写的，本周的话没有大事发现，参加了第七届开源年会，这次是第一次采用元宇宙的形式给大家做分享，有幸作为志愿者组长和区块链会场的主持人参与其中，组长需要培训志愿者，任务虽然简单但是大家时间都不统一，所以有一部分是元宇宙内部培训的，也有一部分是看我的录屏学习，每天晚上基本都是11点以后才回答完所有的问题。会议开始前一天晚上才把主持稿写完，有一位讲师的视频超过时长了，下了剪辑软件剪了10分钟的内容，最后导出发现音频和视频不同步…….主持当天麦克风声音还很小。 技术因为在准备开源年会，所以基本什么都没做 读书《大秦帝国四上》 100%终于读完了 其他之前也有参与过Pycon China 2019,Pychon China 2022。一次是在成都，一次是在深圳，这次是在元宇宙。其实参与社区最主要的一个目的还是因为社区的氛围比较好，因为自己崇尚自由，喜欢不受约束，外加极简的社交，开源社区刚好满足所有的情况，期间的各种工作也给了参与者自由发挥的空间。比如作为主持人我不需要用太官方的话客串全场，主持过程中加点个人的想法这都是可以的。","link":"/weekly/2022/202210W4.html"},{"title":"202211W1","text":"生活计划周六去梅林穿越的，天气不稳定小伙伴们最终一致“下次一定”。周日晚上和朋友出去吃饭，说起来有段时间没见他了，在家快乐当宝爸了吧。Pycon China下个月就要还是老地方举办，收到少飞的突然联系还是挺有意思的，今年还是去折腾直播设备吧，去年真的调试了好久。 技术学习了一下go的template用法。了解了一下 consensys 公司的产品设计思路，重复看了上周区块链论坛的分享内容。目前对于区块链的了解算是小有入门吧，不过还没有看到比较成熟的商品模式。 其他国庆后的作息很不规律，工作日一两点睡，周末有时候四五点还没睡，希望能慢慢调整到在家时的状态。","link":"/weekly/2022/202211W1.html"},{"title":"202210W2","text":"国庆结束说短不短的假期没什么感觉就过去了，看了一个国庆的动物世界，并非所有的动物都畏惧人类，像虎鲸这样的海洋霸主偶尔也会挑逗一下两足生物。上班第二天开始跑步，小半个月没跑第一天就把膝盖摔伤了。S12开始了，lpl的几只队伍表现都不错，小明的辅助硬是打出了C位的感觉，看到有弹幕笑称“4保1辅助”，反而是TES的战绩在lpl中垫底，不管怎么说轻敌也要反思一下。回到深圳和朋友吃了顿饭，离职几个月感觉精神状态好多了，而且还能保持一定的hard刷题量倒是挺意外的。 技术看了一下helm自定义配置功能的源码，打算借鉴到另一个项目中去 读书《大秦帝国四上》 40%吕不韦终于登场了，有一段对话挺精彩的 吕不韦思忖道：“商家以牟利为本。敢问父亲，耕田之利几何？”“劳作立身，其利十倍。”“珠玉之利几何？”吕不韦问。“珠玉无价，其利百倍。”“若得谋国，其利几何？”“谋国？”父亲大是愣怔，“邦国焉得买卖？何谋之有？”吕不韦字斟句酌道：“譬如，拥一新君，掌邦国大全。”“……”父亲默然，良久，竹杖笃笃顿地，“如此谋国，其利万世不竭！” 吕不韦认定秦异人“奇货可居”，于是押上自己全部身家帮秦异人还国，无论是眼光还是魄力都注定了他未来曲折精彩的道路。","link":"/weekly/2022/202210W2.html"},{"title":"202211W4","text":"周二晚上跑步的时候收到社区的电话说经过风险地区，后续几天不能去公司上班。虽说不让去公司上班，倒也没有强制把整个楼封掉，或者不让下楼扔垃圾，只是避免和太多人接触吧。在家的几天也挺规律的，每晚都下楼跑步，12点就睡觉。 听了一周播客从周二开始又想跑步了，之前也提到自国庆以来基本是没有跑了，以往跑步手机直接放家里，只带个手环下楼用于买水和记录跑步的里程和心率等，跑完就上楼了，现在每天会把手机打开播客听一期开源相关的内容，实在没什么可听的就选择一些生活相关的播客，比如设计，旅游，语言……听了一周的体验是相当不错的，平时自己也会关注自己感兴趣的博客。相比之下播客有几个好处：1. 是听的而不是看了，因为跑步的时候只能听而不能拿着手机看博客，除去安全问题眼睛是受不了的。2. 互动，播客的目的就是大家交流想法，比如开发软件可能他觉得有更好的工具或者包，而博客只靠表达效果是远远没有这么好的，比如主持人中间的开玩笑啊，其他人的语气这些从文字中是体会不到的。3. 博客相比线下的Meeting Up灵活很多，在线即可，疫情原因很多线下活动举办起来没那么方便，可能一年也没几场，博客只需开个channel就可以了。4. 其实很多主播也不一定有博客，或者有些主题自己写没什么意思，而在播客里可以了解到更多样的主播。 Github新发现之前一直没注意到 Github 的 Explore 功能，它是通过你关注的项目去推荐可能感兴趣的同类项目，类似抖音的视频推荐，比如最近比较关注区块链相关的项目，它就会推荐 Hyperledger 组织的仓库，挺实用的功能。 其他有趣的发现xlog是一个dapp博客，它的数据都在链上，评论也已经有了，支持用户自定义功能： You can follow, comment, like, and mint your blog and posts, all on the blockchain of course. Domain name, navigation bar, custom styles, all as you wish, and stored on the blockchain. 行尸走肉完结了很多年前追过的一部美剧，也是唯一看过的一部丧尸相关电视剧，前两天在B站看到说它大结局了，从高中到毕业三年，不过真的剧情太长了，看看以后会不会想起来追完它。 Ted英语演讲免费的英语学习app，有讲解视频和中英对应，还有长按翻译，目前使用很好。 Hyperledger视频他们每周都会更新一些区块链相关应用的视频，这周看了一下在慈善基金会的应用。 鬼泣背后的剧情在B站上看到一位Up主分析了鬼泣5背后的剧情，对鬼泣有了新的认识，比如为什么最后总需要V补刀，因为梦魇是无法杀人的。说起来鬼泣还是小学时候在电视上一个游戏频道看到的，打斗感和过场动画震撼到了当时只会玩红警和4399的我，后来去网吧也是会打开玩一下的，也是从那个时候开始粉丁叔的，桀骜不逊的性格，表面上玩世不恭又异常可靠，最喜欢的游戏角色，没有之一了吧。","link":"/weekly/2022/202211W4.html"},{"title":"202211W3","text":"下次不点辣了周六和同学吃了个火锅，锅底选的鸳鸯，微辣。突然发现我们都下意识地把菜加到了番茄的那边。”如今感觉微辣都受不了了“，我感慨道，同学点头表示同意。当初刚从成都来到深圳的时候是不会考虑鸳鸯锅的，至少中辣起步，也算是入乡随俗了。 新人？老人？ hello 各位 我是邢立涛 目前在做go，做过 pycon 2019 pycon 2021 第七届开源年会志愿者 分别负责拍照摄影和主持很高兴认识大家！ 以往每年都会参加 pycon china 的活动，2019年在成都是10月举办的，2021年是11月，今年是12月中旬。不出意外今年还是负责深圳会场的直播摄像。成都那年还是很拘谨的，刚毕业的自己总是不知道怎么融入其中，后来发现社区中不乏奇葩，特立独行的比比皆是，只不过是再多一个而已。 技术Fabric 测试网络调试了链码，对 Fabric 的业务流程熟悉多了，包括从发起一个 proposal 到 install 链码，再到 approval,invoke,deploy an application。下周阅读 Fabric 的源码，有空会开发一个应用。 读书《区块链原理、设计与应用》20%","link":"/weekly/2022/202211W3.html"},{"title":"202211W2","text":"整理书架的时候发现没有空间放置新书了，有一层是放满了读者，还有几杯比较厚的 python 技术书，有的是还没毕业买的，有的是刚毕业那会买的，一起处理了。 逝去的生命网上看到一位币圈的大佬自杀了，他曾炒币收入500万，后来进行一些投资，最近市场不景气差不多归零了，然后就是和女友分手，留下了一段视频之后选择告别人世。惊讶，可惜，惊讶是因为年纪轻轻家里情况又比较特殊的情况下也曾有过那样的折腾。可惜22岁大有重新来过的可能却终结了生命。有时也会把一些场景类比到自己身上，思考在同样的情景中自己的意志是否能平静处理，答案往往是不能。 放慢节奏周末在家宅了一天，看了一天书，还旁观了社区几位大叔下象棋。前一段时间的周末过得很忙，或者说排得有点满，突然有一周不玩游戏不约饭不水群感觉真的不错。 技术正在重拾 Hyperledger Fabric，一个月前在 wsl 上成功跑起来了测试网络就没管了，这次打算系统地学习一下这个框架，感谢pseudoyu 推荐的《区块链原理、设计与应用》和《区块链技术进阶与实战》这两本书。 读书《区块链原理、设计与应用》10%接下来一段时间小说先停下来，小说今年的输入已经远超往年了 其他忍不住又开始看《魔兵传奇》了，说起来银太的名字作为网名已经好多年了，连 Github 当初注册的 id 都是 Mar-heaven。","link":"/weekly/2022/202211W2.html"},{"title":"202212W1","text":"这周听的播客依然以开源为主，几位嘉宾讲述了各自参与到开源的经历，以及一些想法。不得不说每次听到有谁说自己高中啊甚至初中就接触到编程还是有点佩服的，对比自己，初中的时候电脑基本都是用来看剧，或者玩反恐精英，高中就更纯粹了，单调英雄联盟。 深度参与社区其中有一个观点还是很有感触的，就是尝试去深度参与社区。刚毕业的那会自己只负责拍照，还老担心拍的不好（事实上确实很业余），后来借鉴了其他人的照片，现在至少角度不会显得突兀。 后来负责了一个直播的摄影机机位，虽说是固定不用移动，但第一次调试直播设备也经历了一点波折。最噩梦的是切屏器被我玩的对不上了，那天我们调试到了很晚才整好。 再后来线上培训志愿者、主持分会场，观众不多也挺紧张的。幕后也要简单地剪辑视频，偶尔摸出一个脚本去处理一些事情。 以现在的角度回看，在比起更加直接的“**开发工程师”， 在开源社区更多的是有机会尝试不同的角色，也不用去焦虑做不好会怎样。 翻出2021年总结的时候有这么一段：后续会更深度参与社区，期待有新的发现。 ChatGPT微博的热搜前十我不知道是什么，但 ChatGPT 毫无争议是朋友圈的关键词第一，它可以写代码，搞怪，天文地理无所不知个人体验是非常满意的，自己的代码可以交给它 review，有考虑过作为搜索引擎，只是未来它一定是收费的，目前可以白嫖。或许以前没有注意过 AI 的发展，像这种可以有上下文的提问，并且可以把话题一直延伸下去的还是头一次见，目前一些简单的代码实现完全可以用 ChatGPT 去生成初代简易算法，所以未来计算机相关的初级任务完全可以交给人工智能自行解决。 运动连续跑步十天了，打破历史记录中间断了一个月，12月坚持下来200公里应该问题不大。 读书二刷《重构》","link":"/weekly/2022/202212W1.html"},{"title":"","text":"2022’s Weekly report202212-W4 颓废的两周202212-W1 万能的ChatGPT202211-W4 开始听跑步电台202211-W3 好像没那么能吃辣了202211-W2 逝去的生命202211-W1202210-W4202210-W2202210-W1202209-W4202209-W3202209-W2202209-W1202208-W4202208-W3202208-W2202208-W1202207-W3","link":"/weekly/2022/index.html"},{"title":"202212W4","text":"最近发烧的人好多，周四喉咙有点疼，不过当时也没有抗原，也不知道是不是中招了，打了声招呼远程办公。周日一起合租的同学烧到40度+，原本打算元旦前的一周也远程算了，鉴于在家这几天少了固定的运动量精神似乎变差了很多，想想还是去公司吧。周一早上看了一下镜子里的人，不到一周的熬夜和荒废了两周的跑步从黑眼圈和憔悴的面容就可以看出来有多糟糕了。 Pycon 2022和听听卡一起主办了今年的 PyCon China 深圳场，有了往年的惨痛教训流程上顺利了很多，没有因为切屏器再搞到晚上十一点，会前还调侃说今年这个疫情到时候来听的人只有一两个会不会很尴尬，最终还是到场了几十个，似乎比去年还多一点。晚上一起吃饭的时候发现有不少讲师其实也是从听众过来的。第一年是听众，第二年是志愿者，第三年就上台分享。虽然工作上一直在 GO 了，不过在社区的项目还是优先开发效率比较高的 Python。如果明年的 Pycon 自己还在深圳的话，那上去分享一下吧。 花里胡哨开源社的小伙伴大多是 Node.js + * TypeScript*，为了方便后续的合作，计划元旦入坑 Node.js。最近在搞开源社的公众号后台，不需要备案所以内网穿透一个开发也挺方便的，就是支持很不好，自动回复的功能网页端可以支持多条图文，但是开发者的接口只能返回一个，在公众号支持之前看样子是不能直接交付了。 读书这段时间也没读什么书，今年的最后一周就以东野圭吾结束吧。 元旦元旦暂时没有出省的计划，大概率在广东内部游荡了，更大概率就在深圳不出去了，最近两个月都没爬山了，去东莞或者惠州选一座山爬。 其他2022年的最后几天不要感染病毒就好～","link":"/weekly/2022/202212W4.html"},{"title":"202207W3","text":"生活周六申请了加班，一方面是优化一下系统，另外也是打算过段时间请假去西藏或者云南，当然也可能是四川走一走。有好长时间没有旅游了（一两天的就不说了），上次是什么时候已经不记得了。乌龟养了一个多月，这几天精神不是很好，把它放到的窗边了，希望每天有一段时间的光照能让它有有所好转。最近又开始刷宇宙记录片了，韦伯望远镜公布了几张深空照片，从中可以看到几处引力透镜效应，很好奇未来有一天我们通过引力透镜效应观测到的一百多亿年前接近 Bing Bang 时期的宇宙是什么样子。 技术入门了 solidity，虽然不从事区块链相关的工作，一直以来对这方面还是挺感兴趣的。博客从 Vercel 迁移到了 cloudflare，现在 Vercel 在国内访问速度有点感人。还有就是现在的主题有点太花哨了，计划切换成icarus。 读书在读Make Time。","link":"/weekly/2022/202207W3.html"},{"title":"","text":"Weekly report202301-W3 除夕的深圳202301-W1 去听欢乐港湾的弹唱2022","link":"/weekly/index.html"},{"title":"","text":"Weekly report202301-W1 去听欢乐港湾的弹唱202212-W4 颓废的两周202212-W1 万能的ChatGPT202211-W4 开始听跑步电台202211-W3 好像没那么能吃辣了202211-W2 逝去的生命202211-W1202210-W4202210-W2202210-W1202209-W4202209-W3202209-W2202209-W1202208-W4202208-W3202208-W2202208-W1202207-W3","link":"/weekly/index%20copy.html"},{"title":"","text":"Weekly report202301-W1 去听欢乐港湾的弹唱202212-W4 颓废的两周202212-W1 万能的ChatGPT202211-W4 开始听跑步电台202211-W3 好像没那么能吃辣了202211-W2 逝去的生命202211-W1202210-W4202210-W2202210-W1202209-W4202209-W3202209-W2202209-W1202208-W4202208-W3202208-W2202208-W1202207-W3","link":"/index.html"},{"title":"202301W1","text":"下周结束就快过年了，和家里说了今年在深圳过年，第一次在外地过年是两年前，也是在深圳，大部分人来深圳都只是为了赚钱，这边的外来人占比相当大，所以一到过年会发现这座城市很空，特别是除夕会有种一个人拥有整个城市的感觉。至于为什么在深圳过年，是因为毕业之后就一直在工作，节奏很快，每隔一段时间就想留出几天什么都不做，出去户外，或者关掉电子设备一直躺着。 春节假期有两周左右，是想做一些平时没时间去做的事情，比如看看周围有没有地方钓鱼，前几天看到 Grey Li 的年终总结，有提到十多年前的吉他，后来就基本没弹了，有遗憾的也不止我一个，还是可以继续学习的。 周末晚上去欢乐港湾吃了麦当劳，那边每周末都有人唱歌，曲子是随机的，也可以点歌，中间休息的时候去找他们聊了一会，我说平时最喜欢听小刚的《青花》，但是歌单上只看到了《黄昏》，能不能唱《青花》呢，“你是哪一年的？”，弹唱的小哥问到，我说25，不过周传雄的歌不是很多人都听过吗，他笑着说现在听的人少了，最终还是请他唱了《黄昏》。比起近几年火爆抖音的《红昭愿》、《叹》去考古十多年前的歌是有点奢侈了。 技术看了一下 k8s 的 ingress，服务暴漏这部分还一直停留在 nodeport 阶段，ingress-nginx 确实优雅，虽然也支持 istio 实现，公司里也是这么做的，但 istio 的部署和熟悉成本会高很多，一般的中小型项目也用不上。其实中小型项目直接 nginx + docker-compose 也是足够了。 书《How to》30%， 这本书的作者用各种不切实际的问题去请教专业人士，比如飞机怎么停到潜艇上，如何过河（用上亿个热水壶把河水蒸干，坐汽车加速完成抛物线运动，把河水冻成冰），还挺有意思的，推荐阅读。","link":"/weekly/202301W1.html"},{"title":"202301W3","text":"小区附近的店铺都关门回家过年了，使得本就比较偏僻的街道显得格外冷清，连平时后瑞地铁站周边密集的小吃摊也仅剩了三两个在维持着最后的烟火味。 除夕提前放假的几天在家疯狂玩游戏，玩到作息昼夜颠倒，每天凌晨4-5点睡觉，11点之后起床，基本没怎么下楼。直到除夕那天中午应邀去同事家吃午饭，本来约好的吃完早饭就过去的，结果刷了一下B站睡着了，要不是老爸的一个视频电话打过来可能就一直睡到中午了。同事家里做了蛮多的菜，期间她们问我做的如何，我笑了笑，打趣道比昨晚吃的泡面好多了。后来去荷兰小镇转了转，看到有卖乌龟的，想起了之前养的没有活过一个季度的乌龟，同事说可以再买一只，有比较便宜的品种，最终还是没买，家里那只之前生病的时候我觉得症状比较轻微，而且乌龟的生命力比较顽强，就没有带着去看兽医，直到最后结果无法挽回，那段时间极度消沉，不专业的喂养是在亵渎生命，就决定暂时不养宠物了。晚点的时候感谢了同事的招待，坐地铁去深圳湾转了转，坐到了另一个站，又低估了深圳湾的长度，绕了很久都没有走到经常出站的那个地铁口，错过了落日。 看书沉迷游戏也没怎么看书，过年的前三天刷一下曹春辉大大写的《Go语言高级编程》。 其他初一的欢乐港湾人比想象中的多。","link":"/weekly/202301W3.html"}]}